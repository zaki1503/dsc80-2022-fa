{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'otter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Zaki Ahmed\\dsc30_sp22\\dsc80-2022-fa\\labs\\03-hyp-dataframes\\assignment\\lab.ipynb Cell 1\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Zaki%20Ahmed/dsc30_sp22/dsc80-2022-fa/labs/03-hyp-dataframes/assignment/lab.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Initialize Otter\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Zaki%20Ahmed/dsc30_sp22/dsc80-2022-fa/labs/03-hyp-dataframes/assignment/lab.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39motter\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Zaki%20Ahmed/dsc30_sp22/dsc80-2022-fa/labs/03-hyp-dataframes/assignment/lab.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m grader \u001b[39m=\u001b[39m otter\u001b[39m.\u001b[39mNotebook(\u001b[39m\"\u001b[39m\u001b[39mlab.ipynb\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'otter'"
     ]
    }
   ],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 ‚Äì Hypothesis Testing and DataFrame Manipulation\n",
    "\n",
    "## DSC 80, Spring 2022\n",
    "\n",
    "### Due Date: Monday, October 17th at 11:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and Markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding will be done in an accompanying `lab.py` file that is imported into the current notebook.\n",
    "\n",
    "Labs and programming assignments will be graded in (at most) two ways:\n",
    "1. The functions and classes in the accompanying `.py` file will be tested (a la DSC 20),\n",
    "2. The notebook may be graded (if it contains free response questions or asks you to draw plots).\n",
    "\n",
    "**Note**: Labs will have public tests and private tests. The public \"smoke tests\" that you will run below and which appear on Gradescope are generally worth no points. After the due date, we will replace these tests with private tests that will determine your grade. This is different from DSC 10, where labs only had public tests!\n",
    "\n",
    "**Do not change the function names in the `*.py` file!**\n",
    "- The functions in the `*.py` file are how your assignment is graded, and they are graded by their name.\n",
    "- If you changed something you weren't supposed to, just use git to revert! Ask us if you need help with this, or google around for `git revert`.\n",
    "\n",
    "**Tips for working in the notebook**:\n",
    "- The notebooks serve to present the questions and give you a place to present your results for later review.\n",
    "- The notebooks in *lab assignments* are not graded (only the `.py` file is submitted and graded).\n",
    "- The notebook serves as a nice environment for 'pre-development' and experimentation before designing your function in your `.py` file. You can write code here, but make sure that all of your real work is in the `.py` file.\n",
    "\n",
    "**Tips for developing in the `.py` file**:\n",
    "- Do not change the function names in the starter code; grading is done using these function names.\n",
    "- Do not change the docstrings in the functions. These are there to tell you if your work is on the right track!\n",
    "- You are encouraged to write your own additional helper functions to solve the lab! \n",
    "- Always document your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing code from `lab.py`\n",
    "\n",
    "* We import our `.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'reveal_type' from 'typing_extensions' (C:\\Users\\Zaki Ahmed\\AppData\\Roaming\\Python\\Python39\\site-packages\\typing_extensions.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Zaki Ahmed\\dsc30_sp22\\dsc80-2022-fa\\labs\\03-hyp-dataframes\\assignment\\lab.ipynb Cell 6\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Zaki%20Ahmed/dsc30_sp22/dsc80-2022-fa/labs/03-hyp-dataframes/assignment/lab.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlab\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Zaki Ahmed\\dsc30_sp22\\dsc80-2022-fa\\labs\\03-hyp-dataframes\\assignment\\lab.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mio\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping_extensions\u001b[39;00m \u001b[39mimport\u001b[39;00m reveal_type\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'reveal_type' from 'typing_extensions' (C:\\Users\\Zaki Ahmed\\AppData\\Roaming\\Python\\Python39\\site-packages\\typing_extensions.py)"
     ]
    }
   ],
   "source": [
    "from lab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Hypothesis Testing\n",
    "\n",
    "In this section we'll develop an intuition for the terms and structure of hypothesis testing ‚Äì it's nothing to be afraid of!\n",
    "\n",
    "The first step is always to define what you're looking at, create your hypotheses, and set a level of significance.  Once you've done that, you can find a p-value which is related to your test statistic.\n",
    "\n",
    "If all of these words are scary: look at the [Lecture 4](https://github.com/dsc-courses/dsc80-2022-fa/blob/main/lectures/04-hypothesis_testing/notebook/lecture.ipynb) notebook, the readings, and don't forget to think about the real-world meaning of these terms!  The following example describes a real-world scenario, so you can think of it in a normal lens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 ‚Äì Tires üöó\n",
    "\n",
    "A tire manufacturer, TritonTire, claims that their tires are so good, they will bring a Toyota Highlander from 60 mph to a complete stop in under 106 feet, 97% percent of the time.\n",
    "\n",
    "Now, you own a Toyota Highlander equipped with TritonTire tires, and you decide to test this claim. You take your car to an empty Vons parking lot, speed up to exactly 60 mph, hit the brakes, and measure the stopping distance. As illegal as it is, you repeat this process 50 times and find that **you stopped in under 106 feet only 47 of the 50 times**.\n",
    "\n",
    "Livid, you call TritonTire and say that their claim is false. They say, no, that you were just unlucky: your experiment is consistent with their claim. But they didn't realize that they are dealing with a *data scientist* üßë‚Äçüî¨.\n",
    "\n",
    "To settle the matter, you decide to unleash the power of the hypothesis test. The following three subparts ask you to answer a total of four select-all multiple choice questions.\n",
    "\n",
    "#### Question 1.1\n",
    "\n",
    "You will set up a hypothesis test in order to test your suspicion that the tires are are actually worse than claimed. Which of the following are valid null and alternative hypotheses for this hypothesis test?\n",
    "\n",
    "1. The tires will stop your car in under 106 feet exactly 97% of the time.\n",
    "0. The tires will stop your car in under 106 feet less than 97% of the time.\n",
    "0. The tires will stop your car in under 106 feet greater than 97% of the time.\n",
    "0. The tires will stop your car in more than 106 feet exactly 3% of the time.\n",
    "0. The tires will stop your car in more than 106 feet less than 3% of the time.\n",
    "0. The tires will stop your car in more than 106 feet greater than 3% of the time.\n",
    "\n",
    "Create a function called `car_null_hypoth` which takes zero arguments and returns a list of integers, corresponding to the the valid null hypotheses above.\n",
    "Also create a function called `car_alt_hypoth` which takes zero arguments and returns a list of integers, corresponding to the valid alternative hypotheses above.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Question 1.2\n",
    "\n",
    "Which of the following are valid test statistics for our question?\n",
    "\n",
    "1. The number of times the car stopped in under 106 feet in 50 attempts.\n",
    "1. The average number of feet the car took to come to a complete stop in 50 attempts.\n",
    "1. The number of attempts it took before the car stopped in under 95 feet.\n",
    "1. The proportion of attempts in which the car successfully stopped in under 106 feet.\n",
    "\n",
    "Create a function called `car_test_stat` which takes zero arguments and returns a list of integers, corresponding to the valid test statistics above.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Question 1.3\n",
    "\n",
    "The p-value is the probability, under the assumption the null hypothesis is true, of observing a test statistic **equal to our observed statistic, or more extreme in the direction of the alternative hypothesis**.\n",
    "\n",
    "Why don't we just look at the probability of observing a test statistic equal to our observed statistic? That is, why is the \"more extreme in the direction of the alternative hypothesis\" part necessary?\n",
    "\n",
    "1. Because our observed test statistic isn't extreme.\n",
    "4. Because our null hypothesis isn't suggesting equality.\n",
    "5. Because our alternative hypothesis isn't suggesting equality.\n",
    "2. Because the probability of finding our observed test statistic equals the probability of finding something more extreme.\n",
    "3. Because if we run more and more trials (where a trial is speeding up the car then stopping), the probability of finding *any* observed test statistic gets closer and closer to zero, so if we did this we would always reject the null with more trials even if the null is true.\n",
    "\n",
    "\n",
    "Create a function `car_p_value` which takes zero arguments and returns the correct reason as an integer (not a list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Grouping\n",
    "\n",
    "Last month, the UK üá¨üáß announced a new [\"High Potential Individual\" visa](https://www.lexology.com/library/detail.aspx?g=41fa64ec-9272-468c-bdcb-8002745a754f), which allows graduates of universities ranked in the Top 50 globally to move to the UK without a job lined up. This visa has been a subject of much debate, in part due to how much rankings play a role. (Rest assured, UCSD is on the list!)\n",
    "\n",
    "In this section, you will analyze a dataset of university rankings, collected from  [here](https://www.kaggle.com/datasets/mylesoneill/world-university-rankings?datasetId=) (though we have pre-processed and modified the original dataset for the purposes of this question). Our version of the dataset is stored in `data/universities_unified.csv`.\n",
    "\n",
    "Columns:\n",
    "* `'world_rank'`: world rank of the institution\n",
    "* `'institution'`: name of the institution\n",
    "* `'national_rank'`: rank within the nation, formatted as `'country, rank'`\n",
    "* `'quality_of_education'`: rank by quality of education\n",
    "* `'alumni_employment'`: rank by alumni employment\n",
    "* `'quality_of_faculty'`: rank by quality of faculty\n",
    "* `'publications'`: rank by publications\n",
    "* `'influence'`: rank by influence\n",
    "* `'citations'`: rank by number of citations\n",
    "* `'broad_impact'`: rank by broad impact\n",
    "* `'patents'`: rank by number of patents\n",
    "* `'score'`: overall score of the institution, out of 100\n",
    "* `'control'`: whether the university is public or private\n",
    "* `'city'`: city in which the institution is located\n",
    "* `'state'`: state in which the institution is located"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 ‚Äì Rankings 1Ô∏è‚É£\n",
    "\n",
    "There are (still) a few aspects of the dataset we need to clean before it's ready for analysis.\n",
    "\n",
    "IMPORTANT: You should NOT use loops in this question.\n",
    "\n",
    "#### `clean_universities`\n",
    "\n",
    "Create a function `clean_universities` which takes in the raw rankings DataFrame and returns a cleaned DataFrame, cleaned according to the following information:\n",
    "\n",
    "- Some `'institution'` names contain `'\\n'` characters (e.g. `'University of California\\nSan Diego'`). Replace all instances of `'\\n'` with `', '` (a comma and a space) in the `'institution'` column.\n",
    "\n",
    "- Change the data type of the `'broad_impact'` column to `int`.\n",
    "\n",
    "* Split `'national_rank'` into two columns, `'nation'` and `'national_rank_cleaned'`, where:\n",
    "    * `'nation'` is the country indicated in the first part of `'national_rank'`. \n",
    "        * Note that there are **3** countries that appear under different names for different schools. For all 3 of these countries, you should pick **the name that is longer** and use that name for every occurrence of the country. One of the 3 countries is **`'Czech Republic'`**, which also appears as **`'Czechia'`** ‚Äì since these refer to the same country and `'Czech Republic'` is longer, all instances of either name should be replaced with `'Czech Republic'`. You need to find the other 2 countries on your own. \n",
    "        * As is mentioned below, your function will only be tested on the DataFrame in `data/universities_unified.csv`, so you don't need to worry about country names other than these 3.\n",
    "    * `'national_rank_cleaned'` is the integer in the latter part of `'national_rank'`. Make sure that the data type of this column is `int`. \n",
    "    * Don't include the original `'national_rank'` column in the output DataFrame.\n",
    "* Create a Boolean column `'is_r1_public'`. This column should contain `True` if a university is public and classified as R1 and `False` otherwise. Treat `np.NaN`s as False. **Note that in the raw DataFrame, a university is classified as R1 if and only if it has non-null values in all of the following columns: `'control'`, `'city'`, and `'state'`.**\n",
    "    - Read [this page](https://en.wikipedia.org/wiki/List_of_research_universities_in_the_United_States) to learn more about what it means for a university to be classified as R1.\n",
    "    \n",
    "**The only dataset your function will be tested on is `data/universities_unified.csv`; you don't need to worry about other hidden test sets.** In addition, please return a *copy* of the original DataFrame; don't modify the original.\n",
    "\n",
    "<br>\n",
    "\n",
    "Now, we can do some basic exploration.\n",
    "\n",
    "#### `university_info`\n",
    "\n",
    "Create a function `university_info` that takes in the **cleaned** DataFrame outputted by `clean_universities` and returns the following values in a list:\n",
    "* Among `'state(s)'` with three or more `'institution(s)'` in the dataset, the `'state'` whose universities have the lowest mean `'score'`.\n",
    "* The proportion of the `'institution(s)'` in the top 100 for which the `'quality of faculty'` ranking is also in the top 100.\n",
    "* The number of `'state(s)'` where at least 50% of the `'institution(s)'` are Private (NOT r1_public).\n",
    "* The lowest ranking `'institution'`, according to `'world_rank'`, that is ranked #1 in its nation (i.e. that has a `'national_rank_cleaned'` of 1).\n",
    "\n",
    "You can assume there are no ties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>institution</th>\n",
       "      <th>nation</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harvard University</td>\n",
       "      <td>United States</td>\n",
       "      <td>4.637401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stanford University</td>\n",
       "      <td>United States</td>\n",
       "      <td>4.512844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>United States</td>\n",
       "      <td>4.408737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>5.250795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>University of Oxford</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>5.213140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>University of the Algarve</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>-1.144479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Alexandria University</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>-0.721110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Federal University of Cear√°</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>-0.495751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>University of A Coru√±a</td>\n",
       "      <td>Spain</td>\n",
       "      <td>-0.775241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>China Pharmaceutical University</td>\n",
       "      <td>China</td>\n",
       "      <td>-0.544029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               institution          nation     score\n",
       "0                       Harvard University   United States  4.637401\n",
       "1                      Stanford University   United States  4.512844\n",
       "2    Massachusetts Institute of Technology   United States  4.408737\n",
       "3                  University of Cambridge  United Kingdom  5.250795\n",
       "4                     University of Oxford  United Kingdom  5.213140\n",
       "..                                     ...             ...       ...\n",
       "995              University of the Algarve        Portugal -1.144479\n",
       "996                  Alexandria University           Egypt -0.721110\n",
       "997            Federal University of Cear√°          Brazil -0.495751\n",
       "998                 University of A Coru√±a           Spain -0.775241\n",
       "999        China Pharmaceutical University           China -0.544029\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'universities_unified.csv')\n",
    "df = pd.read_csv(fp)\n",
    "\n",
    "datatypedict = {\n",
    "    'broad_impact': np.int64,\n",
    "    'national_rank_cleaned': np.int64\n",
    "                }\n",
    "\n",
    "dfc = df\n",
    "dfc['institution'] = dfc['institution'].replace(r'\\n',', ', regex=True)\n",
    "dfc['institution'] = dfc['institution'].replace(r'\\r,',',', regex=True)\n",
    "dfc['national_rank_cleaned'] = dfc['national_rank'].apply(lambda x: x.split(', ')[1])\n",
    "\n",
    "dfc['nation'] = dfc['national_rank'].apply(lambda x: x.split(', ')[0])\n",
    "\n",
    "dfc= dfc.replace('Czechia', 'Czech Republic')\n",
    "dfc= dfc.replace('USA', 'United States')\n",
    "dfc= dfc.replace('UK', 'United Kingdom')\n",
    "dfc = dfc.astype(datatypedict)\n",
    "\n",
    "def r_1_pub(row):\n",
    "    if pd.isnull(row['control']) \\\n",
    "        or pd.isnull(row['city']) \\\n",
    "        or pd.isnull(row['state']):\n",
    "        return False\n",
    "    elif row['control'] == 'Public':\n",
    "        return True\n",
    "    else: \n",
    "        return False\n",
    "\n",
    "#df['national_rank'].apply(lambda x: x.split(', ')[0]).value_counts()[2:]\n",
    "\n",
    "dfc['is_r1_public'] = dfc.apply(r_1_pub, axis=1)\n",
    "dfc = dfc.drop(columns=['national_rank'])\n",
    "\n",
    "\n",
    "boolstates = pd.Series(dfc[pd.notnull(dfc['state'])].groupby('state')\\\n",
    "                        .count()['institution'] >= 3)\n",
    "statelist = boolstates[boolstates== True].index\n",
    "\n",
    "L = dfc[dfc['state'].isin(statelist.to_list())].\\\n",
    "        groupby('state').mean()['score'].idxmin()\n",
    "\n",
    "propfac = dfc[(dfc['world_rank'] <= 100) & \n",
    "            (dfc['quality_of_faculty'] <= 100)].shape[0]/100\n",
    "\n",
    "L2 = dfc[dfc['national_rank_cleaned'] == 1].\\\n",
    "        set_index('institution')['world_rank'].idxmax()\n",
    "\n",
    "dfc[pd.notnull(dfc['state'])].groupby(['state', 'control']).count()['institution'].reset_index()\n",
    "\n",
    "dfc2 = dfc[pd.notnull(dfc['state'])]\n",
    "ser = dfc2['control'].apply(lambda x: 0 if x == 'Public' else 1)\n",
    "dfc2 = dfc2.assign(control= ser)\n",
    "\n",
    "priv50plus = pd.Series(dfc2.groupby('state').mean()['control'] >= 0.5)\n",
    "privstatenum = priv50plus[priv50plus].size\n",
    "\n",
    "[L, propfac, privstatenum,L2]\n",
    "\n",
    "dfc3 = dfc[['institution', 'nation', 'score']]\n",
    "\n",
    "natsdevs = dfc3.groupby('nation').std(ddof=0)\n",
    "natmeans = dfc3.groupby('nation').mean()\n",
    "\n",
    "def standardize_score(row):\n",
    "    nation = row['nation']\n",
    "    score = row['score']\n",
    "    std = natsdevs.loc[nation]\n",
    "    mean = natmeans.loc[nation]\n",
    "    out = (score-mean)/std\n",
    "    return out\n",
    "copy = dfc3.copy()\n",
    "dfc3 =dfc3.assign(score = copy.apply(standardize_score, axis=1))\n",
    "dfc3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "fp = os.path.join('data', 'universities_unified.csv')\n",
    "df = pd.read_csv(fp)\n",
    "cleaned = clean_universities(df)\n",
    "info = university_info(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 ‚Äì High Standards ‚Ñ¢Ô∏è \n",
    "\n",
    "#### `std_scores_by_nation` \n",
    "\n",
    "Create a function `std_scores_by_nation` that takes in a **cleaned** DataFrame, like the one returned by `clean_universities`, and outputs a DataFrame: \n",
    "- with the same rows as the input, \n",
    "- with three columns: `'institution'`, `'nation'`, and `'score'` (in that order),\n",
    "- where the `'score'` column is **standardized** by `'nation'` - that is, the `'score'`s for each country are converted to standard units, using the mean and standard deviation of the `'score'`s for that country. If a `'score'` is `np.NaN`, leave it as `np.NaN`.\n",
    "    - For a review of standard units, see [Computational and Inferential Thinking](https://www.inferentialthinking.com/chapters/15/1/Correlation).\n",
    "    - ***Hint:*** Use [`groupby` and `transform`](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.transform.html).\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `su_and_spread`\n",
    "\n",
    "Lastly, create a function `su_and_spread` that returns the answers to the following two questions, as a list.\n",
    "\n",
    "****Part 1****\n",
    "\n",
    "Let's compare rankings between two countries ‚Äì the US üá∫üá∏ and Canada üá®üá¶. There are in total $n$ universities in the US and $m$ universities in Canada. Suppose $x_1, x_2, ..., x_n$ are the `'world_rank'`s for US universities in **increasing order**, meaning that $x_1$ is the `'world_rank'` of the \"best\" US university. Similarly, $y_1, y_2, ..., y_m$ are the `'world_rank'`s for Canadian universities, also in increasing order. \n",
    "\n",
    "Suppose we take the aforementioned `'world_rank'`s and sort them together in **increasing order**, e.g. $x_1, x_2, y_1, x_3, ...$. **We define $R$ to be the average of the positions of the $x$ values.**\n",
    "\n",
    "For example, if there are 3 US universities (so $n=3$) and 2 Canadian universities ($m=2$), and\n",
    "  \n",
    "$$x_1 = 1, x_2 = 3, x_3 = 10, \\:\\:\\:\\: y_1 = 5, y_2 = 15$$\n",
    "\n",
    "When we sort the rankings in increasing order, we'd get 1, 3, 5, 10, 15, which correspond to the values $x_1, x_2, y_1, x_3, y_2$. The $x$ values are at positions 1, 2, and 4. Then, $R = \\frac{1 + 2 + 4}{3} = \\frac{7}{3}$. (Note that this is **not** the average of 1, 3, and 10).\n",
    "\n",
    "\n",
    "**Question:** If we believe that US universities in general rank higher than Canadian universities, should $R$ be\n",
    "1. larger than $\\frac{m + n}{2}$?\n",
    "2. smaller than $\\frac{m + n}{2}$?\n",
    "3. equal to $\\frac{m + n}{2}$?\n",
    "\n",
    "\n",
    "Store your answer ‚Äì either 1, 2, or 3 ‚Äì in the first element of `su_and_spread`'s output list. Note that this is a classical example of a non-parametric hypothesis test called a rank test.\n",
    "\n",
    "<br>\n",
    "\n",
    "****Part 2****\n",
    "\n",
    "Which `'nation'` has the largest variation in `'score'`s before standardization? \n",
    "\n",
    "***Note:*** To find the answer to Part 2, you'll need to find the standard deviation of a column. You should use the formula with `n` in the denominator. `numpy`'s `.std()` by default uses that formula, while `pandas`' `.std()` by default uses the formula with `n-1` in the denominator. To force `pandas`' `.std()` to use `n` in the denominator, use the optional argument `ddof=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score    Malaysia\n",
       "dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "natsdevs = dfc3.groupby('nation').std(ddof=0)\n",
    "natsdevs.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not edit this cell -- it is needed for the tests\n",
    "fp = os.path.join('data', 'universities_unified.csv')\n",
    "universities = pd.read_csv(fp)\n",
    "cleaned = clean_universities(universities)\n",
    "universities_out = std_scores_by_nation(cleaned)\n",
    "su_and_spread_out = su_and_spread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Combining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 ‚Äì Making Connections ü§ù\n",
    "\n",
    "A group of students decided to send out a survey to their connections on LinkedIn. Each student asks 1000 of their connections for their first and last name, the company they currently work at, their job title, their email, and the university they attended.\n",
    "\n",
    "**Your job is to combine all the data contained in the files `survey*.csv` (stored within the `data/responses` folder) into a single DataFrame. The number of files and the number of rows in each file may vary, so don't hardcode your answers!** To do so, implement the following two functions.\n",
    "\n",
    "#### `read_linkedin_survey`\n",
    "\n",
    "Create a function `read_linkedin_survey` which takes in a string describing the path to a folder containing `survey*.csv` files and outputs a DataFrame with six columns titled `'first name'`, `'last name'`, `'current company'`, `'job title'`, `'email'`, and `'university'` (in that order) containing the survey information for all files combined. Make sure to reset the index of the combined DataFrame before returning it so that the index is unique. \n",
    "\n",
    "***Hints***:\n",
    "\n",
    "- Take a look at a few of the files in the `responses` folder. You may have to do some data cleaning to combine the DataFrames!\n",
    "\n",
    "- You can list the files in a directory using `os.listdir`.\n",
    "\n",
    "***Note***:\n",
    "\n",
    "- If you are using Windows, do not use \"\\\\\\\\\" to build file paths.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `com_stats`\n",
    "\n",
    "Create a function `com_stats` which takes in a DataFrame returned by `read_linkedin_survey` and returns a list containing, in the following order: \n",
    "- The proportion of people who went to a university with `Ohio` in its name who are some kind of `Nurse`\n",
    "- The number of job titles that **end** in `Engineer`\n",
    "- The job title that has the longest name (there are no ties)\n",
    "- The number of managers (a manager is anyone who has the word `'manager'` in their job title, uppercase or lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fullname\n",
       "Malcolm Kelsall                 marketing manager\n",
       "Devinne Manvelle          human resources manager\n",
       "Pattin Braiden            human resources manager\n",
       "Base Birdseye             human resources manager\n",
       "Redford Shilvock          human resources manager\n",
       "                                ...              \n",
       "Thornie Sowte                  recruiting manager\n",
       "Pauly Berthod                    media manager ii\n",
       "Barnard Drezzer                   project manager\n",
       "Hurleigh Sphinxe                marketing manager\n",
       "Phillipe Dibble     analog circuit design manager\n",
       "Name: job title, Length: 369, dtype: object"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirname = os.path.join('data', 'responses')\n",
    "csvdirlist = os.listdir(dirname)\n",
    "big = pd.DataFrame(pd.read_csv(os.path.join(dirname, csvdirlist[0])))\n",
    "big['fullname'] = big['first name'] + ' ' + big['last name']\n",
    "big\n",
    "for csv in csvdirlist[1:]:\n",
    "    df = pd.read_csv(os.path.join(dirname, csv))\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.columns = df.columns.str.replace('_', ' ')\n",
    "    df['fullname'] = df['first name']  + ' ' +  df['last name']\n",
    "    big = pd.concat([big, df], axis=0)\n",
    " \n",
    "big = big.set_index('fullname')\n",
    "big = big.fillna('')\n",
    "out = big[[\n",
    "        'first name', \n",
    "        'last name', \n",
    "        'current company', \n",
    "        'job title', \n",
    "        'email', \n",
    "        'university'\n",
    "        ]]\n",
    "\n",
    "ohionurses = out[(out['university'].str.contains('Ohio'))\n",
    "    & (out['job title'].str.contains('Nurse'))\n",
    "    ].shape[0]/out[out['university'].str.contains('Ohio')].shape[0]\n",
    "\n",
    "df = out\n",
    "numeng = df[df['job title'].str.endswith('Engineer')].shape[0]\n",
    "x = df['job title']\n",
    "long = pd.DataFrame(\n",
    "        columns = [''],\n",
    "        data= df['job title'].apply(lambda x: len(x)).to_list()).idxmax()\n",
    "df.iloc[int(long)]['job title']\n",
    "man = df['job title'].apply(str.lower)\n",
    "numman = [man[:].str.contains('manager')].shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not edit this cell -- it is needed for the tests\n",
    "dirname = os.path.join('data', 'responses')\n",
    "q4_out = read_linkedin_survey(dirname)\n",
    "stats_out = com_stats(q4_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 ‚Äì Survey Says... üë®‚Äçüë©‚Äçüëß‚Äçüë¶\n",
    "\n",
    "Professor Billy often sends out extra credit surveys asking students for their favorite animals, movies, and other favorite things. These surveys are stored in the `data/extra-credit-surveys` folder. Each file in that folder corresponds to a different survey question (except for `favorite1.csv`, which contains students' names and IDs).\n",
    "\n",
    "Here's how extra credit works:\n",
    "- Each student who has completed at least 50% of the survey questions receives 5 points of extra credit.\n",
    "- If there is at least one survey question that at least 80% of the class answered (e.g. favorite animal), **everyone** in the class receives 1 point of extra credit. This overall class extra credit only applies twice, so if for example 95% of students answer the favorite color survey question and 91% answer the favorite animal survey question, and and 97% answer the favorite movie question, the entire class still receives 2 extra point as a class, not 3.\n",
    "- Note that this means that the most extra credit any student can earn is 7 points.\n",
    "\n",
    "#### `read_student_surveys`\n",
    "\n",
    "Create a function `read_student_surveys` which takes in a string describing the path to a folder containing `favorite*.csv` files and outputs a DataFrame containing all of the survey data combined, indexed by student ID (a value 1-1000).\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `check_credit`\n",
    "\n",
    "Create a function `check_credit` which takes in a DataFrame returned by `read_student_surveys` and outputs a DataFrame indexed by student ID (a value 1-1000) with two columns:\n",
    "- `'name'`, containing the name of each student, and\n",
    "- `'ec'`, containing the number of extra credit points each student earned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>favorite2</th>\n",
       "      <th>favorite3</th>\n",
       "      <th>favorite4</th>\n",
       "      <th>favorite5</th>\n",
       "      <th>favorite6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nathanil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(no genres listed)</td>\n",
       "      <td>Long-crested hawk eagle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joni</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>Euro wallaby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Khaki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prentice</td>\n",
       "      <td>Glass-blower's Children, The (Glasbl√•sarns barn)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown brocket</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Claudette</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(no genres listed)</td>\n",
       "      <td>Peccary, white-lipped</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Obed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Capuchin, brown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fuscia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Valaria</td>\n",
       "      <td>Kung Phooey!</td>\n",
       "      <td>Horror|Mystery|Sci-Fi</td>\n",
       "      <td>Eland, common</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Purple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Gunilla</td>\n",
       "      <td>Angel Heart</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Agouti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Zitella</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shelduck, european</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Jammal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Maroon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Zathura</td>\n",
       "      <td>Drama</td>\n",
       "      <td>African porcupine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name                                         favorite2  \\\n",
       "id                                                                  \n",
       "1      Nathanil                                               NaN   \n",
       "2          Joni                                               NaN   \n",
       "3      Prentice  Glass-blower's Children, The (Glasbl√•sarns barn)   \n",
       "4     Claudette                                               NaN   \n",
       "5          Obed                                               NaN   \n",
       "...         ...                                               ...   \n",
       "996     Valaria                                      Kung Phooey!   \n",
       "997     Gunilla                                       Angel Heart   \n",
       "998     Zitella                                               NaN   \n",
       "999      Jammal                                               NaN   \n",
       "1000        NaN                                           Zathura   \n",
       "\n",
       "                  favorite3                favorite4 favorite5 favorite6  \n",
       "id                                                                        \n",
       "1        (no genres listed)  Long-crested hawk eagle       NaN       Red  \n",
       "2               Documentary             Euro wallaby       NaN     Khaki  \n",
       "3                       NaN            Brown brocket       NaN       Red  \n",
       "4        (no genres listed)    Peccary, white-lipped       NaN    Yellow  \n",
       "5                       NaN          Capuchin, brown       NaN    Fuscia  \n",
       "...                     ...                      ...       ...       ...  \n",
       "996   Horror|Mystery|Sci-Fi            Eland, common       NaN    Purple  \n",
       "997                     NaN                   Agouti       NaN      Blue  \n",
       "998                     NaN       Shelduck, european       NaN       NaN  \n",
       "999                  Comedy                      NaN       NaN    Maroon  \n",
       "1000                  Drama        African porcupine       NaN       Red  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survdir=  os.path.join('data', 'extra-credit-surveys')\n",
    "surveys = os.listdir(survdir)\n",
    "names = pd.DataFrame(pd.read_csv(os.path.join(survdir, surveys[0])))\n",
    "names\n",
    "cols = [x[:-4] for x in surveys][1:]\n",
    "df = pd.DataFrame(index= names['id'], columns=['name'] + cols)\n",
    "df['name'] = names['name']\n",
    "df\n",
    "\n",
    "for survey, col in zip(surveys[1:], cols):\n",
    "    temp = pd.DataFrame(pd.read_csv(os.path.join(survdir, survey)))\n",
    "    temp = temp.set_index('id')\n",
    "    df[col] = temp[temp.columns[0]]\n",
    "\n",
    "outdf = df[cols].notnull().astype('int')\n",
    "outdf['ec'] = outdf.apply(sum, axis=1)\n",
    "\n",
    "i = 0\n",
    "for col in cols:\n",
    "    while i < 2:\n",
    "        if outdf[col].sum()/outdf[col].shape[0]:\n",
    "            outdf['ec'] += 1\n",
    "            i+=1\n",
    "\n",
    "outdf['name'] = df['name']\n",
    "x = outdf[['name', 'ec']]\n",
    "x\n",
    "\n",
    "outdf.loc[:, outdf.columns != 'ec']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not edit this cell -- it is needed for the tests\n",
    "dirname = os.path.join('data', 'extra-credit-surveys')\n",
    "q5_out = read_student_surveys(dirname)\n",
    "check_credit_out = check_credit(q5_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 ‚Äì Paw Patrol üêæ\n",
    "\n",
    "You are analyzing data from a veterinarian clinic. The datasets contain several types of information from the clinic, including its customers (pet owners), pets, available procedures, and procedure history. The column names are self-explanatory. These DataFrames are provided to you:\n",
    "-  `owners` stores the customer information, where every `'OwnerID'` is unique (verify this yourself).\n",
    "-  `pets` stores the pet information. Each pet belongs to a customer in `owners`.\n",
    "-  `procedure_detail` contains a catalog of procedures that are offered by the clinic.\n",
    "-  `procedure_history` has procedure records. Most procedures were given to a pet in `pets`.\n",
    "\n",
    "<br>\n",
    "\n",
    "Implement the following three functions, which each ask you to answer a specific question.\n",
    "\n",
    "#### `most_popular_procedure`\n",
    "\n",
    "What is the most popular `'ProcedureType'` amongst all pets in the `pets` DataFrame? Create a function `most_popular_procedure` that takes in two DataFrames, `pets` and `procedure_history`, and returns the name of the most popular `'ProcedureType'` as a string.\n",
    "\n",
    "Note that some pets are registered but haven't had any procedures performed. Also, some pets that have had procedures done are not registered in `pets`.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `pet_name_by_owner`\n",
    "\n",
    "What is the name of each customer's pet(s)? Create a function `pet_name_by_owner` that takes in two DataFrames, `owners` and `pets`, and returns a Series whose index contains owner first names, and whose values are pet names as **strings**. If an owner has multiple pets, the value corresponding to that owner should instead be a **list of pet names as strings**.\n",
    "\n",
    "Note that owner first names are not necessarily unique, and so the Series you return will not necessarily have a unique index.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `total_cost_per_city`\n",
    "\n",
    "Note that the `owners` DataFrame has a `'City'` column, describing the city in which each pet owner and their pets live. How much did each city spend in total on procedures? Create a function `total_cost_per_city` that takes in four DataFrames, `owners`, `pets`, `procedure_history`, and `procedure_detail`, and returns a Series indexed by `'City'` that describes the total amount that each city has spent on pets' procedures.\n",
    "\n",
    "***Hint:*** At some point, you may have to merge on multiple columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City\n",
       "Ann Arbor            951\n",
       "Center Line          665\n",
       "Commerce             665\n",
       "Detroit              665\n",
       "East Lansing         415\n",
       "Farmington Hills     236\n",
       "Flint                637\n",
       "Grand Rapids        4233\n",
       "Kalamazoo            236\n",
       "Lansing             1995\n",
       "Livonia              665\n",
       "Marquette           3325\n",
       "Michigan Center      665\n",
       "Plymouth             665\n",
       "Pontiac             1995\n",
       "Roseville            665\n",
       "Saint Charles        665\n",
       "Southfield          3962\n",
       "Warren               665\n",
       "Wayne                665\n",
       "Name: Price, dtype: int64"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "owners = pd.read_csv('data/pets/Owners.csv')\n",
    "pets = pd.read_csv('data/pets/Pets.csv')\n",
    "procedure_history = pd.read_csv('data/pets/ProceduresHistory.csv')\n",
    "procedure_detail = pd.read_csv('data/pets/ProceduresDetails.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "procedure_history = procedure_history.merge(procedure_detail, on='ProcedureSubCode')[['PetID', 'ProcedureSubCode', 'Price']]\n",
    "\n",
    "procedure_history = procedure_history.groupby('PetID').sum()\n",
    "\n",
    "petsproc = pets.merge(procedure_history, on='PetID')\n",
    "\n",
    "petsproc = petsproc.merge(owners, on= 'OwnerID', how='left')[['City', 'Price']]\n",
    "\n",
    "out = petsproc.groupby('City').sum()['Price']\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OwnerID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Surname</th>\n",
       "      <th>StreetAddress</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>StateFull</th>\n",
       "      <th>ZipCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6049</td>\n",
       "      <td>Debbie</td>\n",
       "      <td>Metivier</td>\n",
       "      <td>315 Goff Avenue</td>\n",
       "      <td>Grand Rapids</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>49503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2863</td>\n",
       "      <td>John</td>\n",
       "      <td>Sebastian</td>\n",
       "      <td>3221 Perry Street</td>\n",
       "      <td>Davison</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>48423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3518</td>\n",
       "      <td>Connie</td>\n",
       "      <td>Pauley</td>\n",
       "      <td>1539 Cunningham Court</td>\n",
       "      <td>Bloomfield Township</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>48302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3663</td>\n",
       "      <td>Lena</td>\n",
       "      <td>Haliburton</td>\n",
       "      <td>4217 Twin Oaks Drive</td>\n",
       "      <td>Traverse City</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>49684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1070</td>\n",
       "      <td>Jessica</td>\n",
       "      <td>Velazquez</td>\n",
       "      <td>3861 Woodbridge Lane</td>\n",
       "      <td>Southfield</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>48034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2103</td>\n",
       "      <td>Robert</td>\n",
       "      <td>Adkins</td>\n",
       "      <td>2102 Perry Street</td>\n",
       "      <td>Flint</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>48548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>4464</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>Nielson</td>\n",
       "      <td>4876 Tully Street</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>48219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>5737</td>\n",
       "      <td>Alden</td>\n",
       "      <td>McMiller</td>\n",
       "      <td>3111 Tennessee Avenue</td>\n",
       "      <td>Pontiac</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>48342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>9850</td>\n",
       "      <td>Gary</td>\n",
       "      <td>Snider</td>\n",
       "      <td>3139 Nash Street</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>48227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1546</td>\n",
       "      <td>Joseph</td>\n",
       "      <td>Blow</td>\n",
       "      <td>556 D Street</td>\n",
       "      <td>Southfield</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>48075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    OwnerID     Name     Surname          StreetAddress                 City  \\\n",
       "0      6049   Debbie    Metivier        315 Goff Avenue         Grand Rapids   \n",
       "1      2863     John   Sebastian      3221 Perry Street              Davison   \n",
       "2      3518   Connie      Pauley  1539 Cunningham Court  Bloomfield Township   \n",
       "3      3663     Lena  Haliburton   4217 Twin Oaks Drive        Traverse City   \n",
       "4      1070  Jessica   Velazquez   3861 Woodbridge Lane           Southfield   \n",
       "..      ...      ...         ...                    ...                  ...   \n",
       "84     2103   Robert      Adkins      2102 Perry Street                Flint   \n",
       "85     4464   Daniel     Nielson      4876 Tully Street              Detroit   \n",
       "86     5737    Alden    McMiller  3111 Tennessee Avenue              Pontiac   \n",
       "87     9850     Gary      Snider       3139 Nash Street              Detroit   \n",
       "88     1546   Joseph        Blow           556 D Street           Southfield   \n",
       "\n",
       "   State StateFull  ZipCode  \n",
       "0     MI  Michigan    49503  \n",
       "1     MI  Michigan    48423  \n",
       "2     MI  Michigan    48302  \n",
       "3     MI  Michigan    49684  \n",
       "4     MI  Michigan    48034  \n",
       "..   ...       ...      ...  \n",
       "84    MI  Michigan    48548  \n",
       "85    MI  Michigan    48219  \n",
       "86    MI  Michigan    48342  \n",
       "87    MI  Michigan    48227  \n",
       "88    MI  Michigan    48075  \n",
       "\n",
       "[89 rows x 8 columns]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pets = pd.read_csv('data/pets/Pets.csv')\n",
    "hist = pd.read_csv('data/pets/ProceduresHistory.csv')\n",
    "hist\n",
    "temp = pets.merge(hist, right_on= 'PetID', \n",
    "            left_on='PetID')[['PetID', 'ProcedureType']].set_index('PetID')\n",
    "\n",
    "hist = hist.set_index('PetID')\n",
    "\n",
    "pd.concat([hist, temp])['ProcedureType'].value_counts(0).idxmax()\n",
    "\n",
    "\n",
    "\n",
    "owners\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lates = [75]\n",
    "n = 2\n",
    "\n",
    "sorted(lates)[::-1] #O(nlogn)\n",
    "\n",
    "ec = [50,30,20] + (n-3)*[10]\n",
    "out = 0\n",
    "i = n\n",
    "while i > 0:\n",
    "    if lates[0] > ec[0]:\n",
    "        out+=lates[0]\n",
    "        if len(lates) == 1:\n",
    "            lates = n*[0]\n",
    "        else:\n",
    "            lates = lates[1:]\n",
    "        i-=1\n",
    "    else:\n",
    "        out += ec[0]\n",
    "        ec = ec[1:]\n",
    "        i-=1\n",
    "    \n",
    "\n",
    "out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Surname</th>\n",
       "      <th>StreetAddress</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>StateFull</th>\n",
       "      <th>ZipCode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OwnerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6049</th>\n",
       "      <td>Debbie</td>\n",
       "      <td>Metivier</td>\n",
       "      <td>315 Goff Avenue</td>\n",
       "      <td>Grand Rapids</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>49503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2863</th>\n",
       "      <td>John</td>\n",
       "      <td>Sebastian</td>\n",
       "      <td>3221 Perry Street</td>\n",
       "      <td>Davison</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>48423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3518</th>\n",
       "      <td>Connie</td>\n",
       "      <td>Pauley</td>\n",
       "      <td>1539 Cunningham Court</td>\n",
       "      <td>Bloomfield Township</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>48302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3663</th>\n",
       "      <td>Lena</td>\n",
       "      <td>Haliburton</td>\n",
       "      <td>4217 Twin Oaks Drive</td>\n",
       "      <td>Traverse City</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>49684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>Jessica</td>\n",
       "      <td>Velazquez</td>\n",
       "      <td>3861 Woodbridge Lane</td>\n",
       "      <td>Southfield</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>48034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>Robert</td>\n",
       "      <td>Adkins</td>\n",
       "      <td>2102 Perry Street</td>\n",
       "      <td>Flint</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>48548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4464</th>\n",
       "      <td>Daniel</td>\n",
       "      <td>Nielson</td>\n",
       "      <td>4876 Tully Street</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>48219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5737</th>\n",
       "      <td>Alden</td>\n",
       "      <td>McMiller</td>\n",
       "      <td>3111 Tennessee Avenue</td>\n",
       "      <td>Pontiac</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>48342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9850</th>\n",
       "      <td>Gary</td>\n",
       "      <td>Snider</td>\n",
       "      <td>3139 Nash Street</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>48227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>Joseph</td>\n",
       "      <td>Blow</td>\n",
       "      <td>556 D Street</td>\n",
       "      <td>Southfield</td>\n",
       "      <td>MI</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>48075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name     Surname          StreetAddress                 City  \\\n",
       "OwnerID                                                                    \n",
       "6049      Debbie    Metivier        315 Goff Avenue         Grand Rapids   \n",
       "2863        John   Sebastian      3221 Perry Street              Davison   \n",
       "3518      Connie      Pauley  1539 Cunningham Court  Bloomfield Township   \n",
       "3663        Lena  Haliburton   4217 Twin Oaks Drive        Traverse City   \n",
       "1070     Jessica   Velazquez   3861 Woodbridge Lane           Southfield   \n",
       "...          ...         ...                    ...                  ...   \n",
       "2103      Robert      Adkins      2102 Perry Street                Flint   \n",
       "4464      Daniel     Nielson      4876 Tully Street              Detroit   \n",
       "5737       Alden    McMiller  3111 Tennessee Avenue              Pontiac   \n",
       "9850        Gary      Snider       3139 Nash Street              Detroit   \n",
       "1546      Joseph        Blow           556 D Street           Southfield   \n",
       "\n",
       "        State StateFull  ZipCode  \n",
       "OwnerID                           \n",
       "6049       MI  Michigan    49503  \n",
       "2863       MI  Michigan    48423  \n",
       "3518       MI  Michigan    48302  \n",
       "3663       MI  Michigan    49684  \n",
       "1070       MI  Michigan    48034  \n",
       "...       ...       ...      ...  \n",
       "2103       MI  Michigan    48548  \n",
       "4464       MI  Michigan    48219  \n",
       "5737       MI  Michigan    48342  \n",
       "9850       MI  Michigan    48227  \n",
       "1546       MI  Michigan    48075  \n",
       "\n",
       "[89 rows x 7 columns]"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "owners = pd.read_csv('data/pets/Owners.csv')\n",
    "pets = pd.read_csv('data/pets/Pets.csv')\n",
    "multipletowners = set(pets[pets['OwnerID'].duplicated(keep=False)]['OwnerID'].to_list())\n",
    "owners = owners.set_index('OwnerID')\n",
    "\n",
    "out = pd.Series(dtype='object')\n",
    "out\n",
    "\n",
    "pets[pets['OwnerID']==5508]['Name'].to_list()\n",
    "\n",
    "def helper(key):\n",
    "    if key in multipletowners:\n",
    "        return (owners.loc[key]['Name'], \n",
    "                pets[pets['OwnerID']==key]['Name'].to_list())\n",
    "    else:\n",
    "        return (owners.loc[key]['Name'],\n",
    "                pets[pets['OwnerID']==key]['Name'].to_list()[0])\n",
    "    \n",
    "\n",
    "tuplist = pets['OwnerID'].apply(helper).to_list()\n",
    "idx, values = zip(*tuplist)\n",
    "out = pd.Series(values, idx)\n",
    "\n",
    "owners\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not edit this cell -- it is needed for the tests\n",
    "pets_fp = os.path.join('data', 'pets', 'Pets.csv')\n",
    "procedure_history_fp = os.path.join('data', 'pets', 'ProceduresHistory.csv')\n",
    "owners_fp = os.path.join('data', 'pets', 'Owners.csv')\n",
    "procedure_detail_fp = os.path.join('data', 'pets', 'ProceduresDetails.csv')\n",
    "pets = pd.read_csv(pets_fp)\n",
    "procedure_history = pd.read_csv(procedure_history_fp)\n",
    "owners = pd.read_csv(owners_fp)\n",
    "procedure_detail = pd.read_csv(procedure_detail_fp)\n",
    "\n",
    "out_01 = most_popular_procedure(pets, procedure_history)\n",
    "out_02 = pet_name_by_owner(owners, pets)\n",
    "out_03 = total_cost_per_city(owners, pets, procedure_history, procedure_detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You're done! üèÅ\n",
    "\n",
    "Submit your `.py` file to Gradescope. Note that you only need to submit the `.py` file; this notebook should not be uploaded.\n",
    "\n",
    "Before submitting, you should ensure that all of your work is in the `.py` file. You can do this by running the doctests below, which will verify that your work passes the public tests **and** that your work is in the `.py` file. Run the cell below; you should see no output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m doctest lab.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, `grader.check_all()` will verify that your work passes the public tests. Ultimately, the Gradescope autograder is also going to run `grader.check_all()`, so you should ensure these pass as well (which they should if the doctests above passed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "nteract": {
   "version": "0.15.0"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> set(car_null_hypoth()) <= set(range(1, 7))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> set(car_alt_hypoth()) <= set(range(1, 7))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> set(car_test_stat()) <= set(range(1, 5))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> car_p_value() in set(range(1, 6))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> cleaned.shape[0] == df.shape[0]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> cleaned['nation'].nunique() == 59\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> len(info) == 4\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> all([isinstance(x, y) for x, y in zip(info, [str, float, int, str])])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> (info[1] >= 0) & (info[1] <= 1)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> universities_out.shape[0] == cleaned.shape[0]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> all(universities_out.columns == ['institution', 'nation', 'score'])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> np.all(abs(universities_out.select_dtypes(include='number').mean()) < 10**-7)  # standard units should average to 0!\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> len(su_and_spread_out) == 2\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> su_and_spread_out[0] in np.arange(1, 4)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(su_and_spread_out[1], str)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(q4_out, pd.DataFrame) == True\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> len(q4_out) == 5000\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> try:\n...     read_linkedin_survey('nonexistentfile')\n... except FileNotFoundError:\n...     print(True)\nTrue\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> len(stats_out) == 4\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> isinstance(stats_out[0], float)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> isinstance(stats_out[2], str)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(q5_out, pd.DataFrame)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q5_out.shape == (1000, 6)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> try:\n...     read_student_surveys('nonexistentfile')\n... except FileNotFoundError:\n...     print(True)\nTrue\n",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> check_credit_out.shape == (1000, 2)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> check_credit_out['ec'].max() == 6\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(out_01, str)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> len(out_02) == len(owners)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> 'Sarah' in out_02.index\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> 'Cookie' in out_02.values\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> set(out_03.index) <= set(owners['City'])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "19b17eba0dbd5e4b8827ab8a6192fc0dff7c2985f63f4f278d5b971ef380745d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
