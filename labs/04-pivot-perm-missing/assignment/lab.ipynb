{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 – Pivot Tables, Permutation Testing, and Missing Values\n",
    "\n",
    "## DSC 80, Fall 2022\n",
    "\n",
    "### Due Date: Monday, October 24th at 11:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and Markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding will be done in an accompanying `lab.py` file that is imported into the current notebook.\n",
    "\n",
    "Labs and programming assignments will be graded in (at most) two ways:\n",
    "1. The functions and classes in the accompanying `lab.py` file will be tested (a la DSC 20),\n",
    "2. The notebook may be graded (if it contains free response questions or asks you to draw plots).\n",
    "\n",
    "**Do not change the function names in the `*lab.py` file!**\n",
    "- The functions in the `lab.py` file are how your assignment is graded, and they are graded by their name.\n",
    "- If you changed something you weren't supposed to, just use git to revert! Ask us if you need help with this, or google around for `git revert`.\n",
    "\n",
    "**Tips for working in the notebook**:\n",
    "- The notebooks serve to present the questions and give you a place to present your results for later review.\n",
    "- The notebooks in *lab assignments* are not graded (only the `lab.py` file is submitted and graded).\n",
    "- The notebook serves as a nice environment for 'pre-development' and experimentation before designing your function in your `lab.py` file. You can write code here, but make sure that all of your real work is in the `lab.py` file.\n",
    "\n",
    "**Tips for developing in the `lab.py` file**:\n",
    "- Do not change the function names in the starter code; grading is done using these function names.\n",
    "- Do not change the docstrings in the functions. These are there to tell you if your work is on the right track!\n",
    "- You are encouraged to write your own additional helper functions to solve the lab! \n",
    "- Always document your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing code from `lab.py`\n",
    "\n",
    "* We import our `lab.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "from datetime import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 0 – Mid-Quarter Survey 🙋\n",
    "\n",
    "Course staff, along with the Data Science Student Representatives, have put together a mid-quarter survey that will allow you to share feedback on your experience in DSC 80 so far. It is **entirely anonymous**, so we encourage you to be honest.\n",
    "\n",
    "<br>\n",
    "\n",
    "<center><b><a href=https://forms.gle/5Bd64352PArTH7Z89>Click here to access the mid-quarter survey.</a></b></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "We'd like to have as many students as possible in the class fill out the survey. **As such, if 80% of the class fills out this survey before the Midterm Exam, then everyone will earn an extra point on the Midterm Exam.** The survey will close before the Midterm Exam. \n",
    "\n",
    "We really appreciate your feedback, thanks! 😊"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Time Series Data\n",
    "\n",
    "Imagine that you own an online store and you'd like to monitor the visits to your site. You've collected some data that you store in `data/login_table.csv`. It contains the information about different login dates and times for different users. Some users are unique, some visited your store multiple times.\n",
    "\n",
    "You need to answer a few questions below in order to understand the login patters of your users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 – Passwords 🔑\n",
    "\n",
    "Write a function `latest_login` which takes in a DataFrame like `login` and outputs a DataFrame indexed by `'Login Id'`, counting the number of logins that occurs at the prime time for each user. Prime time is as it says: from 4 PM to 8 PM (inclusive). The DataFrame should have just one column, named `'Time'`.\n",
    "\n",
    "For example, if a user logs in at 5 PM one day, 1 PM another day, and again at 8 PM, then her total number of prime-time log-ins is 2. Note that the values in your returned DataFrame should only include counts, not datetime objects.\n",
    "\n",
    "***Note:*** You do not need to use Python's `datetime` module – instead, use the built-in `pandas` methods for working with times that we introduced in [Lecture 6](https://github.com/dsc-courses/dsc80-2022-fa/blob/main/lectures/06-combining/notebook/lecture.ipynb) (though you will need to do a bit more research to fully answer the question). Do not use a `for`-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "fp = os.path.join('data', 'login_table.csv')\n",
    "login = pd.read_csv(fp)\n",
    "q1_result = latest_login(login)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 – Return Users 🔁\n",
    "\n",
    "As a site owner, you would like to find your most enthusiastic users -- the ones who return to your site most frequently. You've noticed that there are users who have several logins and users who logged in only once. You are interested in finding the number of logins *per day* for each user.\n",
    "\n",
    "To do this, you can assume that today is  January 5, 2018. The first login date of users is the first day of their membership in the site, and you can assume that they are still a member today. For simplicity, you only need to count full days that a user has been a member. For example, if a user's first login was 12 days and 5 hours ago, you can say that they have been a user for 12 days. \n",
    "\n",
    "Write a function `calculate_frequency` which takes in a DataFrame like `login` and outputs a Series containing the number of logins per day for each user. Your Series should have `'Login Id'`s in its index, and the frequencies as its values. The order of users in the index is arbitrary.\n",
    "\n",
    "**IMPORTANT**: No Loops Allowed.\n",
    "\n",
    "***Hint:*** Can you write a custom aggregator that allows you to do this with just one `.groupby`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_frequency(login):\n",
    "    \"\"\"\n",
    "    Calculates the the login frequency for each user.\n",
    "    :param login: a DataFrame with login information but without unique IDs\n",
    "    :return: a Series, indexed by Login ID, containing \n",
    "    the login frequency for each user.\n",
    "    >>> fp = os.path.join('data', 'login_table.csv')\n",
    "    >>> login = pd.read_csv(fp)\n",
    "    >>> freq = count_frequency(login)\n",
    "    >>> len(freq)\n",
    "    433\n",
    "    >>> np.isclose(freq.loc[466], 0.24517906336088155)\n",
    "    True\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "fp = os.path.join('data', 'login_table.csv')\n",
    "login = pd.read_csv(fp)\n",
    "q2_result = count_frequency(login)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Pivot Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 – Summarizing Sales 💰\n",
    "\n",
    "Recall from [Lecture 5](https://github.com/dsc-courses/dsc80-2022-fa/blob/main/lectures/05-grouping/notebook/lecture.ipynb), a pivot table allows you to aggregate the entries in a DataFrame based on two categorical columns. In this question, you are given a simple dataset, `data/sales.csv`, and are asked to solve a few simple problems using the `pivot_table` method.  \n",
    "\n",
    "We have provided the outline for your DataFrames, but yours may have a different number of rows and columns and different values.\n",
    "\n",
    "#### `total_seller`\n",
    "\n",
    "Write a function `total_seller` that takes in the `sales` DataFrame and returns a DataFrame that contains the total sales for each seller, indexed by `'Name'`. There should not be any `NaN`s.\n",
    "\n",
    "***Note:*** You may be able to implement `total_seller` without using `pivot_table`.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>Total</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Name</th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>Jones</th>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Smith</th>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Trump</th>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `product_name`\n",
    "\n",
    "Write a function `product_name` that takes in the `sales` DataFrame and returns a DataFrame that contains the total sales for each seller, indexed by `'Product'`. Do not fill in `NaN`s.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Name</th>\n",
    "      <th>Jones</th>\n",
    "      <th>Smith</th>\n",
    "      <th>Trump</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Product</th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>boat</th>\n",
    "      <td>NaN</td>\n",
    "      <td>NaN</td>\n",
    "      <td>0.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>book</th>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>hotel</th>\n",
    "      <td>NaN</td>\n",
    "      <td>NaN</td>\n",
    "      <td>0.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>pen</th>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>ruler</th>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>NaN</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `count_product`\n",
    "\n",
    "Write a function `count_product` that takes in the `sales` DataFrame and returns a DataFrame that contains the total number of items sold product-wise and name-wise per date. Replace `NaN`s with 0s. Don't reset the index after pivoting.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th></th>\n",
    "      <th>Date</th>\n",
    "      <th>01.01.2012</th>\n",
    "      <th>02.20.2013</th>\n",
    "      <th>02.25.2015</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Product</th>\n",
    "      <th>Name</th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>boat</th>\n",
    "      <th>Trump</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th rowspan=\"3\" valign=\"top\">book</th>\n",
    "      <th>Jones</th>\n",
    "      <td>0</td>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Smith</th>\n",
    "      <td>1</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Trump</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>hotel</th>\n",
    "      <th>Trump</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `total_by_month`\n",
    "\n",
    "Write a function `total_by_month` that takes in the `sales` DataFrame and returns a pivot table that contains the total sales name-wise, product-wise per month. Replace `NaN`s with 0s. Don't reset the index after pivoting.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th></th>\n",
    "      <th>Month</th>\n",
    "      <th>February</th>\n",
    "      <th>January</th>\n",
    "      <th>July</th>\n",
    "      <th>March</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Name</th>\n",
    "      <th>Product</th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th rowspan=\"3\" valign=\"top\">Jones</th>\n",
    "      <th>book</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>pen</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>ruler</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th rowspan=\"3\" valign=\"top\">Smith</th>\n",
    "      <th>book</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>pen</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>ruler</th>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "***Note:*** [Here](https://jakevdp.github.io/PythonDataScienceHandbook/03.09-pivot-tables.html) is another great resource that provides an overview of `pivot_table` with many examples from the Titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "fp = os.path.join('data', 'sales.csv')\n",
    "sales = pd.read_csv(fp)\n",
    "q3_total_seller_out = total_seller(sales)\n",
    "q3_product_name_out = product_name(sales)\n",
    "q3_product_count_out = count_product(sales)\n",
    "q3_total_by_month_out = total_by_month(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Permutation Testing\n",
    "\n",
    "[Skittles](https://en.wikipedia.org/wiki/Skittles_(confectionery)) 🍬 are made in two locations in the United States: Yorkville, Illinois and Waco, Texas. In these factories, Skittles of different colors are made separately by different machines and combined/packaged into bags for sale. The **tab-separated file** `data/skittles.tsv` contains the contents of 468 bags of Skittles.\n",
    "\n",
    "Throughout this question, we will compare the color distribution of Skittles between bags made in the Yorkville factory and bags made in the Waco factory. Most people have preferences for their favorite flavor and there is a surprising amount of variation among the distribution of flavors in each bag.\n",
    "\n",
    "Look at the variation by bag in the dataset below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "skittles_fp = os.path.join('data', 'skittles.tsv')\n",
    "skittles = pd.read_csv(skittles_fp, sep='\\t')\n",
    "skittles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "skittles.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 – Orange Skittles 🟠\n",
    "\n",
    "First, you will investigate if the machine that mixes together the Skittles of different colors might favor one color over another. Use a permutation test to assess whether, on average, bags made in Yorkville have the same number of orange skittles as bags made in Waco. Do this by implementing the functions described below.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `diff_of_median_proportions`\n",
    "\n",
    "Create a function `diff_of_median_proportions` that takes in a DataFrame like `skittles` and returns the **absolute difference** between the **median proportion** of orange Skittles per bag from Yorkville and the **median proportion** of orange Skittles per bag from Waco.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `simulate_null`\n",
    "\n",
    "Create a function `simulate_null` that takes in a DataFrame like `skittles` and returns one simulated instance of the test statistic under the null hypothesis. Note that this will involve shuffling!\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `pval_color`\n",
    "\n",
    "Create a function `pval_color` that takes in a DataFrame like `skittles` and calculates the p-value for the permutation test using 1000 trials.\n",
    "\n",
    "<br>\n",
    "\n",
    "Plot the observed statistic, along with the histogram for the simulated distribution, to check your work.\n",
    "\n",
    "***Note:*** In all functions, the default argument for `col` is `'orange'`. Your functions should still work for any color so that you can call it in later questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "# cell may take about 1-2 minutes to execute to completion\n",
    "skittles_fp = os.path.join('data', 'skittles.tsv')\n",
    "skittles = pd.read_csv(skittles_fp, sep='\\\\t', engine='python')\n",
    "q4_diff_of_median_proportions_out = diff_of_median_proportions(skittles)\n",
    "q4_simulate_null_out = simulate_null(skittles)\n",
    "q4_many_diffs = np.array([simulate_null(skittles) for _ in range(100)])\n",
    "q4_pval_out = pval_color(skittles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 – Generalizing to all colors 🔴🟠🟡🟢🟣\n",
    "\n",
    "While your `pval_color` function used a default color of `'orange'`, it should also work for all other colors of Skittles, meaning you can run the same permutation test from Question 4 on all colors of Skittles. Call `pval_color` on all colors of Skittles to find which colors differ the most between the two locations on average. \n",
    "\n",
    "Then, create a function `ordered_colors` that returns a list of five ordered pairs, each of the form `('color', p_value)`. For example, your list might look like `[('pink', 0.000), ('brown', 0.025), ...]`. \n",
    "\n",
    "The list should be **hard-coded**, meaning that you should run your permutation tests in your notebook, not in your `.py` file. The list should also be sorted in **increasing order of p-value**. Make sure your p-values are rounded to **3 decimal places**.\n",
    "\n",
    "Even though there is randomness in the color composition in each bag, this list gives the likelihood that the machines have a systematic, meaningful, difference in how they blend the colors in each bag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "q5_out = ordered_colors()\n",
    "q5_colors = {'green', 'orange', 'purple', 'red', 'yellow'}\n",
    "q5_test_colors = [x[0] for x in q5_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "q5_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 – Overall distributions 🏭\n",
    "\n",
    "Now, suppose you would like to assess whether the two locations make similar amounts of each color overall. That is, suppose we:\n",
    "* Combine and count up all the Skittles of each color that were made in Yorkville (e.g. 14303 total red skittles, 9091 total green skittles, etc.)\n",
    "* Combine and count up all the Skittles of each color that were made in Waco.\n",
    "\n",
    "**Are these distributions of colors similar?** Is the variation among the bags due to each factory making different amounts of each color?\n",
    "\n",
    "Use a permutation test to assess whether the distribution of colors of Skittles made in Yorkville is statistically significantly different than those made in Waco. Set a significance level of 0.01 and determine whether you can reject a null hypothesis that answers the question above using a permutation test with 1000 trials. For your test statistic, use the **total variation distance (TVD)**.\n",
    "\n",
    "Refer to [Lecture 7](https://github.com/dsc-courses/dsc80-2022-fa/blob/main/lectures/07-permutation/notebook/lecture.ipynb) to see an example of a [permutation test](https://www.inferentialthinking.com/chapters/12/Comparing_Two_Samples.html) that uses the [TVD](https://inferentialthinking.com/chapters/11/2/Multiple_Categories.html) as the test statistic. Some guidance:\n",
    "\n",
    "- Our previous permutation tests have compared the median proportion of (say) orange Skittles in Yorkville bags to the median proportion number of orange Skittles in Waco bags. The role of shuffling was to randomly assign bags to Yorkville and Waco.\n",
    "- In this permutation test, we are **still** shuffling to randomly assign bags to Yorkville and Waco. The only difference is that after we randomly assign each bag to a factory, we will compute the distribution of colors amongst the two factories and find the TVD between those two distributions.\n",
    "\n",
    "**Your job:** Create a function `same_color_distribution` that takes in no arguments and outputs a hard-coded **tuple** with the p-value and whether you `'Fail to Reject'` or `'Reject'` the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "q6_out = same_color_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7 – Permutation testing vs. hypothesis testing 🧪\n",
    "\n",
    "In each of the following scenarios, decide  whether  a  permutation test is appropriate to determine if there is a  significant difference between the quantities described. If a permutation test is appropriate, mark `'P'`. Otherwise, mark `'H'`.\n",
    "\n",
    "Record your answers in the function `perm_vs_hyp` that outputs a list of length 5, containing the values `'P'` and `'H'`.\n",
    "\n",
    "1. Compare the DSC 80 pass rate between second years and third years who take the class.\n",
    "2. Compare the proportion of Data Science majors who have completed DSC 80 and the proportion of Data Science minors who have completed DSC 80.\n",
    "3. Compare the proportion of students who have iPhones to the proportion of students who have Android phones (for simplicity, assume that all students either have an iPhone or an Android).\n",
    "4. In DSC 80, we ask all students whether they liked DSC 40A or DSC 40B more. Compare the proportion of students who preferred DSC 40A to the proportion who preferred DSC 40B.\n",
    "5. Compare the attendance rate of classes that play music before class vs. classes that do not play music before class.\n",
    "\n",
    "***Hint:*** Think about the type of data you would collect in each case, and how you would simulate new data under the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "q7_out = perm_vs_hyp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Types of Missingness\n",
    "\n",
    "First, let's recap the different mechanisms of missingness we studied in lecture.\n",
    "\n",
    "### Missing by Design (MD)\n",
    "- The missing field is deliberately missing. The missing field is deliberately set to null or not collected (hence, \"missing by design\").\n",
    "- The missingness can be exactly predicted when a column will be null, with only knowledge of the other columns using a function of the rows of the dataset.\n",
    "\n",
    "### Missing Completely at Random (MCAR)\n",
    "- The missingness of missing value isn't related to the actual, unreported value itself, nor the values in any other fields. The missingness is not systematic.\n",
    "- The missingness is unconditionally uniform across rows. MCAR doesn't bias the observed data.\n",
    "- There is no relationship between the missing data and the any of the other data, observed or missing.\n",
    "\n",
    "### Missing at Random (MAR)\n",
    "- The missingness of the missing value has nothing to do with the value itself, but may be related to another field.\n",
    "- The missingness is uniform across rows, perhaps conditional on another column. MAR biases the observed data, but is fixable.\n",
    "- There is a systematic relationship between the missing values and the observed data (but not the missing values themselves).\n",
    "- Difference between MD and MAR: If you can *exactly/always* determine missingness using the other columns, the missingness is MD. If there is just some sort of systematic relationship between the missing columns/values and other columns/values that may help us predict missingness, the missingness is MAR.\n",
    "\n",
    "### Non-Ignorable (NI, aka NMAR)\n",
    "- The missingness of the missing value is related to the actual, unreported value.\n",
    "- NI biases the observed data in unobservable ways.\n",
    "- There is relationship between the propensity of a value to be missing and its value.\n",
    "- ***Note:*** In lecture, we referred to non-ignorable missingness as \"not missing at random (NMAR)\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8 – After-purchase surveys 🛒\n",
    "\n",
    "You run a small e-commerce website and send surveys out to customers after they purchase an item from your store. The survey asks whether the customer is satisfied with their purchase (\"Yes\" or \"No\"). Below, you are presented with possible datasets, each of which contains a column `'satisfied'` as described above, as well as a `'customer_id'` number corresponding to the customer and an `'item'` column describing the item that the customer purchased. **The column `'satisfied'` is missing data.**\n",
    "\n",
    "For each of the following datasets, label the column `'satisfied'` as being `'MD'`, `'MCAR'`, `'MAR'`, or `'NI'`.\n",
    "\n",
    "1. The dataset consists only of the columns `'customer_id'` and `'satisfied'`.\n",
    "2. The dataset contains the `'customer_id'` of every customer with an account, even if they didn't make a purchase. Also, in this case, you notice everyone who was sent a survey filled it out.\n",
    "3. The dataset contains a column specifying if the user later returned the item.\n",
    "4. The dataset contains a column with the serial number for the item purchased.\n",
    "5. The dataset contains a column with the price of the item purchased.\n",
    "\n",
    "Record your answers in the function `after_purchase` that outputs a list of length 5, containing the values `'MD'`, `'MCAR'`, `'MAR'`, or `'NI'`. For some questions there may be multiple good answers, but there is generally one answer that is \"best\". If you are unsure, ask a tutor, but be prepared to provide justification for whichever answer(s) you think might be right.\n",
    "\n",
    "***Disclaimer:*** We know that this lab has no hidden tests, and so it is possible to just look at the correct answers by running `grader.check`. This is not a good idea – you should really think about all of the questions here, since similar questions will be on the Midterm Exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "q8_out = after_purchase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9 – Miscellaneous missingness questions 🕵️\n",
    "\n",
    "In each of the following scenarios, choose the best answer out of the missingness types: `'MD'`, `'MCAR'`, `'MAR'`, and `'NI'`. Store your answers in a list of length 5, and have the function `multiple_choice` return that list.\n",
    "\n",
    "1. UCSD has recently adopted GrubHub as the food pre-ordering app for campus restaurants, so you can order your food ahead of time and stop by before your next class. In a DataFrame of GrubHub app orders, which contains information such as `'restaurant'`, `'name'`, `'items'`, and `'total'`, the column `'delivery_address'` is often missing for UCSD students. Which is the most likely missingness mechanism for this column?\n",
    "\n",
    "\n",
    "2. In a database of student records that records student profile data, such as `'name'`, `'home_address'`, `'ethnicity'`, etc., sometimes the `'middle_name'` column is missing. Which is the most likely missingness mechanism for this column?\n",
    "\n",
    "\n",
    "3. The UCSD Club Basketball team creates a signup sheet for potential new members. The sheet contains the columns `'full_name'`, `'year'`, `'email'`, `'favorite_sports'`, `'number_of_sports_played'`, and `'sports_previously_played'`. The team president notices that many students left the `'sports_previously_played'` column blank. Which is the most likely missingness mechanism for this column?\n",
    "\n",
    "\n",
    "4. After the 2022 Sun God Festival, Associated Students sends out a survey to all students about whether their expectations for the 2022 Sun God Festival were met, with all questions being optional. They notice that many students left the \"Were you satisfied with the 2022 Sun God Festival?\" question blank. Which is the most likely missingness mechanism for answers to this question?\n",
    "\n",
    "\n",
    "5. UCSD has been using a two-factor authentication system, DUO, since October 16th, 2019. When using DUO, all UCSD accounts are assigned a unique code. UCSD's Service Desk, who maintains DUO, has a database that stores each user's code and their phone number, which users must provide when they sign up for DUO. They notice that many phone numbers are missing. Which is the most likely missingness mechanism for phone numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "q9_out = multiple_choice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You're done! 🏁\n",
    "\n",
    "Submit your `lab.py` file to Gradescope. Note that you only need to submit the `lab.py` file; this notebook should not be uploaded.\n",
    "\n",
    "Before submitting, you should ensure that all of your work is in the `lab.py` file. You can do this by running the doctests below, which will verify that your work passes the public tests **and** that your work is in the `lab.py` file. Run the cell below; you should see no output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m doctest lab.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, `grader.check_all()` will verify that your work passes the public tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "nteract": {
   "version": "0.15.0"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(q1_result) == 433\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q1_result.loc[381, \"Time\"] > 7\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q1_result.loc[457, 'Time'] == 4\nTrue",
         "failure_message": "check user 457",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q1_result.loc[458, 'Time'] > 50\nTrue",
         "failure_message": "check user 457",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> len(set(q1_result.index)) == 433\nTrue",
         "failure_message": "check number of unique users",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q1_result.loc[381, 'Time'] > 6\nTrue",
         "failure_message": "check user 381",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(q2_result) == 433\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> np.isclose(q2_result.loc[466], 0.24517906336088155)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q3_total_seller_out.shape[0] == 3\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q3_total_seller_out[\"Total\"].sum() < 15000\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q3_product_name_out.size == 15\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q3_product_name_out.loc[\"pen\"].isnull().sum() == 0\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q3_product_count_out.size == 70\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q3_total_by_month_out.shape[1] == 5\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> int(q3_product_name_out.loc['hotel'].isnull().sum()) == 2\nTrue",
         "failure_message": "null values: hotel row",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q3_product_count_out.shape == (10, 7)\nTrue",
         "failure_message": "correct shape",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> (q3_total_by_month_out > 2000).sum().sum() == 3\nTrue",
         "failure_message": "number of entries strictly over 2000",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> (q3_total_by_month_out == 0).sum().sum() == 39\nTrue",
         "failure_message": "number of zero entries",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 0 <= q4_diff_of_median_proportions_out\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(q4_simulate_null_out, float)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> 0 <= q4_simulate_null_out <= 1.0\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(q4_pval_out, float)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> 0 <= q4_pval_out <= 1\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q4_diff_of_median_proportions_out > 0\nTrue",
         "failure_message": "greater than zero",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q4_simulate_null_out >= 0\nTrue",
         "failure_message": "greater than zero",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> 0 <= q4_pval_out <= 1\nTrue",
         "failure_message": "orange p-value: doctest",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(q4_pval_out, 0.113, atol=0.1)\nTrue",
         "failure_message": "orange p-value: approx",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(q5_out) == 5\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> set([x[0] for x in q5_out]) == q5_colors\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> all([isinstance(x[1], float) for x in q5_out])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q5_test_colors.index('orange') > q5_test_colors.index('yellow')\nTrue",
         "failure_message": "yellow less than orange",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(q5_out[0][1], 0.0)\nTrue",
         "failure_message": "smallest pval",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(q6_out, tuple)\nTrue",
         "failure_message": "tuple",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(q6_out[0], float)\nTrue",
         "failure_message": "wrong output type at index 0",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q6_out[1] in ['Fail to Reject', 'Reject']\nTrue",
         "failure_message": "wrong output type at index 1",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(q6_out[0], 0.005, atol=0.25)\nTrue",
         "failure_message": "p-value, approximate within 0.25",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(q6_out[0], 0.005, atol=0.5)\nTrue",
         "failure_message": "p-value, approximate within 0.5",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(q7_out) == 5\nTrue",
         "failure_message": "output length should be 5",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> set(q7_out) <= set(['P', 'H'])\nTrue",
         "failure_message": "output contains answers other than P or H",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8": {
     "name": "q8",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(q8_out) == 5\nTrue",
         "failure_message": "output length should be 5",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> set(q8_out) <= set(['MD', 'MCAR', 'MAR', 'NI'])\nTrue",
         "failure_message": "output contains answers other than the specified options",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q9": {
     "name": "q9",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(q9_out) == 5\nTrue",
         "failure_message": "output length should be 5",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> set(q9_out) <= set(['MD', 'MCAR', 'MAR', 'NI'])\nTrue",
         "failure_message": "output contains answers other than the specified options",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
