{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7a622c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1a8a15",
   "metadata": {},
   "source": [
    "# Lab 9 ‚Äì Models and Pipelines üîÅ\n",
    "\n",
    "## DSC 80, Fall 2022\n",
    "\n",
    "### Due Date: Thursday, December 1st at 11:59PM ‚ÄºÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a031c3",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and Markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding will be done in an accompanying `lab.py` file that is imported into the current notebook.\n",
    "\n",
    "<span style='color:red'><b>Note: For Lab 9, there are no hidden tests!</b></span> The tests you see when you run `grader.check` are the final tests that will determine your grade. In addition, when you submit Lab 9 to Gradescope you will see your results on the assignment right away.\n",
    "\n",
    "Labs and programming assignments will be graded in (at most) two ways:\n",
    "1. The functions and classes in the accompanying `lab.py` file will be tested (a la DSC 20),\n",
    "2. The notebook may be graded (if it contains free response questions or asks you to draw plots).\n",
    "\n",
    "**Do not change the function names in the `lab.py` file!**\n",
    "- The functions in the `lab.py` file are how your assignment is graded, and they are graded by their name.\n",
    "- If you changed something you weren't supposed to, just use git to revert! Ask us if you need help with this, or google around for `git revert`.\n",
    "\n",
    "**Tips for working in the notebook**:\n",
    "- The notebooks serve to present the questions and give you a place to present your results for later review.\n",
    "- The notebooks in *lab assignments* are not graded (only the `lab.py` file is submitted and graded).\n",
    "- The notebook serves as a nice environment for 'pre-development' and experimentation before designing your function in your `lab.py` file. You can write code here, but make sure that all of your real work is in the `lab.py` file.\n",
    "\n",
    "**Tips for developing in the `lab.py` file**:\n",
    "- Do not change the function names in the starter code; grading is done using these function names.\n",
    "- Do not change the docstrings in the functions. These are there to tell you if your work is on the right track!\n",
    "- You are encouraged to write your own additional helper functions to solve the lab! \n",
    "- Always document your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b76c1a1",
   "metadata": {},
   "source": [
    "### Importing code from `lab.py`\n",
    "\n",
    "* We import our `lab.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db9c4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3db12e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7413f6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from pipeline_testing_util import get_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f2ec03",
   "metadata": {},
   "source": [
    "***Note:*** While working on the lab, check the Campuswire post titled \"Lab 9 Released!\" for any clarifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6b8ef3",
   "metadata": {},
   "source": [
    "## Part 1: `sklearn` Pipelines üß†\n",
    "\n",
    "The file `data/toy.csv` contains an example dataset that consists of 4 columns:\n",
    "\n",
    "- `'group'`: a categorical column with 3 categories\n",
    "- `'c1'`: a numeric attribute\n",
    "- `'c2'`: a numeric attribute\n",
    "- `'y'`: the target variable (that you want to predict) \n",
    "```\n",
    "\n",
    "In the following questions, you will build `Pipeline`s that combine feature engineering with a linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f90cd6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'toy.csv')\n",
    "data = pd.read_csv(fp)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2cc375",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "First, you will train a regression model using only a *log-scaled* `'c2'` variable. Create a `Pipeline` that:\n",
    "1. log-scales `'c2'`, then\n",
    "2. predicts `'y'` using a linear regression model (using your transformed `'c2'`).\n",
    "\n",
    "That is, create a function `simple_pipeline` that takes in a DataFrame like `data` and returns a **tuple** consisting of \n",
    "- An already-fit `Pipeline`, and\n",
    "- An array containing the predictions your model makes on `data` (after being trained on `data`).\n",
    "\n",
    "***Note:*** By \"log\", we're referring to the natural logarithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e280970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d64070a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eedac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests to work\n",
    "q1_fp = os.path.join('data', 'toy.csv')\n",
    "q1_data = pd.read_csv(q1_fp)\n",
    "q1_pl, q1_preds = simple_pipeline(q1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0e768b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef694ed",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Now, you will engineer features from the other columns and use them to train a regression model.  Create a `Pipeline` that:\n",
    "1. uses `'c1'` as is,\n",
    "1. log-scales `'c2'`,\n",
    "1. one-hot encodes `'group'`, and\n",
    "1. predicts `'y'` using a linear regression model built on the three variables above. (Note that your model will have more than three \"features\", because one-hot encoding `'group'` will create multiple columns. Don't drop any of them.)\n",
    "\n",
    "That is, create a function `multi_type_pipeline` that takes in a DataFrame like `data` and returns a **tuple** consisting of\n",
    "- An already-fit `Pipeline`, and\n",
    "- An array containing the predictions your model makes on `data` (after being trained on `data`).\n",
    "\n",
    "***Hint:*** Use `ColumnTransformer`, as we did in [Lecture 15](https://github.com/dsc-courses/dsc80-2022-fa/blob/main/lectures/15-pipelines/notebook/lecture.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c2b2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7202ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab462b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests to work\n",
    "q2_fp = os.path.join('data', 'toy.csv')\n",
    "q2_data = pd.read_csv(q2_fp)\n",
    "q2_pl, q2_preds = multi_type_pipeline(q2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c82f28",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0164e243",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "It seems like `'c1'` and `'c2'` have strong associations with the values of `'group'` (to see this, run the cell below). This suggests that group-wise scaling might make good features. \n",
    "\n",
    "\n",
    "Now, we want to standardize (i.e. z-scale) both `'c1'` and `'c2'` **within each `'group'`** (`'A'`, `'B'`, and `'C'`). Unfortunately, there is no built-in transformer in `sklearn` that performs group-wise standardization, so **you will need to create your own transformer!**\n",
    "\n",
    "Your job is to complete the implementation of the `StdScalerByGroup` transformer class, meaning that you need to implement the `fit` and `transform` methods, along with the constructor (`__init__`).\n",
    "- The `StdScalerByGroup` transformer works on an input array/DataFrame `X` whose first column contains groups, and whose remaining columns are quantitative and need to be standardized (within each group).\n",
    "- The `fit` method should determine the mean and standard deviation of each quantitative column within each group in the input data `X` and save them in the instance variable `grps_`. (For instance, one of the quantities you may calculate here is the standard deviation of `'c1'`, but only for the rows whose `'group'` is `'B'`.)\n",
    "- The `transform` method should take in an input array/DataFrame `X`, standardize each quantitative column separately using the means and standard deviations stored in `grps_`, and return a DataFrame containing the transformed quantitative columns.\n",
    "\n",
    "\n",
    "If you `fit` and `transform` a `StdScalerByGroup` transformer on the `toy` DataFrame (without the `'y'` column), you should get back a DataFrame with two columns, `'c1'` and `'c2'`, with groups stored in the index (if you end up creating a `MultiIndex`, that is fine).\n",
    "\n",
    "\n",
    "***Notes:***\n",
    "1. You may decide on whatever structure you'd like for the `grps_` variable. This question will be graded on the correctness of the output of your transformer. (Check the correctness of your work by checking the output by-hand!)    \n",
    "2. At no point should you loop over the **rows** of `data` (in fact, our solution doesn't use any loops).\n",
    "3. The `'group'` column in the doctest is named `'g'` instead of `'group'`. Remember, the first column will **always** contain the groups, even if the first column's name is something other than `'group'`.\n",
    "4. Do not worry about cases where the standard deviation is equal to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd16905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The scatter plot referenced at the start of Question 3\n",
    "# This is not needed to answer the question, but motivates why we are standardizing\n",
    "sns.scatterplot(data=data, x='c1', y='y', hue='group');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff4b5ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e52277d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadef194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee76b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests to work\n",
    "# test fit \n",
    "q3_test_fit_cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 2, 2], 'c2': [3, 1, 2, 0]}\n",
    "q3_test_fit_X = pd.DataFrame(q3_test_fit_cols)\n",
    "q3_test_fit_std = StdScalerByGroup().fit(q3_test_fit_X)\n",
    "\n",
    "# test transform\n",
    "q3_test_transform_cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 3, 4], 'c2': [1, 2, 3, 4]}\n",
    "q3_test_transform_X = pd.DataFrame(q3_test_transform_cols)\n",
    "q3_test_transform_std = StdScalerByGroup().fit(q3_test_transform_X)\n",
    "q3_test_transform_out = q3_test_transform_std.transform(q3_test_transform_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86b7235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests to work\n",
    "q3_fit_data = pd.read_csv('data/toy.csv')\n",
    "\n",
    "N = 2*10**6\n",
    "a = np.random.choice(['A', 'B'], size=(N,1)).astype('object')\n",
    "b = np.random.multivariate_normal([1, 2], [[1, 0],[0, 100]], size=N)\n",
    "arr = np.hstack([a, b])\n",
    "q3_transform_data = pd.DataFrame(arr)\n",
    "q3_transform_data[1] = q3_transform_data[1].astype(float)\n",
    "q3_transform_data[2] = q3_transform_data[2].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e99147",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5998b04a",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "`Pipeline`s are supposed to help you easily try different model configurations. Create a function `eval_toy_model` which returns a hard-coded **list of tuples** consisting of the (RMSE, $R^2$) of three different modeling `Pipeline`s, fit and evaluated on the entire input dataset `data`. The three different `Pipeline`s are:\n",
    "1. The `Pipeline` in Question 1.\n",
    "1. The `Pipeline` in Question 2.\n",
    "1. A `Pipeline` consisting of a linear regression model fit on features generated by applying `StdScalerByGroup` to `'c1'`, log-scaling `'c2'`, and applying `OneHotEncoder` to `'group'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285985cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a8fa20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8dad9d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc704b9",
   "metadata": {},
   "source": [
    "## Part 2: Overfitting üòü"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b357b640",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "In this question, you will train two different classes of prediction models ‚Äì **decision tree and k-Nearest Neighbor regressors** ‚Äì on Galton's child heights dataset from lecture and explore different ways in which overfitting can appear.\n",
    "\n",
    "#### `tree_reg_perf` üå≤\n",
    "\n",
    "A decision tree regressor is trained similar to a decision tree classifier: the splits of the tree are created by minimizing the variance of the (training data) response values in the leaves given by making the split in question. A decision tree regressor predicts the response value of a (new) observation based on the **average target value** of the training observations lying in the same leaf node. \n",
    "\n",
    "One **hyperparameter** of a decision tree regressor that affects model complexity is the **depth** of the tree. Larger depths correspond to more complicated decision trees. We will explore this parameter in this question.\n",
    "\n",
    "Create a function `tree_reg_perf` that takes in a DataFrame like `galton` and:\n",
    "- Splits the data into training and test sets,\n",
    "- Trains 20 decision trees ‚Äì one for each depth between 1 and 20, and\n",
    "- Computes both the training RMSE and testing RMSE of each tree.\n",
    "\n",
    "Store and return your results in a DataFrame that has two columns, `'train_err'` and `'test_err'`, and an index that corresponds to tree depths (i.e. 1, 2, ..., 20).\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `knn_reg_perf` üëâüëà\n",
    "\n",
    "A k-Nearest Neighbors (k-NN) regressor predicts the response value of a (new) observation by computing the average value of the k-closest observations in the training set. The most common distance metric is Euclidean distance, i.e. $L_2$ distance.\n",
    "\n",
    "One **hyperparameter** of a k-NN regressor that affects model complexity is k, **the number of neighbors averaged over**. Larger values of k correspond to more complicated regressors. We will explore this hyperparameter in this question.\n",
    "\n",
    "Create a function `knn_reg_perf` that takes in a DataFrame like `galton` and:\n",
    "- Splits the data into training and test sets,\n",
    "- Trains 20 k-NN regressors ‚Äì one for each value of k between 1 and 20, and\n",
    "- Computes both the training RMSE and testing RMSE of each regressor.\n",
    "\n",
    "Again, store and return your results in a DataFrame that has two columns, `'train_err'` and `'test_err'`, and an index that corresponds to values of k (i.e. 1, 2, ..., 20).\n",
    "\n",
    "<br>\n",
    "\n",
    "**Some guidelines for both subparts:**\n",
    "\n",
    "- In all cases, we are using all other columns in `galton` to predict `'childHeight'`.\n",
    "- You need to import the necessary classes from `sklearn` **inside** the functions you create. (Unlike before, we haven't imported them for you because we want you to figure out what to import!)\n",
    "- If you're unsure how to create training and testing sets, refer to [Lecture 16](https://github.com/dsc-courses/dsc80-2022-fa/blob/main/lectures/16-bias_and_variance/notebook/lecture.ipynb). Use a test set size of 0.25.\n",
    "    - For the purposes of this question, do not use any cross-validation.\n",
    "- Don't write the formula for RMSE four times ‚Äì define a helper function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a7832aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `galton` to test your work\n",
    "galton = pd.read_csv('data/galton.csv')\n",
    "galton.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55faebbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3524b329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d2ccc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23728cf1",
   "metadata": {},
   "source": [
    "After you've implemented both functions, run the cells below to plot training and testing error for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f0e7aa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(9) # For reproducibility\n",
    "\n",
    "tree = tree_reg_perf(galton)\n",
    "knn = knn_reg_perf(galton)\n",
    "hyp = np.arange(1, 21)\n",
    "\n",
    "plt.subplots(1, 2, figsize=(10, 4), dpi=100)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hyp, tree.iloc[:, 0], label='Training Error')\n",
    "plt.plot(hyp, tree.iloc[:, 1], label='Testing Error')\n",
    "plt.legend()\n",
    "plt.xlabel('Tree Depth')\n",
    "plt.xticks(np.arange(1, 21, 2))\n",
    "plt.title('Error vs. Tree Depth for Decision Tree Regressor')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hyp, knn.iloc[:, 0], label='Training Error')\n",
    "plt.plot(hyp, knn.iloc[:, 1], label='Testing Error')\n",
    "plt.legend()\n",
    "plt.xlabel('k (# neighbors)')\n",
    "plt.xticks(np.arange(1, 21, 2))\n",
    "plt.title('Error vs. # Neighbors for k-NN Regressor');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edd39f8",
   "metadata": {},
   "source": [
    "If your training and evaluation routines are correct, you should notice a few things:\n",
    "- In both models, testing error initially decreases, and then (perhaps slowly) increases.\n",
    "- With the decision tree, training error **decreases** as depth increases.\n",
    "- With the k-NN regressor, training error **increases** as k (the number of neighbors looked at) increases.\n",
    "\n",
    "You should think about **why** you observe each of the above phenomena. In particular, the last point may seem confusing ‚Äì one would think that because larger values of k correspond to more complicated models (because the regressor is looking at more information to make a prediction), larger values of k should have lower training errors. But the nature of k-NN regressors is quite different than, say, decision tree regressors or linear regression models.\n",
    "\n",
    "Lastly, in both cases, identify the ideal **hyperparameter** choice based on the graphs of testing error. You don't have to write the answer anywhere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5267d64a",
   "metadata": {},
   "source": [
    "## Part 3: Predicting Survival on the Titanic üõ≥üßä"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491ff126",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Predicting whether or not passengers on the Titanic survived is a common first assignment when learning about classification ‚Äì now it's your turn!\n",
    "\n",
    "Create a function `titanic_model` that takes in a DataFrame `titanic` containing **training data only** and returns a `Pipeline` object fit to the training data. \n",
    "\n",
    "\n",
    "#### Requirements\n",
    "\n",
    "You have freedom to build your own model. That is, **you can use any classification algorithm**, but your model should satisfy the following requirements:\n",
    "\n",
    "- The model is built on the (binary) response column `'Survived'`.\n",
    "* The model uses features derived from **all other columns in `titanic`**. Below, we specify which columns to \"engineer\"; you may \"engineer\" features using other columns, but be sure to include every column in your model (even if you choose to leave some columns as-is).\n",
    "\n",
    "* Required feature engineering:\n",
    "    * Derive a feature from the \"title\" in the `'Name'` field (e.g. \"Mr\", \"Miss\", \"Mrs\" ‚Äì the names themselves should not be used as a feature; think about why).\n",
    "    * Derive a feature that standardizes passengers' ages among their `'Pclass'` (use Question 3!).\n",
    "    \n",
    "#### Evaluation\n",
    "    \n",
    "Your model must achieve an accuracy of 0.78 on both the training set and the test set. Note that while you have access to the test set, it is still encouraged to perform your own model validation.\n",
    "\n",
    "**Extra credit: If your model can consistently earn an accuracy of above 0.83 on the test set, you can earn 5 points of extra credit on the lab!**\n",
    "\n",
    "Some guidance:\n",
    "\n",
    "- `Pipeline` objects can have other `Pipeline` objects within them. While this isn't a requirement, you may find this useful to break down your model into smaller, more manageable steps.\n",
    "\n",
    "- Your submitted `titanic_model` function should have the model's hyperparameters (e.g. tree depth) hard-coded in it. That is, the `Pipeline` object doesn't have to include the hyperparameter selection process.\n",
    "\n",
    "- You will find [FunctionTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html) useful. If you want your transformer to output a categorical feature, you will need to select `validate=False`.\n",
    "\n",
    "- When using [ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer), you may find the `remainder` keyword helpful.\n",
    "\n",
    "- If you are set out to get those extra 5 points, consider building some meaningful features before fine-tuning the hyperparameters of your model. Do an EDA on the dataset ‚Äì what kinds of people are more prone to survive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "951a968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment using `titanic` below ‚Äì remember, this is only your training data\n",
    "titanic = pd.read_csv('data/titanic.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf366df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7926b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217b3630",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c897e7",
   "metadata": {},
   "source": [
    "There is **a ton** of material out there on analyzing data from the Titanic. After you build your model, look online for other examples (e.g. [on Kaggle](https://www.kaggle.com/c/titanic)) and think about how you could improve your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de87f67",
   "metadata": {},
   "source": [
    "## Congratulations! You've finished _the final lab of the quarter_! üéâü•≥\n",
    "\n",
    "Submit your `lab.py` file to Gradescope. Note that you only need to submit the `lab.py` file; this notebook should not be uploaded.\n",
    "\n",
    "Before submitting, you should ensure that all of your work is in the `lab.py` file. You can do this by running the doctests below, which will verify that your work passes the public tests **and** that your work is in the `lab.py` file. Run the cell below; you should see no output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "42986457",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m doctest lab.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf27df1b",
   "metadata": {},
   "source": [
    "In addition, `grader.check_all()` will verify that your work passes the public tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8d4b65",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92125e09",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(q1_pl, Pipeline)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(q1_pl.steps[-1][1], LinearRegression)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(q1_pl.steps[0][1], FunctionTransformer)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q1_preds.shape[0] == q1_data.shape[0]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> np.isclose(q1_preds.max(), 17.825, atol=0.01)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q1_pl.steps[0][1].func(1) == 0\nTrue",
         "failure_message": "check log function",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> np.isclose(q1_preds[0], 12.62, atol=0.01)\nTrue",
         "failure_message": "check pipeline predictions",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(q2_pl, Pipeline)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(q2_pl.steps[-1][1], LinearRegression)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(q2_pl.steps[0][1], ColumnTransformer)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q2_data.shape[0] == q2_preds.shape[0]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> np.isclose(q2_preds[0], 13.185, atol=2)\nTrue",
         "failure_message": "check predictions",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> from pipeline_testing_util import get_transformers\n>>> transformers = get_transformers(q2_pl)\n>>> any([isinstance(x, LinearRegression) for x in transformers])\nTrue",
         "failure_message": "Linear Regressor not in pipeline",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> transformers = get_transformers(q2_pl)\n>>> any([isinstance(x, ColumnTransformer) for x in transformers])\nTrue",
         "failure_message": "ColumnTransformer not in pipeline",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> transformers = get_transformers(q2_pl)\n>>> any([isinstance(x, OneHotEncoder) for x in transformers])\nTrue",
         "failure_message": "OneHotEncoder not in pipeline",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> features = q2_pl.steps[0][1].transform(q2_data.drop('y', axis=1))\n>>> features.shape == (1000, 5)\nTrue",
         "failure_message": "check feature matrix shape",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> features = q2_pl.steps[0][1].transform(q2_data.drop('y', axis=1))\n>>> np.isin(features, [0, 1]).all(axis=0).sum() == 3\nTrue",
         "failure_message": "check correct number of binary columns",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> features = q2_pl.steps[0][1].transform(q2_data.drop('y', axis=1))\n>>> np.isclose(features[0], 1.6732727272, atol=0.01).any()\nTrue",
         "failure_message": "check log scaling",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q3_test_fit_std.grps_ is not None\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q3_test_transform_out.shape == (4, 2)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> np.isclose(q3_test_transform_out.abs(), 0.707107, atol=0.001).all().all()\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q3_fit_out = StdScalerByGroup()\n>>> X = q3_fit_data[['group', 'c1', 'c2']].iloc[:4]\n>>> model = q3_fit_out.fit(X)\n>>> df = q3_fit_data.loc[q3_fit_data['group'] != 'C', ['group', 'c1', 'c2']]\n>>> feats = q3_fit_out.transform(df)\n>>> try:\n...     feats = feats.values\n... except:\n...     pass\n>>> \n>>> np.isclose(feats.max(), 11.499, atol=0.01)\nTrue",
         "failure_message": "check max scaled value",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q3_fit_out = StdScalerByGroup()\n>>> X = q3_fit_data[['group', 'c1', 'c2']]\n>>> model = q3_fit_out.fit(X)\n>>> feats = q3_fit_out.transform(X)\n>>> np.isclose(feats.mean(axis=0), 0, atol=0.005).all()\nTrue",
         "failure_message": "check mean of scaled columns",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q3_fit_out = StdScalerByGroup()\n>>> X = q3_fit_data[['group', 'c1', 'c2']]\n>>> model = q3_fit_out.fit(X)\n>>> feats = q3_fit_out.transform(X)\n>>> np.isclose(feats.std(axis=0), 1, atol=0.005).all()\nTrue",
         "failure_message": "check std of scaled columns",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q3_transform_out = StdScalerByGroup().fit(q3_transform_data)\n>>> q3_transform_out.grps_ is not None\nTrue",
         "failure_message": "no .grps_ attribute",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q3_transform_out = StdScalerByGroup().fit(q3_transform_data)\n>>> feats = q3_transform_out.transform(q3_transform_data)\n>>> np.isclose(feats.mean(axis=0), 0, atol=0.005).all()\nTrue",
         "failure_message": "check mean of scaled columns",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q3_transform_out = StdScalerByGroup().fit(q3_transform_data)\n>>> feats = q3_transform_out.transform(q3_transform_data)\n>>> np.isclose(feats.std(axis=0), 1, atol=0.005).all()\nTrue",
         "failure_message": "check std of scaled columns",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out = eval_toy_model()\n>>> len(out) == 3\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> out = eval_toy_model()\n>>> np.all([len(t) == 2 for t in out])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q4_out = eval_toy_model()\n>>> np.isclose(q4_out[0][0], 2.7551086974518118, atol=0.1)\nTrue",
         "failure_message": "incorrect rmse for 4.1",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q4_out = eval_toy_model()\n>>> np.isclose(q4_out[0][1], 0.39558507345910765, atol=0.01)\nTrue",
         "failure_message": "incorrect R^2 for 4.1",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q4_out = eval_toy_model()\n>>> np.isclose(q4_out[1][0], 2.3148336164355277, atol=0.1)\nTrue",
         "failure_message": "incorrect rmse for 4.2",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q4_out = eval_toy_model()\n>>> np.isclose(q4_out[1][1], 0.5733249315673331, atol=0.01)\nTrue",
         "failure_message": "incorrect R^2 for 4.2",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q4_out = eval_toy_model()\n>>> np.isclose(q4_out[2][0], 2.3157339477823844, atol=0.1)\nTrue",
         "failure_message": "incorrect rmse for 4.3",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q4_out = eval_toy_model()\n>>> np.isclose(q4_out[2][1], 0.5729929650348398, atol=0.01)\nTrue",
         "failure_message": "incorrect R^2 for 4.3",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q4_out = eval_toy_model()\n>>> np.isclose(q4_out[2][0], 2.3157339477823844, atol=1.0)\nTrue",
         "failure_message": "incorrect rmse for 4.3",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q4_out = eval_toy_model()\n>>> np.isclose(q4_out[2][1], 0.5729929650348398, atol=0.1)\nTrue",
         "failure_message": "incorrect R^2 for 4.3",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> galton_test = pd.read_csv('data/galton.csv')\n>>> out_tree_test = tree_reg_perf(galton_test)\n>>> (out_tree_test.columns.tolist() == ['train_err', 'test_err']) == True\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> galton_test = pd.read_csv('data/galton.csv')\n>>> out_tree_test = tree_reg_perf(galton_test)\n>>> (out_tree_test['train_err'].iloc[-1] < out_tree_test['test_err'].iloc[-1]) == True\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> galton_test = pd.read_csv('data/galton.csv')\n>>> out_knn_test = knn_reg_perf(galton_test)\n>>> (out_knn_test.columns.tolist() == ['train_err', 'test_err']) == True\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> galton_test = pd.read_csv('data/galton.csv')\n>>> out_tree_test = tree_reg_perf(galton_test)\n>>> (out_tree_test['train_err'].diff().dropna().iloc[:5] <= 0).all()\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> galton_test = pd.read_csv('data/galton.csv')\n>>> out_tree_test = tree_reg_perf(galton_test)\n>>> out_tree_test['test_err'].iloc[0] >= out_tree_test['test_err'].iloc[6]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> galton_test = pd.read_csv('data/galton.csv')\n>>> out_tree_test = tree_reg_perf(galton_test)\n>>> out_tree_test['test_err'].iloc[-1] >= out_tree_test['test_err'].iloc[6]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> galton_test = pd.read_csv('data/galton.csv')\n>>> out_tree_test = tree_reg_perf(galton_test)\n>>> out_tree_test['test_err'].idxmin() in [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> galton_test = pd.read_csv('data/galton.csv')\n>>> out_knn_test = knn_reg_perf(galton_test)\n>>> (out_knn_test['train_err'].diff().dropna().iloc[:5] >= 0).all()\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> galton_test = pd.read_csv('data/galton.csv')\n>>> out_knn_test = knn_reg_perf(galton_test)\n>>> out_knn_test['test_err'].iloc[0] >= out_knn_test['test_err'].iloc[6]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> galton_test = pd.read_csv('data/galton.csv')\n>>> out_knn_test = knn_reg_perf(galton_test)\n>>> out_knn_test['test_err'].iloc[-1] + 1 >= out_knn_test['test_err'].iloc[6]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> galton_test = pd.read_csv('data/galton.csv')\n>>> out_knn_test = knn_reg_perf(galton_test)\n>>> out_knn_test['test_err'].idxmin() not in [1, 2, 3]\nFalse",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q6_data_test = pd.read_csv('data/titanic.csv')\n>>> pl_test = titanic_model(q6_data_test)\n>>> isinstance(pl_test, Pipeline)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q6_data_test = pd.read_csv('data/titanic.csv')\n>>> pl_test = titanic_model(q6_data_test)\n>>> isinstance(pl_test.steps[-1][-1], BaseEstimator)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q6_data_test = pd.read_csv('data/titanic.csv')\n>>> pl_test = titanic_model(q6_data_test)\n>>> preds_test = pl_test.predict(q6_data_test.drop('Survived', axis=1))\n>>> ((preds_test == 0) | (preds_test == 1)).all()\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> from pipeline_testing_util import get_transformers\n>>> q6_data_test = pd.read_csv('data/titanic.csv')\n>>> pl_test = titanic_model(q6_data_test)\n>>> trans_test = get_transformers(pl_test)\n>>> any([isinstance(x, ColumnTransformer) for x in trans_test])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> from pipeline_testing_util import get_transformers\n>>> q6_data_test = pd.read_csv('data/titanic.csv')\n>>> pl_test = titanic_model(q6_data_test)\n>>> trans_test = get_transformers(pl_test)\n>>> any([isinstance(x, FunctionTransformer) for x in trans_test])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> from pipeline_testing_util import get_transformers\n>>> q6_data_test = pd.read_csv('data/titanic.csv')\n>>> pl_test = titanic_model(q6_data_test)\n>>> trans_test = get_transformers(pl_test)\n>>> #any([isinstance(x, StdScalerByGroup) for x in trans_test])\n>>> any([str(x) == 'StdScalerByGroup()' for x in trans_test])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q6_data_test = pd.read_csv('data/titanic.csv')\n>>> pl_test = titanic_model(q6_data_test)\n>>> trans_test = Pipeline(pl_test.steps[:-1])\n>>> trans_test.transform(q6_data_test.drop('Survived', axis=1)).shape[1] >= q6_data_test.drop('Survived', axis=1).shape[1]\nTrue",
         "failure_message": "did you add features?",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q6_data_test = pd.read_csv('data/titanic.csv')\n>>> pl_test = titanic_model(q6_data_test)\n>>> pl_test.score(q6_data_test.drop('Survived', axis=1), q6_data_test['Survived']) >= 0.78\nTrue",
         "failure_message": "accuracy *all* data more than 0.78",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> from sklearn.model_selection import train_test_split\n>>> q6_data_test = pd.read_csv('data/titanic.csv')\n>>> pl_test = titanic_model(q6_data_test)\n>>> X = q6_data_test.drop('Survived', axis=1)\n>>> y = q6_data_test['Survived']\n>>> X_tr, X_ts, y_tr, y_ts = train_test_split(X, y)\n>>> pl_test_fit = pl_test.fit(X_tr, y_tr)\n>>> score = pl_test.score(X_ts, y_ts)\n>>> score >= 0.78\nTrue",
         "failure_message": "train/test split -- accuracy on test",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> from sklearn.model_selection import train_test_split\n>>> q6_data_test = pd.read_csv('data/titanic.csv')\n>>> q6_holdout_test = pd.read_csv('data/titanic_holdout.csv')\n>>> pl_test = titanic_model(q6_data_test)\n>>> X = q6_data_test.drop('Survived', axis=1)\n>>> y = q6_data_test['Survived']\n>>> pl_test_fit = pl_test.fit(X, y)\n>>> X_ts = q6_holdout_test.drop('Survived', axis=1)\n>>> y_ts = q6_holdout_test['Survived']\n>>> score = pl_test.score(X_ts, y_ts)\n>>> score >= 0.77  # assignment says 0.78!\nTrue",
         "failure_message": "accuracy on unseen data >= 0.77",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> from sklearn.model_selection import train_test_split\n>>> q6_data_test = pd.read_csv('data/titanic.csv')\n>>> q6_holdout_test = pd.read_csv('data/titanic_holdout.csv')\n>>> pl_test = titanic_model(q6_data_test)\n>>> X = q6_data_test.drop('Survived', axis=1)\n>>> y = q6_data_test['Survived']\n>>> pl_test_fit = pl_test.fit(X, y)\n>>> X_ts = q6_holdout_test.drop('Survived', axis=1)\n>>> y_ts = q6_holdout_test['Survived']\n>>> score = pl_test.score(X_ts, y_ts)\n>>> score >= 0.815  # assignment says 0.83!\nTrue",
         "failure_message": "score on unseen data >= 0.815, extra-credit",
         "hidden": false,
         "locked": false,
         "points": 5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
