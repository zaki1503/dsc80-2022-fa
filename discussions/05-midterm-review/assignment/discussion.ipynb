{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"discussion.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion 05\n",
    "\n",
    "### Due Saturday October 29th, 11:59:59PM\n",
    "\n",
    "**Discussions will be due by the end of the day on Saturday** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda: Midterm Review ✍️\n",
    "\n",
    "* **Understand:** Take a look at Previous year midterm pattern and how this time's midterm would differ\n",
    "* **Recap:** Revise/Recollect some lecture content related to the midterm\n",
    "* **Practice:** Solve past year midterm problems for practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discussion import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 - 0 Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The table below shows data collected for 330 penguins in Antarctica. Each row represents one penguin. \n",
    "\n",
    "### Three species of penguins appear in the data set: `Adelie`, `Gentoo`, and `Chinstrap`. This data set will be referred to throughout the exam as the DataFrame `df` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data1.csv')\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 - 1 Point\n",
    "\n",
    "## What kind of data is in the column named \"Species\"?\n",
    " - quantitative ?\n",
    " - nominal ?\n",
    " - ordinal ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ans: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3 - 1 Point\n",
    "\n",
    "## What kind of data is in the column named \"Body Mass (g)\"?\n",
    " - quantitative ?\n",
    " - nominal ?\n",
    " - ordinal ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ans: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4 - 1 Point\n",
    "\n",
    "## The code below produces a new table. How many rows will the table have? (See the dataset description above for useful information).\n",
    "\n",
    "\n",
    "### `df.groupby('Species')['Culmen Length (mm)'].aggregate([np.mean, np.median])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ans: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Species')['Culmen Length (mm)'].aggregate([np.mean, np.median])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5 - 1 Point\n",
    "\n",
    "## The following function accepts a series of numbers and returns a series of the same size in which every number has been standardized (also known as \"z-scored\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(ser):\n",
    "    return (ser - ser.mean()) / ser.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Which of the following lines of code will return a series of standardized flipper lengths of length 330 (same as the number of rows in df ), where the standardization is done within each species?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That is, the flipper sizes of Adelie penguins are standardized as a group, the flipper sizes of Gentoo penguins are standardized as another group, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  `df.groupby('Species')['Flipper Length (mm)'].transform(standardize)`\n",
    "<!-- &nbsp;&nbsp; -->\n",
    "### 2.  `df.groupby('Species')['Flipper Length (mm)'].aggregate(standardize)`\n",
    "<!-- &nbsp;&nbsp; -->\n",
    "### 3.  `df.groupby('Species')['Flipper Length (mm)'].standardize()`\n",
    "<!-- &nbsp;&nbsp; -->\n",
    "### 4.  `df.groupby('Species')['Flipper Length (mm)'].agg(standardize)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ans: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Species')['Flipper Length (mm)'].transform(standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby('Species')['Flipper Length (mm)'].aggregate(standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby('Species')['Flipper Length (mm)'].standardize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby('Species')['Flipper Length (mm)'].agg(standardize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 - 1 Point\n",
    "\n",
    "## Suppose incomplete data is collected on three new penguins, shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incomplete = pd.DataFrame({\n",
    "    'Flipper Length (mm)':[191.0,193.0,197.0],\n",
    "    'Culmen Depth (mm)':[20.3,17.7,19.5],\n",
    "    'Species': ['Adelie','Adelie','Adelie']\n",
    "})\n",
    "df_incomplete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call this dataframe `df_incomplete`, and note that there are fewer columns than in `df` and that the columns which do appear are in a different order.\n",
    "\n",
    "### Suppose `df_incomplete` is appended to the end of `df` with the code `pd.concat([df, df_incomplete])`. What will be the values in the last line of the resulting dataframe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.     [197, 19.5, 'Adelie', nan, nan, nan, nan] with row label (index) 2 \n",
    "#### 2.     [nan, 19.5, 197.0, nan, nan, nan, 'Adelie'] with row label (index) 2 \n",
    "#### 3.     [0, 19.5, 197.0, 0, 0, 0, 'Adelie'] with row label (index) 2 \n",
    "#### 4.     [197, 19.5, 'Adelie', 0, 0, 0, 0] with row label (index) 2 \n",
    "#### 5.     [197, 19.5, 'Adelie', nan, nan, nan, nan] with row label (index) 332 \n",
    "#### 6.     [nan, 19.5, 197.0, nan, nan, nan, 'Adelie'] with row label (index) 332 \n",
    "#### 7.     [0, 19.5, 197.0, 0, 0, 0, 'Adelie'] with row label (index) 332 \n",
    "#### 8.     [197, 19.5, 'Adelie', 0, 0, 0, 0] with row label (index) 332"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ans: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df,df_incomplete])\n",
    "df_concat.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7 - 2 Points\n",
    "\n",
    "### Suppose a penguin is considered \"little\" if its body mass is less than 3250 grams. Write a piece of code that computes the number of each species which are considered little. Your code should return a series. To receive full credit, your code should not modify the dataframe df ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ans: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: your code will be graded manually, and it is not expected to be perfect. Be careful to not spend too much time trying to make your code perfect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8 - 1 Point\n",
    "### Suppose you have created a new table by_size which lists each penguin's size as either \"small\", \"medium\", or \"large\". The species is also included. The table looks like this:\n",
    "\n",
    "<img src = \"imgs/sizes.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the code `by_size.pivot_table(index='species', columns='size?', aggfunc='size')` , you've created the pivot table shown below:\n",
    "<img src = 'imgs/pt.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is a `NaN`in this pivot table. Why?\n",
    "\n",
    "#### 1. some Gentoo penguins had sizes that were NaN\n",
    "#### 2. some Gentoo penguins had sizes that were not strings\n",
    "#### 3. there were too many small Gentoo penguins for the computer to represent with finite precision\n",
    "#### 4. there were no small Gentoo penguins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ans: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9 - 1 Point \n",
    "\n",
    "### Suppose we wish to fill in the missing value in the pivot table above. What makes the most sense to fill it in with?\n",
    "\n",
    "#### A. 0\n",
    "#### B. 1\n",
    "#### C. np.inf (infinity)\n",
    "#### D. the mean of the \"small\" column\n",
    "#### E. the mean of the \"Gentoo\" row\n",
    "#### F. a number chosen at random from the observed values in the \"small\" column\n",
    "#### G. a number at random from the uniform distribution on 0, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ans: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10 - 1 Point\n",
    "\n",
    "### You have a second dataframe, `personalities`, that contains the disposition and intelligence of several species of penguin:\n",
    "<img src = 'imgs/personalities.png'></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalities = pd.DataFrame({\n",
    "    'Disposition':['happy','grumpy','mean'],\n",
    "    'Intelligence':['smart','not smart','not smart'],\n",
    "    'Species': ['Adelie','Chinstrap','Emperor']\n",
    "})\n",
    "personalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that personalities is missing some of the species that are in `df`, and it contains species that are not in `df`. You'd like to use the table to add columns to `df` for the disposition and intelligence of each of the penguins in the data set. \n",
    "\n",
    "### If a species in `df` is not listed in `personalities`, you're OK with having their disposition and Intelligence be `NaN`. \n",
    "\n",
    "### And if a species in `personalities` is not in `df`, it should not be added. \n",
    "### Therefore, the result of your merge should have exactly 330 rows -- the same as `df`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which of the below will perform this?\n",
    "\n",
    "#### 1. `pd.merge(df, personalities, how='outer')`\n",
    "#### 2. `pd.merge(df, personalities, how='inner')`\n",
    "#### 3. `pd.merge(df, personalities, how='left')`\n",
    "#### 4. `pd.merge(df, personalities, how='right')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ans: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df, personalities, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df, personalities, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df, personalities, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df, personalities, how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df # Reminder that merge operations are not automatically inPlace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q11 Hypothesis Test - 7 Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the sample of penguins in the table `df` above, 40% are `Gentoo` penguins, 30% are `Adelie`, and 30% are `Chinstrap`.\n",
    "\n",
    "#### It is known that, overall, 45% of penguins in Antarctica are `Gentoo`, 35% are `Adelie`, and 20% are `Chinstrap`. It therefore seems that the distribution of penguin species in your sample may differ from the population distribution.\n",
    "\n",
    "#### You will test this with a hypothesis test. Your null hypothesis is that the sample in `df` was drawn at random from the population. The alternative hypothesis is that your sample was drawn with different probabilities than those shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a piece of code to calculate the p-value of the observed data. You must choose a test statistic, calculate the observed value of the test statistic, compute simulated values of the test statistic, and calculate a p-value. For that reason, this question is worth 7 points, and partial credit will be awarded for each of the above.\n",
    "\n",
    "\n",
    "#### Note: your code will be graded manually, and it is not expected to be perfect. Be careful to not spend too much time trying to make your code perfect!\n",
    "#### Another Note: if you wish, you may write your code elsewhere and paste it into the box below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ans: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_type = pd.DataFrame([['Gentoo', 0.40, 0.45],\n",
    "                    ['Adelie', 0.30, 0.35],\n",
    "                    ['Chinstrap', 0.30, 0.20]],\n",
    "                   columns=['Penguin Type', 'Sample', 'Overall']).set_index('Penguin Type')\n",
    "\n",
    "penguins_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_type.plot(kind='barh', title='Penguin Type Distribution of Sample vs Overall');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_tvd = np.sum(np.abs(penguins_type['Sample'] - penguins_type['Overall'])) / 2\n",
    "observed_tvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate one instance - Keep null hypothesis in mind\n",
    "np.random.multinomial(1000, penguins_type['Overall']) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate 5000 instances\n",
    "N = 5000\n",
    "np.random.multinomial(1000, penguins_type['Overall'], size=N) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_dists = np.random.multinomial(1000, penguins_type['Overall'], size=N) / 1000\n",
    "null_tvds = np.sum(np.abs(null_dists - penguins_type['Overall'].to_numpy()), axis=1) / 2\n",
    "null_tvds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(null_tvds).plot(kind='hist', \n",
    "                     density=True,\n",
    "                     ec='w',\n",
    "                     title='Simulated Null TVDs & Observed TVD');\n",
    "plt.axvline(x=observed_tvd, color='red', linewidth=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "Now that we've finalized our test statistic and since we've also simulated the null hypothesis under the test statistic, define a function `prev_midterm_hypothesis_test` that takes in the observations `penguins_type` and does the following\n",
    "\n",
    "1. Calculate the `observed_tvd`\n",
    "2. Calculate the `p_value` after simulating the null statistic on 5000 samples\n",
    "\n",
    "The function should return a tuple with in the following format `(observed_tvd,p_val)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "penguins_type = pd.DataFrame([['Gentoo', 0.40, 0.45],\n",
    "                    ['Adelie', 0.30, 0.35],\n",
    "                    ['Chinstrap', 0.30, 0.20]],\n",
    "                   columns=['Penguin Type', 'Sample', 'Overall']).set_index('Penguin Type')\n",
    "q1_out = prev_midterm_hypothesis_test(penguins_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q12 - 1 Point\n",
    "\n",
    "### Suppose you look at the distribution of culmen (beak) depth for each species and find the following:\n",
    "\n",
    "<img src = 'imgs/culmen.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It looks as though Chinstrap penguins have larger culmen depth than Gentoo penguins.\n",
    "\n",
    "### Which of the following test statistics could be used to test this alternative hypothesis against the null hypothesis that the two distributions are the same? Check all that apply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. TVD\n",
    "### 2. Kolmogorov-Smirnov\n",
    "### 3. signed difference in mean culmen depth\n",
    "### 4. unsigned difference in mean culmen depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ans: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q13 - 1 Point\n",
    "\n",
    "### Suppose you now look at the distribution of culmen depth for each species once more and again find the following:\n",
    "\n",
    "<img src = 'imgs/culmen1.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What test statistic is the best choice for testing whether the empirical distributions of culmen depth in Chinstrap and Adelie penguins came from different underlying distributions?\n",
    "\n",
    "#### 1. the Kolmogorov-Smirnov Statistic\n",
    "#### 2. the absolute difference in means\n",
    "#### 3. the TVD\n",
    "#### 4. the signed difference in means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ans: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q14 - 1 Point\n",
    "### Suppose some of the entries in the \"Body Mass (g)\" column are missing.\n",
    "\n",
    "\n",
    "### Body mass measurements were taken any time a penguin walked across a scale that was placed outside. In your experience, the scale sometimes fails to make a measurement if the item placed on top is too small.\n",
    "\n",
    "### What is the most likely type of missingness in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Missing Completely at Random\n",
    "#### 2. Missing at Random\n",
    "#### 3. Not Missing at Random\n",
    "#### 4. Missing by Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ans: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q15 - 1 Point\n",
    "\n",
    "### Suppose some of the entries in the \"Delta 15 N (o/oo)\" and \"Delta 13 C (o/oo)\" columns are missing.\n",
    "\n",
    "\n",
    "### The measurements above were taken by four different teams located at different places in Antarctica, and one of the teams had a faulty measurement device that prevented them from measuring \"Delta 15 N\" and \"Delta 13 N\". The penguins in this team's area were mostly Gentoo penguins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the most likely type of missingness in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Missing Completely at Random\n",
    "#### 2. Missing at Random\n",
    "#### 3. Not Missing at Random\n",
    "#### 4. Missing by Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ans: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q16 - 1 Point\n",
    "\n",
    "### Suppose some of the entries in the \"Flipper Length (mm)\" column are missing. It is very hard to measure the flipper length of a wild penguin because penguins have a tendency to run away whenever you approach them with a ruler. \n",
    "\n",
    "### For this reason, the researchers agree that they will only measure the flipper length of half of the penguins they see. To implement this, they flip a coin when they see a penguin -- if the coin comes up heads, they measure the penguin's flipper length, and if it is tails they leave the flipper length blank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the most likely type of missingness in this case?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Missing Completely at Random\n",
    "#### 2. Missing at Random\n",
    "#### 3. Not Missing at Random\n",
    "#### 4. Missing by Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ans: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q17 - 1 Point\n",
    "\n",
    "### Suppose some of the body masses are missing. You'd like to test if some of the body masses are missing at random (MAR) dependent on the species. \n",
    "\n",
    "### You will determine this with a permutation test. Which one of the below is a valid test statistic for this test?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. The TVD (total variation distance)\n",
    "#### 2. The K-S statistic (Kolmogorov-Smirnov)\n",
    "#### 3. The absolute (unsigned) difference in means\n",
    "#### 4. The signed difference in means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q18 - 1 Point\n",
    "\n",
    "\n",
    "### Suppose the \"Flipper Length (mm)\" column has missing values. The distributions of species when the flipper length is missing (null) and when it is present (not null) are shown below:\n",
    "\n",
    "<img src = 'imgs/missingness_distribution.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Futhermore, the average flipper length of each species is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Species')['Flipper Length (mm)'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppose the overall mean flipper length is computed (using only the observed values).\n",
    "### Which of the following is true?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. the mean will be biased high\n",
    "### B. the mean will be biased low\n",
    "### C. the mean will be unbiased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ans: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q19 - 2 Points\n",
    "\n",
    "### Write a piece of code that imputes missing flipper lengths with the median flipper length of the species that the penguin belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Write a helper function, `midterm_review_imputation` that accepts `penguins_with_nulls` dataframe as an argument and returns a `pd.DataFrame` object where the cells in which `Flipper Length (mm)` is missing are **imputed with the median flipper length of the species** that the penguin belongs to. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Not change this cell, it is needed for the autograder code to run correctly\n",
    "penguins_with_nulls = pd.read_csv('data/data1.csv')\n",
    "q2_out = midterm_review_imputation(penguins_with_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You're done!\n",
    "\n",
    "* Submit your `.py` file to Gradescope. Note that you only need to submit the `.py` file; this notebook should not be uploaded. Make sure that all of your work is in the `.py` file and not here by running the doctests: `python -m doctest discussion.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(q1_out, tuple)\nTrue",
         "failure_message": "doctest",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> 0<=q1_out[0]<=1\nTrue",
         "failure_message": "Error in observed TVD",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(q1_out[0],0.09999999999999998,atol=0.1)\nTrue",
         "failure_message": "Error in observed TVD",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(q1_out[0],0.09999999999999998,atol=0.01)\nTrue",
         "failure_message": "Error in observed TVD",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> isinstance(q1_out[1], float)\nTrue",
         "failure_message": "Error in observed P-VALUE",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(q2_out, pd.DataFrame)\nTrue",
         "failure_message": "doctest",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q2_out['Flipper Length (mm)'].isnull().sum() == 0\nTrue",
         "failure_message": "doctest",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q2_out.loc[3,'Flipper Length (mm)'] == 190.0\nTrue",
         "failure_message": "Null Flipper Length not correctly imputed at some indices",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q2_out.isnull().sum().sum() == 33\nTrue",
         "failure_message": "Null Flipper Length not correctly imputed",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q2_out.loc[339,'Flipper Length (mm)'] == 216.0\nTrue",
         "failure_message": "Null Flipper Length not correctly imputed at some indices",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
