{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a04095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (10, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9e66d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 15 - `sklearn` Pipelines\n",
    "\n",
    "## DSC 80, Fall 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51485ffc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Today, in DSC 80\n",
    "\n",
    "- Building machine learning pipelines in `sklearn`\n",
    "\n",
    "Remember to refer to [dsc80.com/resources/#regular-expressions](https://dsc80.com/resources/#regular-expressions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb92bf1a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-white')\n",
    "plt.rc('figure', dpi=100, figsize=(7, 5))\n",
    "plt.rc('font', size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca8999c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `sklearn` overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c176d5a1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The steps of the modeling pipeline\n",
    "\n",
    "<center><img src=\"imgs/image_0.png\" width=\"60%\"></center>\n",
    "\n",
    "1. Create features to best reflect the \"meaning\" behind data.\n",
    "2. Choose a model that is appropriate to capture the relationships between features and the response.\n",
    "3. Select a loss function and fit the model (i.e., determine $w^*$).\n",
    "4. Evaluate the model (e.g. using RMSE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5465012",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Features and models using `sklearn`\n",
    "\n",
    "<center><img src=\"imgs/sklearn.png\" width=\"20%\"></center>\n",
    "    \n",
    "* Scikit-learn (`sklearn`) implements many common steps in the feature and model creation pipeline.\n",
    "    - It is **widely** used throughout [industry](https://scikit-learn.org/stable/testimonials/testimonials.html#:~:text=It%20is%20very%20widely%20used,very%20approachable%20and%20very%20powerful.) and academia.\n",
    "* It interfaces with `numpy` arrays, and to an extent, `pandas` DataFrames.\n",
    "* Huge benefit: the [documentation online](https://scikit-learn.org/stable/modules/classes.html) is **excellent**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa8813d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `preprocessing` and `linear_models`\n",
    "\n",
    "For the **feature creation** step of the modeling pipeline, we will use `sklearn`'s [`preprocessing`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) module.\n",
    "\n",
    "<center><img src=\"imgs/feature_part.png\" width=\"30%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e6b403",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For the **model creation** step of the modeling pipeline, we will use `sklearn`'s [`linear_model`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model) module.\n",
    "\n",
    "<center><img src=\"imgs/model_part.png\" width=\"36%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cc019b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transformers in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fa0668",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Transformer classes\n",
    "\n",
    "- **Transformers** take in \"raw\" data and output \"processed\" data. They are used for **creating features**.\n",
    "    - The input should be a multi-dimensional `numpy` array.\n",
    "        - Inputs can be DataFrames, but `sklearn` only looks at the values (i.e. it calls `to_numpy()` on input DataFrames).\n",
    "    - The output is a `numpy` array (never a DataFrame or Series)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d080955",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Transformers, like most relevant features of `sklearn`, are **classes**, not functions, meaning you need to instantiate them and call their methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d892f4c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example transformer: `Binarizer`\n",
    "\n",
    "The `Binarizer` transformer allows us to map a quantitative sequence to a sequence of 1s and 0s, depending on whether values are above or below a threshold.\n",
    "\n",
    "|Property|Example|Description|\n",
    "|---|---|---|\n",
    "|Initialize with parameters| `binar = Binarizer(thresh)` | set x=1 if x > thresh, else 0|\n",
    "|Transform data in a dataset | `feat = binar.transform(data)` | Binarize all columns in `data`|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d08027",
   "metadata": {},
   "source": [
    "First, we need to import the relevant class from `sklearn.preprocessing`. (Tip: import just the relevant classes you need from `sklearn`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0515b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935212e3",
   "metadata": {},
   "source": [
    "Let's try binarizing `'total_bill'`. We'll say a \"large\" bill is one that is over \\$20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df42a34e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tips = sns.load_dataset('tips') # To remove the columns we \"engineered\" before\n",
    "tips['total_bill'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73277706",
   "metadata": {},
   "source": [
    "First, we initialize a `Binarizer` object with the threshold we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b50dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi = Binarizer(threshold=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f2cbb7",
   "metadata": {},
   "source": [
    "Then, we call `bi`'s `transform` method and pass it the data we'd like to transform. Note that its input and output are both 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0e2638",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_bills = bi.transform(tips[['total_bill']]) # Must pass transform a 2D array/DataFrame\n",
    "transformed_bills[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f21cb9",
   "metadata": {},
   "source": [
    "Cool! We can verify that it worked correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c34e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "((tips['total_bill'] > 20).astype(int) == transformed_bills.flatten()).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717dda31",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example transformer: `StdScaler`\n",
    "\n",
    "- `StdScaler` **standardizes** data using the mean and standard deviation of the data.\n",
    "\n",
    "$$z_i = \\frac{x_i - \\bar{x}}{\\sigma_x}$$\n",
    "\n",
    "- Unlike `Binarizer`, `StdScaler` **requires some knowledge (mean and SD) of the dataset before transforming**.\n",
    "- As such, we need to **`fit`** an `StdScaler` transformer before we can use the `transform` method.\n",
    "* Typical usage: fit transformer on a sample; use that fit transformer to transform future data.\n",
    "\n",
    "\n",
    "|Property|Example|Description|\n",
    "|---|---|---|\n",
    "|Initialize with parameters| `stdscaler = StandardScaler()` | z-scale the data (no parameters) |\n",
    "|Fit the transformer| `stdscaler.fit(data)` | compute the mean and SD of `data`|\n",
    "|Transform data in a dataset | `feat = stdscaler.transform(newdata)` | z-scale `newdata` with mean and SD of `data`|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf21015",
   "metadata": {},
   "source": [
    "It only makes sense to standardize the already-quantitative columns of `tips`, so let's select just those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f68314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_quant = tips[['total_bill', 'tip', 'size']]\n",
    "tips_quant.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf56f81",
   "metadata": {},
   "source": [
    "Let's initialize a `StandardScaler` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156c6d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e565d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adb56f0",
   "metadata": {},
   "source": [
    "Note that the following **does not work!** The error message is very helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86d89f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler.transform(tips_quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db88978",
   "metadata": {},
   "source": [
    "Instead, we need to first call the `fit` method on `stdscaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d10e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler.fit(tips_quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77631aa0",
   "metadata": {},
   "source": [
    "Now, `transform` will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f134c1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First column is 'total_bill', second column is 'tip', third column is 'size'\n",
    "tips_quant_z = stdscaler.transform(tips_quant)\n",
    "tips_quant_z[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b99a2e4",
   "metadata": {},
   "source": [
    "We can also access the mean and variance `stdscaler` computed for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e85146",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f865c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler.var_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2584e7b",
   "metadata": {},
   "source": [
    "Note that we can call `transform` on DataFrames other than `tips_quant`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f99263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler.transform(tips_quant.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdd130e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example transformer: `OneHotEncoder`\n",
    "\n",
    "Let's keep just the categorical columns in `tips`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f687f091",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_cat = tips[['sex', 'smoker', 'day', 'time']]\n",
    "tips_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d11c5e",
   "metadata": {},
   "source": [
    "Like `StdScaler`, we will need to `fit` our `OneHotEncoder` transformer before it can transform anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e555e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac81cbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ohe.fit(tips_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a9d365",
   "metadata": {},
   "source": [
    "We can look at the unique values (i.e. categories) in each column by using the `categories_` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cbb869",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb37bcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_features = ohe.transform(tips_cat)\n",
    "ohe_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeae9f3",
   "metadata": {},
   "source": [
    "Since the resulting matrix is **sparse** â€“ most of its elements are 0 â€“ `sklearn` uses a more efficient representation than a regular `numpy` array. That's no issue, though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146f54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_features.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6522fa",
   "metadata": {},
   "source": [
    "Notice that the column names from `tips_cat` are no longer stored anywhere (remember, `fit` converts the input to a `numpy` array before proceeding).\n",
    "\n",
    "We can use the `get_feature_names` method on `ohe` to access the names of the one-hot-encoded columns, though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3384c4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.get_feature_names() # x0, x1, x2, and x3 correspond to column names in tips_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d596c30",
   "metadata": {},
   "source": [
    "`ohe` also has an `inverse_transform` method, which takes a one-hot-encoded matrix and returns a categorical matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d43592",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.inverse_transform(ohe_features[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933ef809",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Models in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6698f5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model classes\n",
    "\n",
    "- `sklearn` model classes (called \"estimators\") behave like transformers, in that we need to instantiate and `fit` them.\n",
    "- The difference is that we also need to specify what our \"response\" or \"target\" variable is, i.e. what we are trying to predict.\n",
    "    - Calling `fit` is the same as \"training our model\".\n",
    "- There are several models in the [`linear_model`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model) package; we will start with `LinearRegression`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2490cf61",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `LinearRegression` class\n",
    "\n",
    "We've seen this a few times in lecture already, but never formally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6240054",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2f4222",
   "metadata": {},
   "source": [
    "**Important:** From [the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression), we have\n",
    "\n",
    "> LinearRegression fits a linear model with coefficients w = (w1, â€¦, wp) to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation.\n",
    "\n",
    "In other words, `LinearRegression` minimizes mean squared error by default.\n",
    "\n",
    "Additionally, by default the `fit_intercept` argument is set to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb2e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearRegression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d040a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Predicting `'tip'` from `'total_bill'` and `'size'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a75d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a30a98",
   "metadata": {},
   "source": [
    "First, we instantiate and fit. By calling `fit`, we are saying \"minimize mean squared error and find $w^*$\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f97fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "# Note that there are two arguments to fit â€“ X and y!\n",
    "# (It is not necessary to write X= and y=)\n",
    "lr.fit(X=tips[['total_bill', 'size']], y=tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1307af09",
   "metadata": {},
   "source": [
    "After fitting, the `predict` method is available. Note that the argument to `predict` can be any 2D array with two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6035c1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted tip from a table of 3 that spends $25 \n",
    "lr.predict([[25, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71e891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted tip from a table of 14 that spends $1000 â€“ probably not accurate!\n",
    "lr.predict([[1000, 14]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace82a67",
   "metadata": {},
   "source": [
    "We can access the intercepts and slopes individually. This model is of the form\n",
    "\n",
    "$$\\text{predicted tip} = w_0^* + w_1^* \\cdot \\text{total bill} + w_2^* \\cdot \\text{table size}$$\n",
    "\n",
    "so we should expect three parameters total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61edabc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c36124",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d806cc5",
   "metadata": {},
   "source": [
    "If we want to compute the RMSE of our model, we need to find its predictions on every row in the training data (`tips`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db64f6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = lr.predict(tips[['total_bill', 'size']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a54e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean((all_preds - tips['tip']) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09529df8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It turns out that fit `LinearRegression` objects also have a `score` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dded7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr.score(tips[['total_bill', 'size']], tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dea71a",
   "metadata": {},
   "source": [
    "That doesn't look like the RMSE... what is it? ðŸ¤”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22d192b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: $R^2$\n",
    "\n",
    "- $R^2$, or the **coefficient of determination**, is a measure of the **quality of a linear fit**.\n",
    "- There are a few equivalent ways of computing it, assuming your model has an intercept term:\n",
    "\n",
    "$$R^2 = \\frac{\\text{var}(\\text{predicted $y$ values})}{\\text{var}(\\text{actual $y$ values})}$$\n",
    "\n",
    "$$R^2 = \\left[ \\text{correlation}(\\text{predicted $y$ values}, \\text{actual $y$ values}) \\right]^2$$\n",
    "\n",
    "- In the simple linear regression case, it is the square of the correlation coefficient, $r$.\n",
    "- **Key idea:** $R^2$ ranges from 0 to 1. **The closer it is to 1, the better the linear fit is.**\n",
    "- Interpretation: $R^2$ is the **proportion of variance in $y$ that the linear model explains**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca2f1de",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Calculating $R^2$\n",
    "\n",
    "Recall, `all_preds` contains the predicted `'tip'` for every data point in `tips`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0761e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bee7c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9b4972",
   "metadata": {},
   "source": [
    "**Method 1: $R^2 = \\frac{\\text{var}(\\text{predicted $y$ values})}{\\text{var}(\\text{actual $y$ values})}$**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d376a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(all_preds) / np.var(tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf5d418",
   "metadata": {},
   "source": [
    "**Method 2:** $R^2 = \\left[ \\text{correlation}(\\text{predicted $y$ values}, \\text{actual $y$ values}) \\right]^2$\n",
    "\n",
    "Note: By correlation here, we are referring to $r$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23d3d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.corrcoef(all_preds, tips['tip'])) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4695ba29",
   "metadata": {},
   "source": [
    "**Method 3:** `lr.score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7407f84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr.score(tips[['total_bill', 'size']], tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6e6e64",
   "metadata": {},
   "source": [
    "All three methods provide the same result!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e08af8c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `LinearRegression` summary\n",
    "\n",
    "|Property|Example|Description|\n",
    "|---|---|---|\n",
    "|Initialize model parameters| `lr = LinearRegression()` | Create (empty) linear regression model|\n",
    "|Fit the model to the data | `lr.fit(data, responses)` | Determines regression coefficients|\n",
    "|Use model for prediction |`lr.predict(newdata)`| Use regression line make predictions|\n",
    "|Evaluate the model| `lr.score(data, responses)` | Calculate the $R^2$ of the LR model|\n",
    "|Access model attributes| `lr.coef_` | Access the regression coefficients|\n",
    "\n",
    "***Note:*** Once `fit`, estimators like `LinearRegression` are just transformers (`predict` <-> `transform`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792f51bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee069dee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- Quantitative feature transformations allow us to use linear models to model non-linear data.\n",
    "- Transformers in `sklearn` are used for **feature engineering**, while estimators in `sklearn` are used for **models**.\n",
    "- A common pattern:\n",
    "    - Instantiate.\n",
    "    - `fit`.\n",
    "    - `transform` / `predict`.\n",
    "- We like linear models with **low RMSE** and **high $R^2$**!\n",
    "- **Next:** Combining transformers and estimators in a single **pipeline**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6294db72",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "plt.style.use('seaborn-white')\n",
    "plt.rc('figure', dpi=100, figsize=(7, 5))\n",
    "plt.rc('font', size=12)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29f87dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Models in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3585032a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Predicting `'tip'` from `'total_bill'` and `'size'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737283ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = sns.load_dataset('tips')\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4be0c23",
   "metadata": {},
   "source": [
    "First, we instantiate and fit. By calling `fit`, we are saying \"minimize mean squared error and find $w^*$\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1481f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "# Note that there are two arguments to fit â€“ X and y!\n",
    "# (It is not necessary to write X= and y=)\n",
    "lr.fit(X=tips[['total_bill', 'size']], y=tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2c3cde",
   "metadata": {},
   "source": [
    "After fitting, the `predict` method is available. Note that the argument to `predict` can be any 2D array with two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9db524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted tip from a table of 3 that spends $25 \n",
    "lr.predict([[25, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceac617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted tip from a table of 14 that spends $1000 â€“ probably not accurate!\n",
    "lr.predict([[1000, 14]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726d03ac",
   "metadata": {},
   "source": [
    "We can access the intercepts and slopes individually. This model is of the form\n",
    "\n",
    "$$\\text{predicted tip} = w_0^* + w_1^* \\cdot \\text{total bill} + w_2^* \\cdot \\text{table size}$$\n",
    "\n",
    "so we should expect three parameters total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17953699",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d58200",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97583e3f",
   "metadata": {},
   "source": [
    "If we want to compute the RMSE of our model, we need to find its predictions on every row in the training data (`tips`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5e0e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = lr.predict(tips[['total_bill', 'size']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af9df3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean((all_preds - tips['tip']) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b723a52",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It turns out that fit `LinearRegression` objects also have a `score` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a778ce6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr.score(tips[['total_bill', 'size']], tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b348e5",
   "metadata": {},
   "source": [
    "That doesn't look like the RMSE... what is it? ðŸ¤”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9197d54a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: $R^2$\n",
    "\n",
    "- $R^2$, or the **coefficient of determination**, is a measure of the **quality of a linear fit**.\n",
    "- There are a few equivalent ways of computing it, assuming your model **is linear and has an intercept term**:\n",
    "\n",
    "$$R^2 = \\frac{\\text{var}(\\text{predicted $y$ values})}{\\text{var}(\\text{actual $y$ values})}$$\n",
    "\n",
    "$$R^2 = \\left[ \\text{correlation}(\\text{predicted $y$ values}, \\text{actual $y$ values}) \\right]^2$$\n",
    "\n",
    "- In the simple linear regression case, it is the square of the correlation coefficient, $r$.\n",
    "- **Key idea:** $R^2$ ranges from 0 to 1. **The closer it is to 1, the better the linear fit is.**\n",
    "    - $R^2$ has no units of measurement, unlike RMSE.\n",
    "- Interpretation: $R^2$ is the **proportion of variance in $y$ that the linear model explains**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cfa7ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Calculating $R^2$\n",
    "\n",
    "Recall, `all_preds` contains the predicted `'tip'` for every data point in `tips`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c78d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9286000",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e759e0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Method 1: $R^2 = \\frac{\\text{var}(\\text{predicted $y$ values})}{\\text{var}(\\text{actual $y$ values})}$**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c598e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(all_preds) / np.var(tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9788a4cd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Method 2:** $R^2 = \\left[ \\text{correlation}(\\text{predicted $y$ values}, \\text{actual $y$ values}) \\right]^2$\n",
    "\n",
    "Note: By correlation here, we are referring to $r$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af21dfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.corrcoef(all_preds, tips['tip'])) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61125187",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Method 3:** `lr.score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fc8665",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr.score(tips[['total_bill', 'size']], tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f48ca0b",
   "metadata": {},
   "source": [
    "All three methods provide the same result!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566cf7bd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `LinearRegression` summary\n",
    "\n",
    "|Property|Example|Description|\n",
    "|---|---|---|\n",
    "|Initialize model parameters| `lr = LinearRegression()` | Create (empty) linear regression model|\n",
    "|Fit the model to the data | `lr.fit(data, responses)` | Determines regression coefficients|\n",
    "|Use model for prediction |`lr.predict(newdata)`| Use regression line make predictions|\n",
    "|Evaluate the model| `lr.score(data, responses)` | Calculate the $R^2$ of the LR model|\n",
    "|Access model attributes| `lr.coef_` | Access the regression coefficients|\n",
    "\n",
    "***Note:*** Once `fit`, estimators like `LinearRegression` are just transformers (`predict` <-> `transform`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9821cb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee9bfd1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"imgs/image_0.png\" width=\"50%\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "So far, we've used transformers for feature engineering and models for prediction. We can combine these steps into a single `Pipeline`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac398cb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Pipeline`s in `sklearn`\n",
    "\n",
    "- A `Pipeline` object is instantiated using a **list** containing transformer(s) and a model (estimator).\n",
    "```py\n",
    "pl = Pipeline([feat_trans1, feat_trans2, ..., mdl])\n",
    "```\n",
    "- Once a `Pipeline` is instantiated, you can fit **all** steps (transformers and model) using `fit`.\n",
    "```py\n",
    "pl.fit(data, responses)\n",
    "```\n",
    "- To make predictions using **raw (untransformed) data**, use `pl.predict`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae60ae1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Creating a `Pipeline`\n",
    "\n",
    "- To instantiate a `Pipeline`, we must provide a list with zero or more transformers followed by a single model.\n",
    "    - All \"steps\" must have `fit` methods, and all but the last must have `transform` methods.\n",
    "- The list we provide `Pipeline` with must be a list of **tuples**, where\n",
    "    - The first element is a \"name\" (that we choose) for the step.\n",
    "    - The second element is a transformer or estimator instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1a3f82",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's build a `Pipeline` that:\n",
    "- One-hot-encodes the categorical features in `tips`.\n",
    "- Fits a regression model on the one-hot-encoded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567c0478",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_cat = tips[['sex', 'smoker', 'day', 'time']]\n",
    "tips_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76a745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9860a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('one-hot', OneHotEncoder()),\n",
    "    ('lin-reg', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f53341",
   "metadata": {},
   "source": [
    "Now that `pl` is instantiated, we `fit` it the same way we would fit the individual steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384850f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.fit(tips_cat, tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ac1778",
   "metadata": {},
   "source": [
    "Now, to make predictions using **raw data**, all we need to do is use `pl.predict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafc3226",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.predict([['Male', 'Yes', 'Sat', 'Lunch']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11829fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.predict(tips_cat.iloc[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f4a05a",
   "metadata": {},
   "source": [
    "`pl` performs **both** feature transformation and prediction with just a single call to `predict`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629d8916",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can access individual \"steps\" of a `Pipeline` through the `named_steps` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819cff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0059ae4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.named_steps['one-hot'].transform(tips_cat).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4becc3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.named_steps['lin-reg'].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8959ebff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### More sophisticated `Pipeline`s\n",
    "\n",
    "- In the previous example, we one-hot-encoded every input column. **What if we want to perform different transformations on different columns?**\n",
    "- **Solution:** Use a `ColumnTransformer`.\n",
    "    - Instantiate a `ColumnTransformer` using a list of tuples, where:\n",
    "        - The first element is a \"name\" we choose for the transformer.\n",
    "        - The second element is a transformer instance (e.g. `OneHotEncoder()`).\n",
    "        - The third element is a **list of relevant column names**.\n",
    "    - `ColumnTransformer` is extremely useful, but it was only added to `sklearn` in 2018!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5901a85f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='imgs/image_3.png' width=50%></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48641add",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438e84b3",
   "metadata": {},
   "source": [
    "Let's perform different transformations on the quantitative and categorical features of `tips` (so, we will not transform `'tip'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ae7802",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_features = tips.drop('tip', axis=1)\n",
    "tips_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a684b7c5",
   "metadata": {},
   "source": [
    "- To the **quantitative features (`'total_bill'` and `'size'`)**, we will apply the `StandardScaler` transformer.\n",
    "- To the **categorical features**, we will apply the `OneHotEncoder` transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a4be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('quant', StandardScaler(), ['total_bill', 'size']),\n",
    "        ('cat', OneHotEncoder(), ['sex', 'smoker', 'day', 'time'])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a630f1ba",
   "metadata": {},
   "source": [
    "Now, let's create a `Pipeline` using `preproc` as a transformer, and `fit` it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3d6b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('preprocessor', preproc), \n",
    "    ('lin-reg', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f6e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.fit(tips_features, tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da51e5e5",
   "metadata": {},
   "source": [
    "Prediction is as easy as calling `predict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dafb2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff076dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.predict(tips_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884266a3",
   "metadata": {},
   "source": [
    "`pl` also has a `score` method, the same way a fit `LinearRegression` instance does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616d9a34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pl.score(tips_features, tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec66b39c",
   "metadata": {},
   "source": [
    "Recall, we can access the individual \"steps\" in `pl` using the `named_steps` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a73c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.named_steps['preprocessor'].transform(tips_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785dfb8c",
   "metadata": {},
   "source": [
    "**Note:** `ColumnTransformer` has a `remainder` argument that you can use to specify what to do with columns that aren't being transfromed (`'drop'` or `'passthrough'`)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
