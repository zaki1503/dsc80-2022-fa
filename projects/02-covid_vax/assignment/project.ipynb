{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"project.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 ‚Äì COVID Vaccinations ü¶†\n",
    "\n",
    "## DSC 80, Fall 2022\n",
    "\n",
    "### Checkpoint Due Date: Thursday, October 20th (Questions 1, 2, 6, 8, and 10)\n",
    "### Due Date: Thursday, October 27th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions üìù\n",
    "\n",
    "Welcome to Project 2!\n",
    "\n",
    "---\n",
    "\n",
    "### Working on the Project üíª\n",
    "\n",
    "This Jupyter Notebook contains the statements of the problems and provides code and Markdown cells to display your answers to the problems.  \n",
    "\n",
    "* Like in labs, your coding work will be developed in the accompanying `project.py` file, that will be imported into the current notebook. This code will be autograded.\n",
    "* Note that there is no manually-graded component to Project 2, so the only thing you will ever submit is `project.py`.\n",
    "* **For the checkpoint, you only need to turn in a `project.py` containing solutions for Questions 1, 2, 6, 8, and 10!**\n",
    "    - The \"Project 2 Checkpoint\" autograder on Gradescope does not thoroughly check your code ‚Äì it only runs the public notebook tests on the checkpoint questions to make sure that you have completed them. When you submit the final version of the project, we will use hidden tests to check your answers more thoroughly.\n",
    "    - Note that this means you will ultimately have to submit the project twice ‚Äì once to the \"Project 2 Checkpoint\" autograder (Questions 1, 2, 6, 8, and 10 only), and once to the \"Project 2\" autograder (once you're fully done).\n",
    "    - The reason for skipping around is that **the project has two distinct parts, and you should start on both parts by the time the checkpoint is due**. Note that the checkpoint questions are less than half of the total project (and some of them are easier than the average project question), so budget your time appropriately for completing the rest of the project.\n",
    "\n",
    "**Do not change the function names in the `project.py` file!**\n",
    "- The functions in the `project.py` file are how your assignment is graded, and they are graded by their name.\n",
    "- If you changed something you weren't supposed to, just use git to revert! Ask us if you need help with this, or Google around for `git revert`.\n",
    "\n",
    "**Tips for developing in the `project.py` file**:\n",
    "- Do not change the function names in the starter code; grading is done using these function names.\n",
    "- Do not change the docstrings in the functions. These are there to tell you if your work is on the right track!\n",
    "- You are **encouraged to write your own additional functions** to solve the questions! \n",
    "- Always document your code!\n",
    "\n",
    "**Tips for testing the correctness of your answers:**\n",
    "\n",
    "Once you write your code in `project.py`, you should use your notebook to inspect and analyze your functions' outputs for correctness. You should also run the doctests on the command line, and submit a version of your project to the Gradescope autograder well in advance of the deadline to ensure that there are no unexpected bugs in your code or your computing environment.\n",
    "\n",
    "<span style='color:red'><b>Note that in this project, the doctests and public Otter notebook tests are not identical</b></span>, though they test similar ideas. In particular, the doctests often test your functions on smaller subsets of the larger datasets that we use in the notebook. **You should regularly run both.**\n",
    "\n",
    "### Warning! ‚ö†Ô∏è\n",
    "\n",
    "This project contains larger datasets than usual. They aren't huge, but they aren't tiny. The autograder has been set to allow more memory usage than usual, but if you write inefficient code you may exhaust all of the allocated memory, causing the autograder to fail. If this happens, the autograder will say that your submission was formatted incorrectly.\n",
    "\n",
    "**Writing efficient code is part of the project!** Be sure to submit your code to the Gradescope autograder regularly to check that it is efficient enough. If your code fails to run on the autograder due to efficiency reasons and it is past the late deadline, we will perform a \"catastrophic regrade\" by removing your inefficient code (deleting that function definition) and charging the usual cost of two slip days. This is expensive, so be sure to check that your code works with the autograder with plenty of time before the deadline!\n",
    "\n",
    "### Working with a Partner üßë‚Äçü§ù‚Äçüßë\n",
    "\n",
    "You are allowed to work with a partner on projects in DSC 80. If you do work with a partner, you must follow the [Pair Programming Guidelines](https://dsc10.com/pair-programming/). Specifically, you must be actively working on the project at the same time on one computer. Splitting up the project and working on it separately **is not** pair programming.\n",
    "\n",
    "You can use the Google Sheet posted on the class messageboard to find a partner.\n",
    "\n",
    "Note that if you do work with a partner, you and your partner must submit the Checkpoint together and the whole project together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import pathlib\n",
    "import urllib.request\n",
    "\n",
    "# if this cell raises an ImportError, you should install `ipywidgets`\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "plt.rc('figure', dpi=100, figsize=(8, 5))\n",
    "plt.rc('font', size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Assignment\n",
    "\n",
    "Data science has been an important tool in understanding the development of the COVID-19 pandemic. In this project, we'll take a took at two real-world datasets that measure vaccination rates and effectiveness.\n",
    "\n",
    "---\n",
    "\n",
    "### Navigating the Project\n",
    "\n",
    "Click on the links below to navigate to different parts of the project. Note that Questions 1, 2, 6, 8, and 10 constitute your Checkpoint submission.\n",
    "\n",
    "- [Part 1: Global Vaccination Rates üåé](#part1)\n",
    "    - [Question 1 (Checkpoint Question)](#Question-1-(Checkpoint-Question))\n",
    "    - [Question 2 (Checkpoint Question)](#Question-2-(Checkpoint-Question))\n",
    "    - [Question 3](#Question-3)\n",
    "    - [Question 4](#Question-4)\n",
    "    - [Question 5](#Question-5)\n",
    "- [Part 2: Vaccine Effectiveness üíâ](#part2)\n",
    "    - [Question 6 (Checkpoint Question)](#Question-6-(Checkpoint-Question))\n",
    "    - [Question 7](#Question-7)\n",
    "    - [Question 8 (Checkpoint Question)](#Question-8-(Checkpoint-Question))\n",
    "    - [Question 9](#Question-9)\n",
    "    - [Question 10 (Checkpoint Question)](#Question-10-(Checkpoint-Question))\n",
    "    - [Question 11](#Question-11)\n",
    "\n",
    "---\n",
    "\n",
    "The file `data/covid_vaccinations_updated.csv` contains information on the number of COVID vaccinations that have been administered in various countries and regions of the world, as of September 21st, 2022:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vacs = pd.read_csv(os.path.join('data', 'covid_vaccinations_updated.csv'))\n",
    "vacs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='part1'></a>\n",
    "\n",
    "## Part 1: Global Vaccination Rates üåé\n",
    "\n",
    "One question we might hope to answer with this data is, **does the population density of countries affect vaccination rates?** *A priori*, we might think that denser countries are more vaccinated -- is this true? We will try answering this by looking at the average vaccination rates for countries with similar densities.\n",
    "\n",
    "We may think that we can use this data directly for getting the vaccination rate but unfortunately, the messiness of real-world data means that answering even this question requires a bit of cleaning and organization. We'll do this cleaning and organization in the next few questions.\n",
    "\n",
    "First, we need to find the total number of vaccinated individuals in each country/region. To do this, we have to understand what the values in the `'People_at_least_one_dose'` column mean. Are they the number people vaccinated on *that day*? Or are they the *cumulative* number of vaccinated people? This can be answered with a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vacs[vacs['Country_Region'] == 'US'].plot(x='Date', y='People_at_least_one_dose')\n",
    "plt.title('People_at_least_one_dose in the US')\n",
    "plt.xticks(rotation=45);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vacs[vacs['Country_Region'] == 'US']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the curve *appears* to be always increasing, this plot suggests that the `'Doses_admin'` column contains the *cumulative* number of doses administered, and this is indeed what the column is *supposed* to be. However, this is messy, real-world data, and you can't *assume* that the reported vaccination rates are monotonically increasing (or, rather, monotonically non-decreasing). For example, let's look at the plot for Ethiopia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacs[vacs['Country_Region'] == 'Ethiopia'].plot(x='Date', y='People_at_least_one_dose')\n",
    "plt.title('People_at_least_one_dose in Ethiopia')\n",
    "plt.xticks(rotation=45);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the dips in the graph? Unless there were *negative* doses administered (which would be... awkward), we must conclude that the data is messy - there will be instances where, either due to errors in reporting or in recording, the cumulative number of doses actually *decreases* from one day to the next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 (‚úÖ Checkpoint Question)\n",
    "\n",
    "Let's explore whether the messiness seen above is common.\n",
    "\n",
    "#### `count_monotonic`\n",
    "\n",
    "Create a function named `count_monotonic` which accepts a 1D `numpy` array and returns the counts of how many times an entry in the array (except the first) is strictly less than the previous entry.\n",
    "\n",
    "***Hint***: There's a `numpy` function for computing the difference between consecutive elements of an array.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `monotonic_violations_by_country`\n",
    "\n",
    "Create a function named `monotonic_violations_by_country` which accepts a DataFrame like `vacs` and returns a DataFrame with one row for each country and two `int` columns ‚Äì `'Doses_admin_monotonic'` and `'People_at_least_one_dose_monotonic'`. An entry in the `'Doses_admin'` column should be the number of times a country's `'Doses_admin'` is NOT monotonically increasing; likewise for the other columns. The index of the returned DataFrame should contain country names.\n",
    "\n",
    "***Note:*** No looping is allowed, but `groupby` is your friend. Use the `count_monotonic` function, along with the assumption that the input DataFrame `vacs` is already sorted by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to see the result, and don't change this cell -- it is used by the tests\n",
    "mono = monotonic_violations_by_country(vacs)\n",
    "mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've completed Question 1 correctly, you should see that it is not rare for the data to violate the monotonicity assumption (and multiple times at that). We'll have to take this into account when doing our data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 (‚úÖ Checkpoint Question)\n",
    "\n",
    "To get the vaccination rate, we'd like to get the total number of doses administered and people vaccinated for each country. If the data were truly monotonic, we could simply group by country and find the maximum within each group and within each column ‚Äì this would be the overall cumulative total. However, if the data has errors that make it not monotonically increasing, there could be a noisy \"spike\" in the graph (as in the plot for Ethiopia above), so that the maximum may be an unfaithful measure of the total number of doses. Instead of the maximum, we should use something more robust, such as **the 97th percentile**.\n",
    "\n",
    "Create a function named `robust_totals` that accepts a DataFrame like `vacs` and returns a DataFrame with one row for each country and two columns ‚Äì `'Doses_admin'` and `'People_at_least_one_dose'`. The `'Doses_admin'` column should contain the 97th percentile of the `'Doses_admin'` values for each country; likewise for the other column. The index of the returned DataFrame should contain country names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to see the result, and don't change this cell -- it is used by the tests\n",
    "tots = robust_totals(vacs)\n",
    "tots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to calculate the vaccination rate for each country by using the number of people vaccinated as a percentage of the total population. We then want to use this information in conjunction with population density to answer our initial question. Of course, our original vaccination dataset does not contain population data. Luckily, we have access to a separate dataset of country statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pops_raw = pd.read_csv(os.path.join('data', 'populations_updated.csv'))\n",
    "pops_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Unfortunately, this DataFrame's data types require some cleaning. All of the columns except the first are numeric and should either be integers or floats, as appropriate, but many of them are being stored incorrectly.\n",
    "\n",
    "Create a function named `fix_dtypes` which accepts a DataFrame like `pops_raw` above and returns a DataFrame with exactly the same columns and rows, but with the data types \"fixed\" to be appropriate for the data contained within.\n",
    "\n",
    "**Note:**\n",
    " - All percentages should be represented as decimals ‚Äì e.g., 27% should be 0.27.\n",
    " - `Population in 2022` is currently being stored in thousands. That is, the population of Tokelau is 1,871 people, but it is represented as 1.871 in the dataset above. \"Convert\" this population total to the actual number of people. That is, in your resulting dataframe, the population of Tokelau should be 1871.\n",
    "\n",
    "***Hint:*** You can make helper functions! It's OK to loop over the **columns** of the DataFrame (but not the rows).\n",
    "\n",
    "As always, make sure that your function does not change the DataFrame it is called on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to see the result, and don't change this cell -- it is used by the tests\n",
    "pops = fix_dtypes(pops_raw)\n",
    "pops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Remember that one of the steps towards our goal is to compute the percentage of people vaccinated in each country. Our next step is to take the population and density numbers from the previous problem and insert them into the DataFrame of vaccination numbers (`tots`). In theory this is a simple `concat` or `merge`, but there's a problem: the names of the countries are not always the same in each DataFrame.\n",
    "\n",
    "#### `missing_in_pops`\n",
    "First, create a function named `missing_in_pops` which takes in two DataFrames, the first, like `tots` above, containing the total number of vaccinations per country, and the second like `pops` above, containing the population of each country. It should return a Python **set** of names that appear in `tots` but not in `pops`.\n",
    "\n",
    "***Hint:*** `pandas` indexes have a method that checks if each element of the index is a member of some other collection. **Do not** use a `for`-loop.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `fix_names`\n",
    "After running `missing_in_pops`, you'll notice that there are 11 countries that appear in `tots` that do not appear in `pops`. It turns out that most of these countries *do* appear in `pops`, just under a different name or spelling. Using the power of Google or your ‚ú®*domain knowledge*‚ú®, combined with an exploration of the `tots` DataFrame, create a function named `fix_names` that accepts one argument ‚Äì a DataFrame like `pops` ‚Äì and returns a copy of `pops`, but with the `'Country (or dependency)'` column changed so that all countries that appear in `tots` also appear in the result, with a few exceptions listed below. \n",
    "\n",
    "For example, the country `'Burma'` appears in `tots`, but is listed as `'Myanmar'` in `pops`. In the DataFrame returned by your function, `'Myanmar'` should be changed to `'Burma'` to match `tots`.\n",
    "\n",
    "As noted above, there are a few exceptions:\n",
    "\n",
    "- `'Kosovo'` does not appear in `pops`. You do not need to change an entry in `pops` to match it.\n",
    "- There is a region simply called `'World'`. This doesn't appear in `pops`. You do not need to change an entry in `pops` to match it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run this to see the result, and don't change this cell -- it is used by the tests\n",
    "missing = missing_in_pops(tots, pops)\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run this to see the result, and don't change this cell -- it is used by the tests\n",
    "pops_fixed = fix_names(pops)\n",
    "pops_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Finally, our data is clean and we can analyze the association between vaccination rate and population density.\n",
    "\n",
    "To reduce noise, we will group countries into bins by their population densities, and then compute the mean vaccination rate within each bin. To be precise, we will divide the countries into $k$ bins based on *sample quantiles* -- *pandas* provides the `pd.qcut` function for just this purpose. The first bin will countain the lowest-density countries, the second bin will contain the next lowest density countries, and so forth. We'll leave understanding how to use `pd.qcut` as an exercise for the reader -- remember, the documentation is helpful!\n",
    "\n",
    "To answer this question, create a function named `partially_vaccinated_by_pop_density` that accepts three arguments: a DataFrame like `tots`, a DataFrame like `pops_fixed`, and an integer, `k`, and returns a Series of average vaccination rates within each of the $k$ bins described above.\n",
    "\n",
    "The index of the Series should be the population density bin(s) returned by `pd.qcut`, and values should be average vaccination rates for countries in those bins as decimal numbers between 0 and 1.\n",
    "\n",
    "The index should be in sorted ascending order so its easier to see if there is a relationship between vaccination rates and the population density of a country.\n",
    "\n",
    "**Note**:\n",
    "- The $k$ population density bins *must* be generated by using the `pd.qcut` function. This means the index of the returned series must contain objects of the type [pd.Interval](https://pandas.pydata.org/docs/reference/api/pandas.Interval.html) with `closed='Right'` which corresponds to an interval from a (exclusive) to b (inclusive) seen in math such as (a, b]\n",
    "- For the purposes of this question, we define vaccination rate to be the number of individuals with at least one dose divided by the total population. \n",
    "- You may note when getting the vaccination rates for countries that some of them are greater than 1, you should clip these values to keep them between 0 and 1 before calculating the average vaccination rate for the population density bins.\n",
    "- Note that your function will be doing a lot: it has to merge data sets, discretize the data into bins, compute vaccination rates, etc. Despite this, the code does not need to be all that long or complex -- it is possible to solve this with a handful of lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to see the result, and don't change this cell -- it is used by the tests\n",
    "bin_10 = partially_vaccinated_by_pop_density(tots, pops_fixed, 10)\n",
    "bin_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a plot of the mean vaccination rate by density bin - what do you think?\n",
    "bin_10.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for Part 1 of the project!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a name='part2'></a>\n",
    "\n",
    "## Part 2: Vaccine Effectiveness üíâ\n",
    "\n",
    "There has naturally been much interest in the effectiveness of COVID-19 vaccines. In particular, recent reports suggest that the effectiveness of vaccines ‚Äì and the Pfizer vaccine in particular ‚Äì may decrease over time. While this is true, the public perception of declining vaccine effectiveness has been affected by what is often a poor use of statistics by media outlets.\n",
    "\n",
    "For example, take the following blurb from [this article](https://www.cbc.ca/news/world/israel-covid-delta-variant-booster-1.6159472) on the Canadian Broadcasting Corporation's website (emphasis added):\n",
    "\n",
    "> Meanwhile, Israeli health officials reported what appeared to be a waning efficacy of the vaccine, including among those who had been double vaccinated. **Data showed that of the serious cases being admitted to hospital, around 60 per cent of patients were people who had been fully vaccinated**, though most were over 60 or with underlying health conditions.\n",
    "\n",
    "This stat sounds terrible ‚Äì if you're sick in a hospital bed with COVID-19, you're actually more likely to be vaccinated than not! If you're not a data scientist, you might come away with the conclusion that the vaccine is no longer effective against serious illness, or ‚Äì even worse ‚Äì that getting the vaccine will **increase** your risk of sickness. Of course, this statistic by itself is actually meaningless. For instance, imagine a world in which 100% of people are vaccinated. Then 100% of people admitted to the hospital will be vaccinated, too! In Question 8, we will explain the theory behind **vaccine effectiveness**, a statistic that more meaningfully measures the improvement in outcomes for vaccinated individuals over unvaccinated individuals.\n",
    "\n",
    "To start, let's load in some data. For this project, we'll work with a dataset of vaccine effectiveness in Israel through mid-summer 2021. The vaccination and hospitalization records in the dataset are real. Israel was mostly vaccinated using the Pfizer vaccine, and was one of the first places where lots of data on the Delta variant was gathered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Israeli COVID vaccinations data from the ‚òÅÔ∏è\n",
    "if not pathlib.Path(os.path.join('data', 'israel.csv')).exists():\n",
    "    urllib.request.urlretrieve(\n",
    "        'https://f000.backblazeb2.com/file/dsc-data/covid-israel/israel.csv',\n",
    "        os.path.join('data', 'israel.csv')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "israel_raw = pd.read_csv(os.path.join('data', 'israel.csv'))\n",
    "israel_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in the dataset is a person. Some are vaccinated (marked with a 1 in the \"Vaccinated\" column), and some became severely ill (marked with a 1 in the \"Severe Sickness\" column).\n",
    "\n",
    "As always, we will first check that the data is clean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 (‚úÖ Checkpoint Question)\n",
    "\n",
    "If you look at the data types of each column in `israel_raw`, you'll see that the `'Age'` column has a `dtype` of `object`. If you investigate further, you will see that a special value has been used to indicate that some ages are missing. Write a function named `clean_israel_data` that accepts a DataFrame like `israel_raw` and returns a *new* DataFrame where the missing ages are replaced by `np.NaN`s and the `'Age'` column's data type is `float`. Furthermore, the `'Vaccinated'` and `'Severe Sickness'` columns should be stored as `bool`s. The shape of the returned DataFrame should be the same as `israel_raw`, and, as usual, your function should not modify the input DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to see the result, and don't change this cell -- it is used by the tests\n",
    "israel = clean_israel_data(israel_raw)\n",
    "israel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to decide what to do with the missing values in the `'Age'` column. Can we simply drop those rows? First, let's look at whether the missing values might be MCAR, NMAR, missing by design, etc. We'll first check to see if the distribution of the other columns differs depending on whether the ages are missing or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "israel.assign(null_age=israel['Age'].isna()).groupby('null_age').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Because the vaccination rate and severe sickness rate appear to be about the same, whether or not `'Age'` is missing, we hypothesize that `'Age'` is MCAR (missing completely at random). Let's investigate.\n",
    "\n",
    "#### `mcar_permutation_tests`\n",
    "\n",
    "Write a function named `mcar_permutation_tests` that accepts two arguments ‚Äì a DataFrame like `israel` and a number `n_permutations` of permutations ‚Äì and runs the two permutation tests described below. Your function should return a 2-tuple where the first entry is an array of the simulated test statistics for the first permutation test, and the second entry is an array of simulated test statistics for the second permutation test.\n",
    "\n",
    "- The first permutation test should check the null hypothesis that values in the `'Vaccinated'` column for rows where the `'Age'` was missing were drawn from the same distribution as the values in rows where `'Age'` was not missing. The alternative hypothesis should be that they were drawn from *different* distributions. As your test statistic, use the **absolute difference in group means**. \n",
    "- The second permutation test should do the same, but for the `'Severe Sickness'` column.\n",
    "\n",
    "***Note:*** Your code should run in less than two minutes when called with `n_permutations=100`. You should be able to run both permutation tests in a single `for`-loop.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `missingness_type`\n",
    "\n",
    "Then, create a function named `missingness_type` that takes no arguments and returns a single integer corresponding to the option below that you think describes the type of missingess in this data:\n",
    "\n",
    "1. MCAR (Missing completely at random)\n",
    "2. MAR (Missing at random)\n",
    "3. NMAR (Not missing at random)\n",
    "4. Missing by design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to see the result, and don't change this cell -- it is used by the tests\n",
    "test_stats_vax, test_stats_sick = mcar_permutation_tests(israel, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's proceed by simply dropping the rows with missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "vax = israel.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving forward, use `vax`, not `israel`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8 (‚úÖ Checkpoint Question)\n",
    "\n",
    "***Note:*** Assume that \"hospitalization\" and \"severe illness\" mean the same thing; that is, if someone is hospitalized they developed severe illness and vice versa.\n",
    "\n",
    "As mentioned at the start of Part 2, looking at the probability of being vaccinated if you're hospitalized is meaningless, since if everyone is vaccinated, this probability will be 1. Instead, we care about **the probability of being hospitalized if you're vaccinated.** More than that, what we care most about is how this probability relates to the probability of being hospitalized if you're **unvaccinated**.\n",
    "\n",
    "To put it more concretely, let's say that 1 in 100 vaccinated people are hospitalized, while 10 in 100 unvaccinated people are hospitalized. This means that unvaccinated people are 10x more likely to be hospitalized than vaccinated people. To put it another way, if those 10 hospitalized unvaccinated people had been vaccinated, we'd expect that 9 of them would not have been hospitalized. That is, the vaccine would have prevented 90% of the hospitalizations, and we might therefore say that it is 90% effective against severe illness.\n",
    "\n",
    "This is the intuition behind the definition of **vaccine effectiveness** (see the CDC's [page](https://www.cdc.gov/csels/dsepd/ss1978/lesson3/section6.html) for more information). That is, to compute a vaccine's effectiveness, we need to know two things:\n",
    "\n",
    "1. The proportion of vaccinated people who developed severe illness (i.e., the probability that a vaccinated person will be hospitalized). Call this $p_V$.\n",
    "2. The proportion of unvaccinated people who developed severe illness (i.e., the probability that an unvaccinated person will be hospitalized). Call this $p_U$.\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "\\text{effectiveness} = 1 - \\frac{p_V}{p_U} = \\frac{p_U - p_V}{p_U}\n",
    "$$\n",
    "\n",
    "**What this formula calculates, in words, is the proportion of unvaccinated people with severe illness who would (we expect) not have severe illness if they were vaccinated.** For instance, if no one who is vaccinated becomes severely ill, then $p_V = 0$ and the effectiveness is 1 (100%). On the other hand, if the vaccine is no better than being unvaccinated, $p_V = p_U$ and the effectiveness is 0 (0%).\n",
    "\n",
    "\n",
    "Many news articles report effectiveness numbers, and this is certainly better than reporting the percentage of hospital patients that are vaccinated. Note, though, that there are different types of effectiveness ‚Äì effectiveness against severe illness, effectiveness against symptomatic illness, effectiveness against death ‚Äì and articles often are vague about which they are using. But even then, effectiveness can *still* be misleading due to statistical quirks, as we'll now see.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**Your job is to** create a function named `effectiveness` that accepts a DataFrame like `vax` and returns the effectiveness of the vaccine against severe illness as a proportion between 0 and 1.\n",
    "\n",
    "***Note:*** Assume that you will not run into any division-by-zero errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to see the result, and don't change this cell -- it is used by the tests\n",
    "eff_overall = effectiveness(vax)\n",
    "eff_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you implemented `effectiveness` correctly, you should see a vaccine effectiveness between 60% and 70%. This is OK, but not great! It means that the vaccine is only around 60-70% effective at preventing severe illness overall.\n",
    "\n",
    "But remember Simpson's Paradox, which roughly says that sometimes a result that appears in aggregated data disappears when we look at disaggregated data. So let's disaggregate the data and perform the same calculation. That is, let's compute the effectiveness of the vaccine within each of several age groups. For convenience, here is a list of the age groups we'll consider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGE_GROUPS = [\n",
    "    '12-15',\n",
    "    '16-19',\n",
    "    '20-29',\n",
    "    '30-39',\n",
    "    '40-49',\n",
    "    '50-59',\n",
    "    '60-69',\n",
    "    '70-79',\n",
    "    '80-89',\n",
    "    '90-'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each string above lists an age group. For example, the age group `'12-15'` should contain anyone aged 12, 13, 14, or 15. The last age group, '90-', denotes everyone who is 90 or above. `vax` does not contain anyone younger than 12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Create a function named `stratified_effectiveness` that accepts one argument ‚Äì a DataFrame like `vax` ‚Äì and returns the effectiveness of the vaccine within each of the age groups in `AGE_GROUPS`. The return value of the function should be a Series of the same length as `AGE_GROUPS`, with the index of the Series being age groups as strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to see the result, and don't change this cell -- it is used by the tests\n",
    "s_eff = stratified_effectiveness(vax)\n",
    "s_eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If done correctly, you should notice that the effectiveness of the vaccine within each age group is higher than the overall effectiveness. In fact, the effectiveness of every age group is above 80%, and for most age groups it is above 90%.\n",
    "\n",
    "This is an instance of [Simpson's paradox](https://dsc80.com/resources/lectures/lec08/lec08.html#Simpson's-paradox). This result might seem strange, or even impossible ‚Äì how can *every one* of the age groups see a higher effectiveness rate than the overall effectiveness rate? We'll take a deeper look at this in the next question, but for now let's consider a slightly different scenario where we can give dosages of a vaccine on a scale, so that some people can receive more vaccine than others. We expect that the higher a dosage someone receives, the less sick they become. But suppose we plot the data and we see something like this:\n",
    "\n",
    "<img src=\"./data/simpsons-aggregated.svg\">\n",
    "\n",
    "It actually looks like the more dosage someone receives, the more sick they get! But suppose we were to *disaggregate* the data into two age groups ‚Äì old and young. That is, let's look at the same plot, but now mark young people as red and older people as purple. We might see this:\n",
    "\n",
    "<img src=\"./data/simpsons.svg\">\n",
    "\n",
    "Now we see a different story: the larger the dosage, the less the sickness within each age group. Therefore, while the overall trend is a *positive* relationship between dosage and sickness, the within-group trends are all negative, as we'd hope. **The reason for this difference comes from the fact that, for each dosage level, the sickness rate of older people is greater than the sickness rate for younger people.**\n",
    "\n",
    "If our data gives different answers depending on how we aggregate it, which answer should we use? In this case, we don't care about overall effectiveness ‚Äì we care about how effective the vaccine will be for an *individual*. The data shows that, no matter what your age, unvaccinated people are ten times as likely to develop severe illness than vaccinated people, and it shows that the vaccine's effectiveness against severe illness is still quite strong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots above may help to understand Simpson's paradox a little bit more, but it may still be unclear how each age group's effectiveness rate can be higher than the overall effectiveness rate. To explore this in more depth, **we'll build a calculator that takes in several parameters and calculates three effectivenesses: the overall (aggregate) effectiveness, the effectiveness among young people, and the effectiveness among old people.** For simplicity, we'll assume that there are just as many old people as young people.\n",
    "\n",
    "To calculate these effectivenesses, you need to know six numbers:\n",
    "\n",
    "1. The proportion of young people that are vaccinated.\n",
    "2. The proportion of old people that are vaccinated.\n",
    "3. The probability that a young vaccinated person will be hospitalized.\n",
    "4. The probability that a young *un*vaccinated person will be hospitalized.\n",
    "5. The probability that an old vaccinated person will be hospitalized.\n",
    "6. The probability that an old *un*vaccinated person will be hospitalized.\n",
    "\n",
    "Given these six pieces of information, you can calculate the overall effectiveness, the effectiveness in young people, and the effectiveness in old people.\n",
    "\n",
    "How, you may ask? Well, to find the effectiveness in young people, you can use the effectiveness definition from [Question 8](#Question-8-(Checkpoint-Question)) ($1 - \\frac{p_V}{p_U}$) directly since you are given the probability that a young vaccinated person will be hospitalized ($p_V$, for young people) and the probability that a young unvaccinated person will be hospitalized ($p_U$, for young people). The same applies for the effectiveness in old people.\n",
    "\n",
    "To find the overall effectiveness, you need to find the values of $p_V$ and $p_U$ in the overall population, given  the six parameters that `effectiveness_calculator` takes in. \n",
    "- One approach is to express all six parameters in terms of conditional probability notation and to use your knowledge of probability theory from DSC 40A. One idea to look at in particular is the law of total probability ([Wikipedia article](https://en.wikipedia.org/wiki/Law_of_total_probability), [slides from DSC 40A](https://dsc-courses.github.io/dsc40a-2021-fa/resources/lecture/lec14-filled.pdf)).\n",
    "- Another approach is to fix concrete numbers. \n",
    "    - For instance, assume that there are 1000 old people and 1000 young people (recall, we are operating under the assumption there are an equal number of old and young people, for simplicity).\n",
    "    - To calculate the probability that a vaccinated person is hospitalized, you need to know the _number_ of vaccinated people that are hospitalized in this hypothetical example. If you're told that 20% of young people are vaccinated and that 10% of young vaccinated people will be hospitalized, you know that $1000 \\cdot 0.2 \\cdot 0.1 = 20$ young vaccinated people will be hospitalized. \n",
    "    - If you're also told that 60% of old people are vaccinated and that 30% of old vaccinated people will be hospitalized, then you know that $1000 \\cdot 0.6 \\cdot 0.3 = 180$ old vaccinated people will be hospitalized.\n",
    "    - This means that 200 of 800 ($1000 \\cdot 0.2 + 1000 \\cdot 0.6$) vaccinated people will be hospitalized, so the overall $p_V$ is $p_V = \\frac{200}{800} = 0.25$ in this example.\n",
    "    - You can do the same for unvaccinated people to find the overall $p_U$.\n",
    "    - Working with concrete numbers like this *is* using probability theory, just with extra steps. But it might be less abstract and easier to reason about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10 (‚úÖ Checkpoint Question)\n",
    "\n",
    "Create a function named `effectiveness_calculator` that accepts 6 arguments:\n",
    "\n",
    "1. `young_vaccinated_prop`: The proportion of young people that are vaccinated.\n",
    "2. `old_vaccinated_prop`: The proportion of old people that are vaccinated.\n",
    "3. `young_risk_vaccinated`: The probability that a young vaccinated person will be hospitalized.\n",
    "4. `young_risk_unvaccinated`: The probability that a young *un*vaccinated person will be hospitalized.\n",
    "5. `old_risk_vaccinated`: The probability that an old vaccinated person will be hospitalized.\n",
    "6. `old_risk_unvaccinated`: The probability that an old *un*vaccinated person will be hospitalized.\n",
    "\n",
    "It should return a dictionary with three keys: `'Overall'`, `'Young'`, and `'Old'`, whose values are the overall effectiveness, the effectiveness within young people, and the effectiveness within old people, respectively. This will allow you to experiment with Simpson's paradox by plugging in different values and seeing what happens.\n",
    "\n",
    "***Note:*** All arguments to `effectiveness_calculator` are numbers between 0 and 1 (inclusive).\n",
    "\n",
    "***Hint:*** You are given two example inputs to `effectiveness_calculator` ‚Äì one in the doctest and one in the notebook. Make sure your code works correctly for **both** of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to see the result, and don't change this cell -- it is used by the tests\n",
    "eff_example = effectiveness_calculator(\n",
    "    young_vaccinated_prop=0.01,\n",
    "    old_vaccinated_prop=0.99,\n",
    "    young_risk_vaccinated=0.01,\n",
    "    young_risk_unvaccinated=0.20,\n",
    "    old_risk_vaccinated=0.10,\n",
    "    old_risk_unvaccinated=0.50\n",
    ")\n",
    "eff_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be helpful to think about the result of your effectiveness calculator. In the example above, we have constructed an extreme situation where essentially all older people are vaccinated, but almost no younger people are. Therefore, when calculating the overall vaccine effectiveness, we're using the probability of illness given vaccination ‚Äì which is essentially the probability of severe illness if you're old ‚Äì and comparing it to the probability of severe illness if you're unvaccinated, which is essentially the probability of severe illness if you're young.\n",
    "\n",
    "In fact, it is possible to create an example where the overall effectiveness is negative (taking the vaccine is worse than not taking it!), but where the effectiveness within groups is above 80%. The next question asks you to do just this. \n",
    "\n",
    "To help you with your experimentation, we've created an animated version of your `effectiveness_calculator`, that allows you to test different arguments by dragging sliders. Run the next cell to use it.\n",
    "\n",
    "If you're curious, this sort of interactive tool is created using the `ipywidgets` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(effectiveness_calculator,\n",
    "         young_vaccinated_prop=FloatSlider(min=0.01, max=0.99, step=0.01, value=0.01),\n",
    "         old_vaccinated_prop=FloatSlider(min=0.01, max=0.99, step=0.01, value=0.99),\n",
    "         young_risk_vaccinated=FloatSlider(min=0.01, max=0.99, step=0.01, value=0.01),\n",
    "         young_risk_unvaccinated=FloatSlider(min=0.01, max=0.99, step=0.01, value=0.20),\n",
    "         old_risk_vaccinated=FloatSlider(min=0.01, max=0.99, step=0.01, value=0.10),\n",
    "         old_risk_unvaccinated=FloatSlider(min=0.01, max=0.99, step=0.01, value=0.50));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "Create a function named `extreme_example` that accepts no arguments and returns a dictionary whose keys are the arguments to the function `effectiveness_calculator`. When your function is called and the dictionary is passed to `effectiveness_calculator`, it should return an `'Overall'` effectiveness that is negative and `'Young'` and `'Old'` effectivenesses that are both over 0.8.\n",
    "\n",
    "***Note:*** Use the animated calculator above to help you, but **make sure to think about what the numbers mean**. There are many possible correct answers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to see the result, and don't change this cell -- it is used by the tests\n",
    "eff_extreme = effectiveness_calculator(**extreme_example())\n",
    "eff_extreme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations, you've finished Project 2! üéâ\n",
    "\n",
    "Submit your `project.py` file to Gradescope. Note that you only need to submit the `project.py` file; this notebook should not be uploaded because there are no manually-graded questions in this project.\n",
    "\n",
    "Before submitting, you should ensure that all of your work is in the `project.py` file. You can do this by running the doctests below, which will verify that your work passes the public tests **and** that your work is in the `project.py` file. Run the cell below; you should see no output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m doctest project.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, `grader.check_all()` will verify that your work passes the public tests. Ultimately, the Gradescope autograder is also going to run `grader.check_all()`, so you should ensure these pass as well (which they should if the doctests above passed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> count_monotonic(np.array([3, 6, 6, 2, 5, 8])) == 1\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(mono, pd.DataFrame)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> mono.shape == (194, 2)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> mono.loc['Zimbabwe', 'Doses_admin_monotonic'] == 4\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q10": {
     "name": "q10",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(eff_example, dict)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> eff_example.keys() == {'Overall', 'Young', 'Old'}\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> .4 < eff_example['Overall'] < .6\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> test_eff = effectiveness_calculator(young_vaccinated_prop=0.5, old_vaccinated_prop=0.5, young_risk_vaccinated=0.01, young_risk_unvaccinated=0.20, old_risk_vaccinated=0.01, old_risk_unvaccinated=0.20)\n>>> test_eff['Overall'] == test_eff['Young'] == test_eff['Old'] == 0.95\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q11": {
     "name": "q11",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(eff_extreme, dict)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> keys = {'old_risk_unvaccinated', 'young_risk_vaccinated', 'young_vaccinated_prop', 'old_risk_vaccinated', 'old_vaccinated_prop', 'young_risk_unvaccinated'}\n>>> extreme_example().keys() == keys\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> eff_extreme.keys() == {'Overall', 'Young', 'Old'}\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.25
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(tots, pd.DataFrame)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> tots.shape == (194, 2)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> int(tots.loc['Venezuela', 'Doses_admin']) == 37860994\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> int(tots.loc['Venezuela', 'People_at_least_one_dose']) == 22157232\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(pops, pd.DataFrame)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> pops.shape == (234, 5)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> pops.loc[pops['Country (or dependency)'] == 'Montserrat', 'Population in 2022'].iloc[0] == 4390\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(missing) == 11\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> ex_tots = pd.DataFrame({\n...             'Doses_admin': [1, 2, 3],\n...             'People_partially_vaccinated': [1, 2, 3],\n...             'People_fully_vaccinated': [1, 2, 3]\n...         },\n...         index = ['China', 'Angola', 'Republic of Data Science']\n...     )\n>>> missing_in_pops(ex_tots, pops)\n{'Republic of Data Science'}",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> isinstance(pops_fixed, pd.DataFrame)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> pops_fixed.shape == (234, 5)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.75
        },
        {
         "code": ">>> 'Burma' in pops_fixed['Country (or dependency)'].values\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> not 'Myanmar' in pops_fixed['Country (or dependency)'].values\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(bin_10, pd.Series)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> bin_10.size == 10\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> bin_10.index[0] == pd.Interval(2.172, 16.682, closed='right')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> tots_sample = pd.read_csv(os.path.join('data', 'tots_sample_for_tests.csv')).set_index('Country_Region')\n>>> partially_vaccinated_by_pop_density(tots_sample, pops_fixed, 10).index[2] == pd.Interval(25.964, 41.358, closed='right')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(israel, pd.DataFrame)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> israel.shape\n(6937542, 3)",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> str(israel.dtypes['Age'])\n'float64'",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(test_stats_vax, np.ndarray) and isinstance(test_stats_sick, np.ndarray)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> len(test_stats_vax) == len(test_stats_sick) == 100\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> missingness_type() in {1, 2, 3, 4}\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.25
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8": {
     "name": "q8",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(eff_overall, float)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> 0.6 < eff_overall < 0.7\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> 0.65 < eff_overall < 0.7\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> example_vax = pd.DataFrame({'Age': [15, 20, 25, 30, 35, 40], \n...                             'Vaccinated': [True, True, True, False, False, False], \n...                             'Severe Sickness': [True, False, False, False, True, True]})\n>>> effectiveness(example_vax)\n0.5",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q9": {
     "name": "q9",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(s_eff, pd.Series)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> len(s_eff)\n10",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> s_eff.loc['12-15'] == 1.0\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
