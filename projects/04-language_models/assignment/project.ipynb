{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "\n",
    "grader = otter.Notebook(\"project.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: Language Models ðŸ—£\n",
    "\n",
    "### Checkpoint Due Date: Thursday, Nov 17th at 11:59PM (Questions 1-4)\n",
    "\n",
    "### Due Date: Monday, Nov 28th at 11:59PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Welcome to Project 4! Project 4 will work similar to Projects 1 and 2, in that:\n",
    "- All of your code should go in `project.py`.\n",
    "- There is a checkpoint that is due a week before the project is due. (In this case, the checkpoint consists of Questions 1-4.)\n",
    "\n",
    "As per usual, you are able to work with a partner, provided that you follow the practice of [Pair Programming](http://dsc80.com/syllabus.html#pair-programming)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Assignment\n",
    "\n",
    "### Introduction to Language Models (LM)\n",
    "\n",
    "In this project, you will build *[statistical language models](https://en.wikipedia.org/wiki/Language_model)* using public domain books found on [Project Gutenberg](https://www.gutenberg.org/). Language models attempt to capture the likelihood that a given sequence of words occur in a given \"language\" (the precise term is \"corpus\" or \"corpora\"). Here, \"language\" is a broad term that, in addition to the normal usage, may mean the language of a particular author or style. As with all statistical models, the true data generating process is never known and thus we cannot know the true probability that a sequence of words will occur â€“ however, we can estimate these probabilities via various methods, some of which are more reliable than others. For example, one might guess that the probability of a sentence is simply the product of the empirical probabilities (i.e., the number of times a word is observed in a dataset divided by the number of words in that dataset). This is one of the methods of estimating the probability of a sequence of words that you will implement in this project.\n",
    "\n",
    "### Tokenizing Corpora\n",
    "\n",
    "Computing the probabilities of a language model from a book requires breaking up the text of book into sequences of words. This process is called *tokenization*. In reality though, the sequences are not made up entirely of words, but rather more general terms called *tokens*. In this project tokens will include not only whole words, but also punctuation and other terms. Below are a few examples of other types of tokens:\n",
    "\n",
    "* Punctuation. For example, the period makes sense as a token, as certain words tend to end sentences (i.e. appear right before a `'.'`), while other words tend to begin sentences (i.e. appear right after a `'.'`).\n",
    "* We have special \"START\" and \"END\" tokens that begin and end every word sequence (in our case, paragraphs of words in a given book). These make sense as tokens, as certain words may tend to begin and end paragraphs. \n",
    "\n",
    "It is useful for the tokens used to represent START and END to be single characters that can never be found in the text of the book you use to create your language model. Thus, you will use two ASCII hidden \"[control characters](https://en.wikipedia.org/wiki/C0_and_C1_control_codes#C0_(ASCII_and_derivatives))\":\n",
    "* For START, you will use the character `'\\x02'`, which refers to the \"beginning of text\".\n",
    "* For END, you will use the character `'\\x03'`, which refers to the \"end of text\".\n",
    "\n",
    "### A Note on Checking Your Work for Correctness\n",
    "\n",
    "To build a language model, you will need to perform several steps, from data cleaning to implementing mathematical formulas. **Things will get messy, and it can be difficult to assess the correctness of your work.**\n",
    "\n",
    "- The doctests will include checks on the inputs and outputs of your methods.\n",
    "- The `grade.check` public notebook tests will be **more informative** than the doctests, but they still won't guarantee that your code is correct.\n",
    "- The doctests include small-enough examples that you should be able to determine the correct outputs (e.g. probabilities) by hand.\n",
    "- Run your functions on **real books** taken from [Project Gutenberg](https://www.gutenberg.org/) and make sure that their behavior looks correct. After selecting a book, click the \"Plain Text UTF-8\" link to find the book's text ([example](https://www.gutenberg.org/cache/epub/68085/pg68085.txt))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Navigating the Project\n",
    "\n",
    "Below is an outline of the the project. If there are terms you don't understand in following descriptions, you should review the introduction for an explanation of the terms and ideas described.\n",
    "\n",
    "- [Part 1: Dissecting the Corpus ðŸªšðŸ«€](#part1)\n",
    "    - [Question 1: Preparing the Corpus (Checkpoint Question)](#question1)\n",
    "    - [Question 2: Tokenizing the Corpus (Checkpoint Question)](#question2)\n",
    "- [Part 2: Creating Baseline Language Models ðŸ“•](#part2)\n",
    "    - [Question 3: Uniform Language Models (Checkpoint Question)](#question3)\n",
    "    - [Question 4: Unigram Language Models (Checkpoint Question)](#question4)\n",
    "- [Part 3: Creating an N-Gram Language Model ðŸ“š](#part3)\n",
    "    - [Question 5.1: Creating N-Grams](#question5a)\n",
    "    - [Question 5.2: Training the N-Gram LM](#question5b)\n",
    "    - [Question 5.3: Computing Probabilities using the N-Gram Model](#question5c)\n",
    "    - [Question 5.4: Sampling from the N-Gram Model](#question5d)\n",
    "    \n",
    "**Disclaimer: You should expect Question 5/Part 3 to take the same amount of time as Parts 1 and 2 combined.** Do not leave it to the last minute just because it looks like there is only \"one question\"! Note also that the entire project is worth **105 points**, of which **48 come from Question 5/Part 3 alone**.\n",
    "\n",
    "Good luck â€“ let's get started! ðŸŽ‰\n",
    "    \n",
    "---\n",
    "\n",
    "While working on the project, check the Campuswire post titled \"Project 4 Released!\" for any clarifications.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Dissecting the Corpus ðŸªšðŸ«€\n",
    "\n",
    "<a name='part1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 â€“ Preparing the Corpus\n",
    "\n",
    "<a name='question1'></a>\n",
    "\n",
    "In this question, you will use `requests` to download a public domain book from [Project Gutenberg](https://www.gutenberg.org/), like [this one](http://www.gutenberg.org/files/57988/57988-0.txt), and prepare it for analysis in later questions. Create a function `get_book` that takes in the `url` of a \"Plain Text UTF-8\" book and **returns a string** containing the contents of the book. \n",
    "\n",
    "The returned string should satisfy the following conditions:\n",
    "* The contents of the book consist of **everything** between Project Gutenberg's START and END comments (but not including the START and END comments themselves).\n",
    "* The contents **do** include the title, author, and table of contents.\n",
    "* You should replace any Windows newline characters (`'\\r\\n'`) with standard newline characters (`'\\n'`).\n",
    "* You should check Project Gutenberg's [`robots.txt`](https://gutenberg.org/robots.txt) as well and implement a \"pause\" in your request in accordance with the website's policy. If the function is called twice in succession, it should not violate the `robots.txt` policy.\n",
    "\n",
    "***Notes:*** \n",
    "- There is no need to use BeautifulSoup here, so please don't import it.\n",
    "- You are encouraged to find whatever books on the website that interest you to test your code and the language models you develop. The text doesn't even need to be an English-language book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book(url):\n",
    "    \"\"\"\n",
    "    get_book that takes in the url of a 'Plain Text UTF-8' book and \n",
    "    returns a string containing the contents of the book.\n",
    "\n",
    "    The function should satisfy the following conditions:\n",
    "        - The contents of the book consist of everything between \n",
    "        Project Gutenberg's START and END comments.\n",
    "        - The contents will include title/author/table of contents.\n",
    "        - You should also transform any Windows new-lines (\\r\\n) with \n",
    "        standard new-lines (\\n).\n",
    "        - If the function is called twice in succession, it should not \n",
    "        violate the robots.txt policy.\n",
    "\n",
    "    :Example: (note '\\n' don't need to be escaped in notebooks!)\n",
    "    >>> url = 'http://www.gutenberg.org/files/57988/57988-0.txt'\n",
    "    >>> book_string = get_book(url)\n",
    "    >>> book_string[:20] == '\\\\n\\\\n\\\\n\\\\n\\\\nProduced by Chu'\n",
    "    True\n",
    "    \"\"\"\n",
    "    time.sleep(6)\n",
    "    try:\n",
    "        r=requests.get(url)\n",
    "        full= r.text\n",
    "        truncate_start = full.split('*** START')[1]\n",
    "        truncate_end = truncate_start.split(\"*** END\")[0]\n",
    "\n",
    "        remove_st = truncate_end.split('***')[1]\n",
    "        remove_st = re.sub(pattern=\"\\r\\n\", repl=\"\\n\", string= remove_st)\n",
    "\n",
    "        return remove_st\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\nProduced by Chu'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://www.gutenberg.org/files/57988/57988-0.txt'\n",
    "book_string = get_book(url)\n",
    "book_string[:20]# == '\\\\n\\\\n\\\\n\\\\n\\\\nProduced by Chu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests\n",
    "beowulf = get_book('https://www.gutenberg.org/ebooks/16328.txt.utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests\n",
    "homer = get_book('https://www.gutenberg.org/ebooks/1727.txt.utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1 results: All test cases passed!"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 â€“ Tokenizing the Corpus\n",
    "\n",
    "<a name='question2'></a>\n",
    "\n",
    "Now, you need to **tokenize** the text of a book. To do so, create a function `tokenize` that takes in a string, `book_string`, and returns a **list of the tokens** (words, numbers, and all punctuation) satisfying the following conditions:\n",
    "* The start of every paragraph should be represented in the list with the single character `'\\x02'` (standing for START).\n",
    "* The end of every paragraph should be represented in the list with the single character `'\\x03'` (standing for STOP).\n",
    "* Tokens should include *no* whitespace.\n",
    "* Two or more newlines count as a paragraph break. Whitespace (e.g. multiple newlines) between two paragraphs of text should not appear as tokens.\n",
    "* All punctuation marks count as tokens, even if they are uncommon (e.g. `'@'`, `'+'`, and `'%'` are all valid tokens).\n",
    "\n",
    "For example, consider the following excerpt. (The first sentence is at the end of a larger paragraph, and the second sentence is at the start of a longer paragraph.)\n",
    "```\n",
    "...\n",
    "My phone's dead.\n",
    "\n",
    "I didn't get your call.\n",
    "...\n",
    "```\n",
    "should tokenize to:\n",
    "```py\n",
    "[...\n",
    "'My', 'phone', \"'\", 's', 'dead', '.', '\\x03', '\\x02', 'I', 'didn', \"'\", 't', 'get', 'your', 'call', '.'\n",
    "...]\n",
    "```\n",
    "\n",
    "***Note:*** `tokenize` should run quickly; you should avoid loops when possible (our solution only has one loop). Specifically, `tokenize` should run on the the complete works of Shakespeare (in `data/shakespeare.txt`) in **under 10 seconds** to get full credit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(book_string):\n",
    "    \"\"\"\n",
    "    tokenize takes in book_string and outputs a list of tokens \n",
    "    satisfying the following conditions:\n",
    "        - The start of every paragraph should be represented in the \n",
    "        list with the single character \\x02 (standing for START).\n",
    "        - The end of every paragraph should be represented in the list \n",
    "        with the single character \\x03 (standing for STOP).\n",
    "        - Tokens should include no whitespace.\n",
    "        - Whitespace (e.g. multiple newlines) between two paragraphs of text \n",
    "          should be ignored, i.e. they should not appear as tokens.\n",
    "        - Two or more newlines count as a paragraph break.\n",
    "        - All punctuation marks count as tokens, even if they are \n",
    "          uncommon (e.g. `'@'`, `'+'`, and `'%'` are all valid tokens).\n",
    "\n",
    "\n",
    "    :Example:\n",
    "    >>> test_fp = os.path.join('data', 'test.txt')\n",
    "    >>> test = open(test_fp, encoding='utf-8').read()\n",
    "    >>> tokens = tokenize(test)\n",
    "    >>> tokens[0] == '\\x02'\n",
    "    True\n",
    "    >>> tokens[9] == 'dead'\n",
    "    True\n",
    "    >>> sum([x == '\\x03' for x in tokens]) == 4\n",
    "    True\n",
    "    >>> '(' in tokens\n",
    "    True\n",
    "    \"\"\"\n",
    "    tokens = [\"\\x02\"]\n",
    "\n",
    "    test = book_string.strip()\n",
    "    test = re.sub(pattern=\"\\n{2,}\", repl=\" \\x03 \\x02 \", string= test)\n",
    "    test = re.sub(pattern=\" {1,}\", repl=\" \", string= test)\n",
    "    test = re.sub(r\"([\\W]+|[^\\w/'+$\\s-]+)\\s*\", r\" \\1 \", string= test)\n",
    "    test = re.sub(pattern=\"\\n\", repl=\" \", string= test)\n",
    "    test = re.sub(pattern=\"[.]\", repl= \" . \", string= test)\n",
    "\n",
    "    tokens.extend(test.split())\n",
    "    tokens.append(\"\\x03\")\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fp = os.path.join('data', 'test.txt')\n",
    "test = open(test_fp, encoding='utf-8').read()\n",
    "\n",
    "\n",
    "pretoken = test.split(' ')\n",
    "tokens = [\"\\x02\"]\n",
    "\n",
    "test = re.sub(pattern=\"\\n{2,}\", repl=\" \\x03 \\x02 \", string= test)\n",
    "test = re.sub(r\"([\\W]+|[^\\w/'+$\\s-]+)\\s*\", r\" \\1 \", string= test)\n",
    "test = re.sub(pattern=\"\\n\", repl=\" \", string= test)\n",
    "test = re.sub(pattern=\"[.]\", repl= \" . \", string= test)\n",
    "\n",
    "tokens.extend(test.split())\n",
    "tokens.append(\"\\x03\")\n",
    "\n",
    "'(' in tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "st =  'call.\\n\\nThis'\n",
    "\n",
    "if re.search(pattern=\"\\n{2,}\", string= st):\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to prepare the autograder tests. It runs your `tokenize` function on the full body of Shakespeare's work. As a guide, you should expect the first three elements of `shakes` to be `'\\x02'`, `'The'`, and `'Complete'`, and the last three elements of `shakes` to be `'William'`, `'Shakespeare'`, and `'\\x03'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7730958461761475"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests\n",
    "import time\n",
    "start = time.time()\n",
    "shakes = tokenize(open('data/shakespeare.txt', encoding=\"utf-8\").read())\n",
    "elapsed = time.time() - start\n",
    "elapsed # Should be under 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['by', 'William', 'Shakespeare', '\\x03']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakes[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests\n",
    "homer = tokenize(open('data/homertokens.txt').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2 results: All test cases passed!"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a name='part2'></a>\n",
    "\n",
    "## Part 2: Creating Baseline Language Models ðŸ“•\n",
    "\n",
    "Now that we're able to tokenize a corpus, it is time to start building language models (LM).\n",
    "\n",
    "In this project, we will build three different language models. They all operate under the premise of assigning probabilities to sentences. Given a sentence â€“ that is, a sequence of tokens $w = w_1\\ldots w_n$ â€“ we want to be able to compute the **probability** that sentence is used: \n",
    "$$P(w) = P(w_1,\\ldots,w_n)$$\n",
    "\n",
    "However, sentences are built from tokens, and the likelihood that a token occurs where it does depends on the tokens before it. This points to using **conditional probability** to compute $P(w)$. That is, we can write:\n",
    "\n",
    "$$\n",
    "P(w) = P(w_1,\\ldots,w_n) = P(w_1) \\cdot P(w_2|w_1) \\cdot P(w_3|w_1,w_2) \\cdot\\ldots\\cdot P(w_n|w_1,\\ldots,w_{n-1})\n",
    "$$  \n",
    "This is also called the **chain rule** for probabilities.\n",
    "\n",
    "**Example:** Consider the sentence \n",
    "\n",
    "<center><code>'when I drink Coke I smile'</code></center>\n",
    "    \n",
    "The probability that it occurs, according the the chain rule, is\n",
    "\n",
    "$$\n",
    "P(\\text{when}) \\cdot P(\\text{I | when}) \\cdot P(\\text{drink | when I})\\cdot P(\\text{Coke | when I drink}) \\cdot P(\\text{I | when I drink Coke}) \\cdot P(\\text{smile | when I drink Coke I})\n",
    "$$\n",
    "\n",
    "That is, the probability that the sentence occurs is the product of the probability that each subsequent token follows the tokens that came before. For example, the probability $P(\\text{Coke | when I drink})$ is likely pretty high, as Coke is something that you drink. The probability $P(\\text{pizza | when I drink})$ is likely low (if not 0), because pizza is not something that you drink.\n",
    "\n",
    "You may wonder how the language model \"knows\" that Coke is something that you drink, but pizza is not. The way that the language model \"learns\" its probabilities is by **looking at examples of existing sentences**, i.e. by being **trained on a corpus**. Throughout Parts 2 and 3, you will look at **different ways of estimating these probabilities**. In each case, you will use a corpus to assign probabilities to different tokens and combinations of tokens, and use those probabilities to generate new sentences.\n",
    "\n",
    "<br>\n",
    "\n",
    "Each language model you build will be a **class** with a few methods in common:\n",
    "\n",
    "* The `__init__` constructor: when you instantiate an LM object, you will need to pass the \"training corpus\" on which your model will be trained (i.e. a list of tokens you created in Question 2 with `tokenize`). The `train` method will then use that data to create a model which is saved in the `mdl` attribute. This code is given to you.\n",
    "* The `train` method takes in a list of tokens (e.g. the output of `tokenize`) and outputs a language model. **This language model is represented as a `Series`, whose index consists of tokens and whose values are the probabilities that the tokens occur.** (In the case of the N-Gram model in Part 3/Question 5, the model will be represented as a DataFrame instead of a Series â€“ more on this later.)\n",
    "* The `probability` method takes in a sequence of tokens and returns the probability that this sequence occurs under the language model.\n",
    "* The `sample` method takes in a positive integer `M` and generates a string made up of `M` tokens using the language model. **This method generates random sentences!**\n",
    "\n",
    "The description of Question 3 walks through in detail how each of these methods work. However, here's the general workflow:\n",
    "\n",
    "$$\\text{initialize LM with tokenized corpus} \\rightarrow \\text{train LM (i.e. assign probabilities to each token) using corpus} \\rightarrow \\text{used trained LM to compute probabilities of input sentences and generate random sentences}$$\n",
    "\n",
    "In Questions 3, 4, and 5, you will create classes for different language models â€“ uniform, unigram, and N-Gram, respectively. In each class, you will implement each of the above methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 â€“ Uniform Language Models\n",
    "\n",
    "<a name='question3'></a>\n",
    "\n",
    "A uniform language model is one in which each **unique** word is equally likely to appear in any position, unconditional of any other information.\n",
    "\n",
    "Let's put into context what this means by using the following example corpus:\n",
    "\n",
    "```py\n",
    ">>> corpus = 'when I eat pizza, I smile, but when I drink Coke, my stomach hurts'\n",
    ">>> tokenize(corpus)\n",
    "['\\x02', 'when', 'I', 'eat', 'pizza', ',', 'I', 'smile', ',', 'but', 'when', 'I', 'drink', 'Coke', ',', 'my', 'stomach', 'hurts', '\\x03']\n",
    "```\n",
    "\n",
    "Given a tokenized corpus, you need to build the language model itself in `train`. As mentioned above, language models are stored as Series, where words are the index and probabilities are the values. **In a uniform language model**, the probability assigned to each token is **1 over the total number of unique tokens in the corpus**.\n",
    "\n",
    "The example corpus above has 14 **unique** tokens. This means that we'd have $P(\\text{\\x02}) = \\frac{1}{14}$, $P(\\text{when}) = \\frac{1}{14}$, and so on. Specifically, in this example, **the Series that `train` returns should contain the following values**:\n",
    "\n",
    "| Token | Probability |\n",
    "| --- | --- |\n",
    "| `'\\x02'` | $\\frac{1}{14}$ |\n",
    "| `'when'` | $\\frac{1}{14}$ |\n",
    "| `'I'` | $\\frac{1}{14}$ |\n",
    "| `'eat'` | $\\frac{1}{14}$ |\n",
    "| `'pizza'` | $\\frac{1}{14}$ |\n",
    "| `','` | $\\frac{1}{14}$ |\n",
    "| `'smile'` | $\\frac{1}{14}$ |\n",
    "| `'but'` | $\\frac{1}{14}$ |\n",
    "| `'drink'` | $\\frac{1}{14}$ |\n",
    "| `'Coke'` | $\\frac{1}{14}$ |\n",
    "| `'my'` | $\\frac{1}{14}$ |\n",
    "| `'stomach'` | $\\frac{1}{14}$ |\n",
    "| `'hurts'` | $\\frac{1}{14}$ |\n",
    "| `'\\x03'` | $\\frac{1}{14}$ |\n",
    "\n",
    "Note that:\n",
    "- **None of the probabilities we computed are conditional â€“ the uniform model does not use conditional probabilities!**\n",
    "- When looking at the Series that `train` returns (i.e. when looking at the `mdl` attribute), the `'\\x02'` and `'\\x03'` characters will show up as blank characters in the index. This is to be expected.\n",
    "- Your Series doesn't need to have the labels `'Token'` or `'Probability'` in it, like the above table does.\n",
    "\n",
    "After training the model, you need to implement two more methods, `probability` and `sample`.\n",
    "\n",
    "`probability` should take in any tuple of tokens and use the probabilities you computed in `train` (that are stored in the `mdl` attribute) to assign a probability to that sequence. For instance, suppose the input tuple is `('when', 'I', 'drink', 'Coke', 'I', 'smile')` (note that this tuple does not need to start with `'\\x02'` or end with `'\\x03'`). To compute the probability of this tuple under our language model, we would multiply the \"trained\" probabilities for each word individually. Here that would give us \n",
    "\n",
    "$$P(\\text{when I drink Coke I smile}) = P(\\text{when}) \\cdot P(\\text{I}) \\cdot P(\\text{drink}) \\cdot P(\\text{Coke}) \\cdot P(\\text{I}) \\cdot P(\\text{smile}) = \\left( \\frac{1}{14} \\right)^6$$\n",
    "\n",
    "Note that if the input tuple contains a token that was not in our corpus, `probability` should return 0.\n",
    "\n",
    "Finally, `sample` should take in a positive integer, `M`, and return a sentence made up of `M` randomly sampled tokens, in which the probabilities come from `mdl`. For instance, if `M=5`, then we'd return a sentence containing 5 randomly selected tokens from the table above, such that the probability that each token is selected is $\\frac{1}{14}$. The sampling is done with replacement, so we could end up with the same token multiple times. For instance, we might end up with `'but drink smile drink hurts'`. Note that this sentence doesn't make any grammatical sense (that's okay!) and that tokens are separated by spaces.\n",
    "\n",
    "The starter code contains a class `UniformLM` which represents a uniform language model. Complete the implementation of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tip: Test out your UniformLM class on the \"shakes\" corpus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniformLM(object):\n",
    "    \"\"\"\n",
    "    Uniform Language Model class.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tokens):\n",
    "        \"\"\"\n",
    "        Initializes a Uniform languange model using a\n",
    "        list of tokens. It trains the language model\n",
    "        using `train` and saves it to an attribute\n",
    "        self.mdl.\n",
    "        \"\"\"\n",
    "        self.mdl = self.train(tokens)\n",
    "        \n",
    "    def train(self, tokens):\n",
    "        \"\"\"\n",
    "        Trains a uniform language model given a list of tokens.\n",
    "        The output is a series indexed on distinct tokens, and\n",
    "        values giving the (uniform) probability of a token occuring\n",
    "        in the language.\n",
    "\n",
    "        :Example:\n",
    "        >>> tokens = tuple('one one two three one two four'.split())\n",
    "        >>> unif = UniformLM(tokens)\n",
    "        >>> isinstance(unif.mdl, pd.Series)\n",
    "        True\n",
    "        >>> set(unif.mdl.index) == set('one two three four'.split())\n",
    "        True\n",
    "        >>> (unif.mdl == 0.25).all()\n",
    "        True\n",
    "        \"\"\"\n",
    "        out_dt = {token:1 for token in tokens}\n",
    "\n",
    "        return pd.Series(out_dt)/len(out_dt)\n",
    "    \n",
    "    def probability(self, words):\n",
    "        \"\"\"\n",
    "        probability gives the probabiliy a sequence of words\n",
    "        appears under the language model.\n",
    "        :param: words: a tuple of tokens\n",
    "        :returns: the probability `words` appears under the language\n",
    "        model.\n",
    "\n",
    "        :Example:\n",
    "        >>> tokens = tuple('one one two three one two four'.split())\n",
    "        >>> unif = UniformLM(tokens)\n",
    "        >>> unif.probability(('five',))\n",
    "        0\n",
    "        >>> unif.probability(('one', 'two')) == 0.0625\n",
    "        True\n",
    "        \"\"\"\n",
    "        if all(i in self.mdl.index for i in set(words)):\n",
    "            return np.prod([self.mdl[word] for word in words])\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def sample(self, M):\n",
    "        \"\"\"\n",
    "        sample selects tokens from the language model of length M, returning\n",
    "        a string of tokens.\n",
    "\n",
    "        :Example:\n",
    "        >>> tokens = tuple('one one two three one two four'.split())\n",
    "        >>> unif = UniformLM(tokens)\n",
    "        >>> samp = unif.sample(1000)\n",
    "        >>> isinstance(samp, str)\n",
    "        True\n",
    "        >>> len(samp.split()) == 1000\n",
    "        True\n",
    "        >>> s = pd.Series(samp.split()).value_counts(normalize=True)\n",
    "        >>> np.isclose(s, 0.25, atol=0.05).all()\n",
    "        True\n",
    "        \"\"\"\n",
    "        lst = list(np.random.choice(\n",
    "                            a = self.mdl.index, \n",
    "                            p= self.mdl.values, \n",
    "                            size=M\n",
    "                            ))\n",
    "\n",
    "        return ' '.join(lst)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# QUESTION 4\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class UnigramLM(object):\n",
    "    \n",
    "    def __init__(self, tokens):\n",
    "        \"\"\"\n",
    "        Initializes a Unigram languange model using a\n",
    "        list of tokens. It trains the language model\n",
    "        using `train` and saves it to an attribute\n",
    "        self.mdl.\n",
    "        \"\"\"\n",
    "        self.mdl = self.train(tokens)\n",
    "    \n",
    "    def train(self, tokens):\n",
    "        \"\"\"\n",
    "        Trains a unigram language model given a list of tokens.\n",
    "        The output is a series indexed on distinct tokens, and\n",
    "        values giving the probability of a token occuring\n",
    "        in the language.\n",
    "\n",
    "        :Example:\n",
    "        >>> tokens = tuple('one one two three one two four'.split())\n",
    "        >>> unig = UnigramLM(tokens)\n",
    "        >>> isinstance(unig.mdl, pd.Series)\n",
    "        True\n",
    "        >>> set(unig.mdl.index) == set('one two three four'.split())\n",
    "        True\n",
    "        >>> unig.mdl.loc['one'] == 3 / 7\n",
    "        True\n",
    "        \"\"\"\n",
    "        out_dt = {}\n",
    "\n",
    "        for token in tokens:\n",
    "            if token not in out_dt.keys():\n",
    "                out_dt[token]= 1\n",
    "            else:\n",
    "                out_dt[token]+=1\n",
    "\n",
    "        return pd.Series(out_dt)/len(tokens)\n",
    "    \n",
    "    def probability(self, words):\n",
    "        \"\"\"\n",
    "        probability gives the probabiliy a sequence of words\n",
    "        appears under the language model.\n",
    "        :param: words: a tuple of tokens\n",
    "        :returns: the probability `words` appears under the language\n",
    "        model.\n",
    "\n",
    "        :Example:\n",
    "        >>> tokens = tuple('one one two three one two four'.split())\n",
    "        >>> unig = UnigramLM(tokens)\n",
    "        >>> unig.probability(('five',))\n",
    "        0\n",
    "        >>> p = unig.probability(('one', 'two'))\n",
    "        >>> np.isclose(p, 0.12244897959, atol=0.0001)\n",
    "        True\n",
    "        \"\"\"\n",
    "        if all(i in self.mdl.index for i in words):\n",
    "            return np.prod([self.mdl[word] for word in words])\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def sample(self, M):\n",
    "        \"\"\"\n",
    "        sample selects tokens from the language model of length M, returning\n",
    "        a string of tokens.\n",
    "\n",
    "        >>> tokens = tuple('one one two three one two four'.split())\n",
    "        >>> unig = UnigramLM(tokens)\n",
    "        >>> samp = unig.sample(1000)\n",
    "        >>> isinstance(samp, str)\n",
    "        True\n",
    "        >>> len(samp.split()) == 1000\n",
    "        True\n",
    "        >>> s = pd.Series(samp.split()).value_counts(normalize=True).loc['one']\n",
    "        >>> np.isclose(s, 0.41, atol=0.05).all()\n",
    "        True\n",
    "        \"\"\"\n",
    "        lst = list(np.random.choice(\n",
    "                            a = self.mdl.index, \n",
    "                            p= self.mdl.values, \n",
    "                            size=M))\n",
    "\n",
    "        return ' '.join(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = 'when I eat pizza, I smile, but when I drink Coke, my stomach hurts'\n",
    "tokens = tokenize(corpus)\n",
    "\n",
    "out_dt = {token:1 for token in tokens}\n",
    "\n",
    "out = pd.Series(out_dt)/len(out_dt)\n",
    "\n",
    "words = ('when', 'I', 'drink', 'Coke', 'I', 'smile')\n",
    "\n",
    "probs = [out[word] for word in words]\n",
    "\n",
    "np.prod(probs)\n",
    "\n",
    "out\n",
    "\n",
    "set(words).issubset(tuple(out.index))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my stomach when but smile'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = 5\n",
    "\n",
    "' '.join(list(np.random.choice(a = out.index, p= out.values, size=M)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0013717421124828531"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = (tuple(['again','had']))\n",
    "\n",
    "if all(i in hidden_unif.mdl.index for i in set(words)):\n",
    "        out =  np.prod([hidden_unif.mdl[word] for word in words])\n",
    "else:\n",
    "        out=  0\n",
    "\n",
    "out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'three one one four one one three four three four two one four three four four two two one two three four four one three one four four two two two two three one two one two four four three two four four two two two one two two two one one two four three four three one two four four three three three one two two one three four four one four two two four four three two four two one one one one three three two four one four two four two three three two four two two'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests\n",
    "tokens = tuple('one one two three one two four'.split())\n",
    "unif = UniformLM(tokens)\n",
    "unif.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests\n",
    "hidden_tokens = \"\\x02 Humpty Dumpty sat on a wall , Humpty Dumpty had a great fall . \\x03 \\x02 All the king ' s horses and all the king ' s men couldn ' t put Humpty together again . \\x03\".split()\n",
    "hidden_tokens = tuple(hidden_tokens)\n",
    "hidden_unif = UniformLM(hidden_tokens)\n",
    "\n",
    "hidden_unif.probability(('five',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3 results: All test cases passed!"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 â€“ Unigram Language Models\n",
    "\n",
    "<a name='question4'></a>\n",
    "\n",
    "A unigram language model is one in which the **probability assigned to a token is equal to the proportion of tokens in the corpus that are equal to said token**. That is, the probability distribution associated with a unigram language model is just the empirical distribution of tokens in the corpus. \n",
    "\n",
    "Let's understand how probabilities are assigned to tokens using our example corpus from before.\n",
    "\n",
    "```py\n",
    ">>> corpus = 'when I eat pizza, I smile, but when I drink Coke, my stomach hurts'\n",
    ">>> tokenize(corpus)\n",
    "['\\x02', 'when', 'I', 'eat', 'pizza', ',', 'I', 'smile', ',', 'but', 'when', 'I', 'drink', 'Coke', ',', 'my', 'stomach', 'hurts', '\\x03']\n",
    "```\n",
    "\n",
    "Here, there are 19 total tokens. 3 of them are equal to `'I'`, so $P(\\text{I}) = \\frac{3}{19}$. Here, the Series that `train` returns should contain the following values:\n",
    "\n",
    "| Token | Probability |\n",
    "| --- | --- |\n",
    "| `'\\x02'` | $\\frac{1}{19}$ |\n",
    "| `'when'` | $\\frac{2}{19}$ |\n",
    "| `'I'` | $\\frac{3}{19}$ |\n",
    "| `'eat'` | $\\frac{1}{19}$ |\n",
    "| `'pizza'` | $\\frac{1}{19}$ |\n",
    "| `','` | $\\frac{3}{19}$ |\n",
    "| `'smile'` | $\\frac{1}{19}$ |\n",
    "| `'but'` | $\\frac{1}{19}$ |\n",
    "| `'drink'` | $\\frac{1}{19}$ |\n",
    "| `'Coke'` | $\\frac{1}{19}$ |\n",
    "| `'my'` | $\\frac{1}{19}$ |\n",
    "| `'stomach'` | $\\frac{1}{19}$ |\n",
    "| `'hurts'` | $\\frac{1}{19}$ |\n",
    "| `'\\x03'` | $\\frac{1}{19}$ |\n",
    "\n",
    "As before, the `probability` method should take in a tuple and return its probability, using the probabilities stored in `mdl`. For instance, suppose the input tuple is `('when', 'I', 'drink', 'Coke', 'I', 'smile')`. Then,\n",
    "\n",
    "$$P(\\text{when I drink Coke I smile}) = P(\\text{when}) \\cdot P(\\text{I}) \\cdot P(\\text{drink}) \\cdot P(\\text{Coke}) \\cdot P(\\text{I}) \\cdot P(\\text{smile}) = \\frac{2}{19} \\cdot \\frac{3}{19} \\cdot \\frac{1}{19} \\cdot \\frac{1}{19} \\cdot \\frac{3}{19} \\cdot \\frac{1}{19}$$\n",
    "\n",
    "The `sample` method should now account for the fact that not all tokens are equally likely to be sampled. For instance, `'I'` is much more likely to appear in a randomly generated sentence created by `sample` than `'Coke'` is.\n",
    "\n",
    "The starter code contains a class `UnigramLM` which represents a uniform language model. Complete the implementation of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tip: Test out your UnigramLM class on the \"shakes\" corpus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one      0.428571\n",
       "two      0.285714\n",
       "three    0.142857\n",
       "four     0.142857\n",
       "dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tuple('one one two three one two four'.split())\n",
    "unigram = UnigramLM(tokens)\n",
    "\n",
    "unigram.mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'three four four three one one one one one three two two four two two two two four three three two four two four three one four two one four two two four four one one two one one two one two three two one four one one one two one four two four one four four one two four four one one one two two two one two three one one two one two two one one four one two three one two two one four four two one three two one three two one one four two one'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests\n",
    "tokens = tuple('one one two three one two four'.split())\n",
    "unigram = UnigramLM(tokens)\n",
    "unigram.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests\n",
    "tokens = \"\\x02 Humpty Dumpty sat on a wall , Humpty Dumpty had a great fall . \\x03 \\x02 All the king ' s horses and all the king ' s men couldn ' t put Humpty together again . \\x03\".split()\n",
    "tokens = tuple(tokens)\n",
    "ugrm = UnigramLM(tokens)\n",
    "\n",
    "ugrm.probability(tuple(['Humpty','blahblah']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q4 results: All test cases passed!"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: Baseline Language Models\n",
    "\n",
    "You've now trained two baseline language models capable of generating new text from a given training text. Attempt to answer these questions for yourself before you continue.\n",
    "\n",
    "* Which model do you think is better? Why?\n",
    "* What are the ways in which both of these models are bad?\n",
    "\n",
    "If you haven't trained your models on the `shakes` corpus, uncomment and run the cells below to do so and generate new random \"sentences\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run â€“ should take less than 10 seconds\n",
    "shakes_uniform = UniformLM(shakes)\n",
    "shakes_unigram = UnigramLM(shakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'motions prose _Cornets 876 Begd allies really bouncing GARGRAVE 131'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment and run\n",
    "shakes_uniform.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'host shun FALSTAFF God down might his O slaught calf'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment and run\n",
    "shakes_unigram.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a name='part3'></a>\n",
    "\n",
    "## Part 3: Creating an N-Gram Language Model ðŸ“š\n",
    "\n",
    "### Recap\n",
    "\n",
    "First, let's recap what we've done so far. Recall the chain rule for probability, where $w$ is a sentence made up of tokens $w_1, w_2, ..., w_n$:\n",
    "\n",
    "$$P(w) = P(w_1,\\ldots,w_n) = P(w_1) \\cdot P(w_2|w_1) \\cdot P(w_3|w_1,w_2) \\cdot\\ldots\\cdot P(w_n|w_1,\\ldots,w_{n-1})$$\n",
    "\n",
    "In Questions 3 (Uniform) and 4 (Unigram), your `train` methods computed these probabilities **unconditionally**, meaning that the probability that a token appeared in a sentence did **not depend** on the other tokens around it. That is, you said $P(w_i | w_1, w_2, ..., w_{i - 1}) = P(w_i)$. In Question 3, you let $P(w_i) = \\frac{1}{\\text{# unique tokens in corpus}}$, and in Question 4, you let $P(w_i) = \\frac{\\text{# tokens in corpus equal to $w_i$}}{\\text{# tokens in corpus}}$. Cruciually, each probability was determined by looking at the corpus that the model was trained on.\n",
    "\n",
    "<br>\n",
    "\n",
    "### N-Gram Overview\n",
    "\n",
    "Now we will build an N-Gram language model, in which the probability of a token appearing in a sentence **does depend** on the tokens that come before it. \n",
    "\n",
    "The chain rule above specifies that the probability that a token occurs at in a particular position in a sentence depends on **all** previous tokens in the sentence. However, it is often the case that the likelihood that a token appears in a sentence is influenced more by **nearby** tokens. (Remember, tokens are words, punctuation, or `'\\x02'` / `'\\x03'`).\n",
    "\n",
    "The N-Gram language model relies on the assumption that only nearby tokens matter. Specifically, it assumes that the probability that a token occurs depends only on the previous $N-1$ tokens, rather than all previous tokens. That is:\n",
    "\n",
    "$$P(w_n|w_1,\\ldots,w_{n-1}) = P(w_n|w_{n-(N-1)},\\ldots,w_{n-1})$$\n",
    "\n",
    "In an N-Gram language model, there is a hyperparameter that we get to choose when creating the model, $N$. For any $N$, the resulting N-Gram model looks at the previous $N-1$ tokens when computing probabilities. (Note that the unigram model you built in Question 4 is really an N-Gram model with $N=1$, since it looked at 0 previous tokens when computing probabilities.)\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Example: Trigram Model\n",
    "\n",
    "When $N=3$, we have a \"trigram\" model. Such a model looks at the previous $N-1 = 2$ tokens when computing probabilities.\n",
    "\n",
    "Consider the tuple `('when', 'I', 'drink', 'Coke', 'I', 'smile')`, corresponding to the sentence `'when I drink Coke I smile'`. Under the trigram model, the probability of this sentence is computed as follows:\n",
    "\n",
    "$$P(\\text{when I drink Coke I smile}) = P(\\text{when}) \\cdot P(\\text{I | when}) \\cdot P(\\text{drink | when I}) \\cdot P(\\text{Coke | I drink}) \\cdot P(\\text{I | drink Coke}) \\cdot P(\\text{smile | Coke I})$$\n",
    "\n",
    "The trigram model doesn't consider the beginning of the sentence when computing the probability that the sentence ends in `'smile'`.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### N-Grams\n",
    "\n",
    "Both when working with a training corpus and when implementing the `probability` method to compute the probabilities of other sentences, you will need to work with \"chunks\" of $N$ tokens at a time.\n",
    "\n",
    "**Definition:** The **N-Grams of a text** are a list of tuples containing sliding windows of length $N$.\n",
    "\n",
    "For instance, the trigrams in the sentence `'when I drink Coke I smile'` are:\n",
    "\n",
    "```py\n",
    "[('when', 'I', 'drink'), ('I', 'drink', 'Coke'), ('drink', 'Coke', 'I'), ('Coke', 'I', 'smile')]\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Computing N-Gram Probabilities\n",
    "\n",
    "Notice in our trigram model above, we computed $P(\\text{when I drink Coke I smile})$ as being the product of several conditional probabilities. These conditional probabilities are the result of **training** our N-Gram model on a training corpus.\n",
    "\n",
    "To train an N-Gram model, we must compute a conditional probability for every $N$-token sequence in the corpus. For instance, suppose again that we are training a trigram model. Then, for every 3-token sequence $w_1, w_2, w_3$, we must compute $P(w_3 | w_1, w_2)$. To do so, we use:\n",
    "\n",
    "$$P(w_3 | w_1, w_2) = \\frac{C(w_1, w_2, w_3)}{C(w_1, w_2)}$$\n",
    "\n",
    "where $C(w_1, w_2, w_3)$ is the number of occurrences of the trigram sequence $w_1, w_2, w_3$ in the training corpus and $C(w_1, w_2)$ is the number of occurrences of the bigram sequence  $w_1, w_2$ in the training corpus. (Technical note: the probabilities that we compute using the ratios of counts are _estimates_ of the true conditional probabilities of N-Grams in the population of corpuses from which our corpus was drawn.)\n",
    "\n",
    "In general, for any $N$, conditional probabilities are computed by dividing the counts of N-Grams by the counts of the (N-1)-Grams they follow. \n",
    "\n",
    "**In the description of Question 5.2 we provide a detailed example of how we might compute such probabilities.**\n",
    "\n",
    "<br>\n",
    "\n",
    "### The `NGramLM` Class\n",
    "\n",
    "The `NGramLM` class contains a few extra methods and attributes beyond those of `UniformLM` and `UnigramLM`:\n",
    "\n",
    "1. Instantiating `NGramLM` requires both a list of tokens and a positive integer `N`, specifying the N in N-grams. This parameter is stored in an attribute `N`.\n",
    "1. The `NGramLM` class has a method `create_ngrams` that takes in a list of tokens and returns a list of N-Grams (recall from above, an N-Gram is a **tuple** of length N). This list of N-Grams is then passed to the `train` method to train the N-Gram model.\n",
    "1. While the `train` method still creates a language model (in this case, an N-Gram model) and stores it in the `mdl` attribute, this model is most naturally stored as a DataFrame. This DataFrame will have three columns:\n",
    "    - `'ngram'`, containing the N-Grams found in the text.\n",
    "    - `'n1gram'`, containing the (N-1)-Grams upon which the N-Grams in `ngram` are built.\n",
    "    - `'prob'`, containing the probabilities of each N-Gram in `ngram`.\n",
    "1. The `NGramLM` class has an attribute `prev_mdl` that stores an (N-1)-Gram language model over the same corpus (which in turn will store an (N-2)-Gram language model over the same corpus, and so on). This is necessary to compute the probability that a word occurs at the start of a text. This code is included for you in the constructor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.1 â€“ Creating N-Grams\n",
    "\n",
    "<a name='question5a'></a>\n",
    "\n",
    "Complete the implementation of the `create_ngrams` method of the `NGramLM` class, which takes in a list of tokens and returns a list of N-Grams, as a tuple. Example behavior is shown below.\n",
    "\n",
    "```py\n",
    ">>> corpus = 'when I eat pizza, I smile, but when I drink Coke, my stomach hurts'\n",
    ">>> tokens = tokenize(corpus)\n",
    ">>> tokens\n",
    "['\\x02', 'when', 'I', 'eat', 'pizza', ',', 'I', 'smile', ',', 'but', 'when', 'I', 'drink', 'Coke', ',', 'my', 'stomach', 'hurts', '\\x03']\n",
    ">>> pizza_model = NGramLM(3, tokens)\n",
    ">>> pizza_model.create_ngrams(tokens)\n",
    "[('\\x02', 'when', 'I'),\n",
    " ('when', 'I', 'eat'),\n",
    " ('I', 'eat', 'pizza'),\n",
    " ('eat', 'pizza', ','),\n",
    " ('pizza', ',', 'I'),\n",
    " (',', 'I', 'smile'),\n",
    " ('I', 'smile', ','),\n",
    " ('smile', ',', 'but'),\n",
    " (',', 'but', 'when'),\n",
    " ('but', 'when', 'I'),\n",
    " ('when', 'I', 'drink'),\n",
    " ('I', 'drink', 'Coke'),\n",
    " ('drink', 'Coke', ','),\n",
    " ('Coke', ',', 'my'),\n",
    " (',', 'my', 'stomach'),\n",
    " ('my', 'stomach', 'hurts'),\n",
    " ('stomach', 'hurts', '\\x03')]\n",
    "```\n",
    "\n",
    "Make sure you understand the above behavior before implementing `create_ngrams`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\x02', 'when', 'I'),\n",
       " ('when', 'I', 'eat'),\n",
       " ('I', 'eat', 'pizza'),\n",
       " ('eat', 'pizza', ','),\n",
       " ('pizza', ',', 'I'),\n",
       " (',', 'I', 'smile'),\n",
       " ('I', 'smile', ','),\n",
       " ('smile', ',', 'but'),\n",
       " (',', 'but', 'when'),\n",
       " ('but', 'when', 'I'),\n",
       " ('when', 'I', 'drink'),\n",
       " ('I', 'drink', 'Coke'),\n",
       " ('drink', 'Coke', ','),\n",
       " ('Coke', ',', 'my'),\n",
       " (',', 'my', 'stomach'),\n",
       " ('my', 'stomach', 'hurts'),\n",
       " ('stomach', 'hurts', '\\x03')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = 'when I eat pizza, I smile, but when I drink Coke, my stomach hurts'\n",
    "tokens = tokenize(corpus)\n",
    "tokens\n",
    "\n",
    "N=3\n",
    "\n",
    "out = []\n",
    "for i in range(len(tokens)-N+1):\n",
    "    out.append(tuple(tokens[i:i+N]))\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLM(object):\n",
    "    \n",
    "    def __init__(self, N, tokens):\n",
    "        \"\"\"\n",
    "        Initializes a N-gram languange model using a\n",
    "        list of tokens. It trains the language model\n",
    "        using `train` and saves it to an attribute\n",
    "        self.mdl.\n",
    "        \"\"\"\n",
    "        # You don't need to edit the constructor,\n",
    "        # but you should understand how it works!\n",
    "        \n",
    "        self.N = N\n",
    "\n",
    "        ngrams = self.create_ngrams(tokens)\n",
    "\n",
    "        self.ngrams = ngrams\n",
    "        self.mdl = self.train(ngrams)\n",
    "\n",
    "        if N < 2:\n",
    "            raise Exception('N must be greater than 1')\n",
    "        elif N == 2:\n",
    "            self.prev_mdl = UnigramLM(tokens)\n",
    "        else:\n",
    "            self.prev_mdl = NGramLM(N-1, tokens)\n",
    "\n",
    "    def create_ngrams(self, tokens):\n",
    "        \"\"\"\n",
    "        create_ngrams takes in a list of tokens and returns a list of N-grams. \n",
    "        The START/STOP tokens in the N-grams should be handled as \n",
    "        explained in the notebook.\n",
    "\n",
    "        :Example:\n",
    "        >>> tokens = tuple('\\x02 one two three one four \\x03'.split())\n",
    "        >>> bigrams = NGramLM(2, [])\n",
    "        >>> out = bigrams.create_ngrams(tokens)\n",
    "        >>> isinstance(out[0], tuple)\n",
    "        True\n",
    "        >>> out[0]\n",
    "        ('\\\\x02', 'one')\n",
    "        >>> out[2]\n",
    "        ('two', 'three')\n",
    "        \"\"\"\n",
    "        out = []\n",
    "        for i in range(len(tokens)-self.N+1):\n",
    "            out.append(tuple(tokens[i:i+self.N]))\n",
    "\n",
    "        return out\n",
    "        \n",
    "    def train(self, ngrams):\n",
    "        \"\"\"\n",
    "        Trains a n-gram language model given a list of tokens.\n",
    "        The output is a dataframe with three columns (ngram, n1gram, prob).\n",
    "\n",
    "        :Example:\n",
    "        >>> tokens = tuple('\\x02 one two three one four \\x03'.split())\n",
    "        >>> bigrams = NGramLM(2, tokens)\n",
    "        >>> set(bigrams.mdl.columns) == set('ngram n1gram prob'.split())\n",
    "        True\n",
    "        >>> bigrams.mdl.shape == (6, 3)\n",
    "        True\n",
    "        >>> bigrams.mdl['prob'].min() == 0.5\n",
    "        True\n",
    "        \"\"\"\n",
    "        # N-Gram counts C(w_1, ..., w_n)\n",
    "        \n",
    "        \n",
    "        # (N-1)-Gram counts C(w_1, ..., w_(n-1))\n",
    "        \n",
    "\n",
    "        # Create the conditional probabilities\n",
    "        \n",
    "        \n",
    "        # Put it all together\n",
    "        out= pd.DataFrame(columns=[\"ngram\", \"n1gram\", \"prob\"])\n",
    "\n",
    "        ngrams = self.ngrams\n",
    "        n1grams = [tuple(x[:-1]) for x in ngrams]\n",
    "        out[\"ngram\"] = ngrams\n",
    "        out[\"n1gram\"] = n1grams\n",
    "        out[\"prob\"] = [1 for x in ngrams]\n",
    "        vcounts = out[\"n1gram\"].value_counts()\n",
    "\n",
    "        def helper(row):\n",
    "            return row['prob']/vcounts[row['n1gram']]\n",
    "\n",
    "        out[\"prob\"] = out.apply(helper, axis=1)\n",
    "\n",
    "        return out\n",
    "\n",
    "    \n",
    "    def probability(self, words):\n",
    "        \"\"\"\n",
    "        probability gives the probabiliy a sequence of words\n",
    "        appears under the language model.\n",
    "        :param: words: a tuple of tokens\n",
    "        :returns: the probability `words` appears under the language\n",
    "        model.\n",
    "\n",
    "        :Example:\n",
    "        >>> tokens = tuple('\\x02 one two one three one two \\x03'.split())\n",
    "        >>> bigrams = NGramLM(2, tokens)\n",
    "        >>> p = bigrams.probability('two one three'.split())\n",
    "        >>> np.isclose(p, (1/4) * (1/2) * (1/3))\n",
    "        True\n",
    "        >>> bigrams.probability('one two five'.split()) == 0\n",
    "        True\n",
    "        \"\"\"\n",
    "        modelngrams, wordsngrams = list(self.mdl['ngram']), list(self.create_ngrams(words))\n",
    "\n",
    "        prob = []\n",
    "\n",
    "        if not all([ngram in modelngrams for ngram in wordsngrams]):\n",
    "            return 0 #\n",
    "\n",
    "\n",
    "        subgram = self.prev_mdl\n",
    "        subgrams = []\n",
    "        while hasattr(subgram, 'prev_mdl'):\n",
    "            subgrams.append(subgram)\n",
    "            subgram = subgram.prev_mdl\n",
    "\n",
    "        subgrams.append(subgram)\n",
    "        subgrams = subgrams[::-1]\n",
    "\n",
    "        if not all([word in subgrams[0].mdl.index for word in words]):\n",
    "            return 0 \n",
    "            \n",
    "        for i in range(len(subgrams)):\n",
    "            if i == 0:\n",
    "                prob.append(subgrams[i].mdl[words[0:i+1][0]])\n",
    "                continue\n",
    "            if tuple(words[0:i+1]) not in list(subgrams[i].mdl[\"ngram\"]):\n",
    "                return 0\n",
    "            sdf = subgrams[i].mdl\n",
    "            prob.append(float(sdf[sdf[\"ngram\"] == tuple(words[0:i+1])][\"prob\"]))\n",
    "\n",
    "        model = self.mdl\n",
    "        for ngram in wordsngrams:\n",
    "            prob.append(model[model[\"ngram\"] == ngram][\"prob\"])\n",
    "\n",
    "        return prob, np.prod(prob)\n",
    "        \n",
    "    \n",
    "\n",
    "    def sample(self, M):\n",
    "        \"\"\"\n",
    "        sample selects tokens from the language model of length M, returning\n",
    "        a string of tokens.\n",
    "\n",
    "        :Example:\n",
    "        >>> tokens = tuple('\\x02 one two three one four \\x03'.split())\n",
    "        >>> bigrams = NGramLM(2, tokens)\n",
    "        >>> samp = bigrams.sample(3)\n",
    "        >>> len(samp.split()) == 4  # don't count the initial START token.\n",
    "        True\n",
    "        >>> samp[:2] == '\\\\x02 '\n",
    "        True\n",
    "        >>> set(samp.split()) <= {'\\\\x02', '\\\\x03', 'one', 'two', 'three', 'four'}\n",
    "        True\n",
    "        \"\"\"\n",
    "        string = [\"\\x02\"]\n",
    "\n",
    "        subgram = self.prev_mdl\n",
    "        subgrams = []\n",
    "        while hasattr(subgram, 'prev_mdl'):\n",
    "            subgrams.append(subgram)\n",
    "            subgram = subgram.prev_mdl\n",
    "\n",
    "        subgrams.append(subgram)\n",
    "        subgrams = subgrams[::-1][1:]\n",
    "\n",
    "        for i in range(len(subgrams)):\n",
    "            tdf = subgrams[0].mdl\n",
    "            tdf = tdf[tdf[\"n1gram\"]==tuple(string[i:i+1])]\n",
    "            if tdf.shape[0] == 1:\n",
    "                string.append(tdf['ngram'][0][-1])\n",
    "            else:\n",
    "                x = tdf\n",
    "\n",
    "        i = len(subgrams)\n",
    "        while i < M-1:\n",
    "            tdf = self.mdl\n",
    "            if tuple(string[i:i+self.N]) not in [tup for tup in tdf[\"n1gram\"]]:\n",
    "                for i in range(M-len(string)):\n",
    "                    string.extend([\"\\x03\"]*(M-len(string)))\n",
    "                    break\n",
    "            else:\n",
    "                tdf = tdf[tdf[\"n1gram\"]==tuple(string[i:i+self.N])]\n",
    "                if tdf.shape[0] == 1:\n",
    "                    string.append(tdf['ngram'].values[0][-1])\n",
    "                else:\n",
    "                    string.append(np.random.choice(\n",
    "                                a=[ngram[-1] for ngram in tdf[\"ngram\"]],\n",
    "                                p=[p for p in tdf[\"prob\"]]))\n",
    "            \n",
    "            i+=1\n",
    "\n",
    "        string.append(\"\\x03\")\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('two', 'three')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tuple('\\x02 one two three one four \\x03'.split())\n",
    "bigrams = NGramLM(2, tokens)\n",
    "out = bigrams.create_ngrams(tokens)\n",
    "out[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.2 â€“ Training the N-Gram LM\n",
    "\n",
    "<a name='question5b'></a>\n",
    "\n",
    "Now, you will compute the probabilities that define N-Gram language model itself. Recall that the N-Gram LM consists of probabilities of the form\n",
    "\n",
    "$$P(w_n|w_{n-(N-1)},\\ldots,w_{n-1})$$\n",
    "\n",
    "which we estimate by  \n",
    "\n",
    "$$\\frac{C(w_{n-(N-1)}, w_{n-(N-2)}, \\ldots, w_{n-1}, w_n)}{C(w_{n-(N-1)}, w_{n-(N-2)}, \\ldots, w_{n-1})}$$\n",
    "\n",
    "for every N-Gram that occurs in the corpus. To illustrate, consider again the following example corpus:\n",
    "\n",
    "```py\n",
    ">>> corpus = 'when I eat pizza, I smile, but when I drink Coke, my stomach hurts'\n",
    ">>> tokens = tokenize(corpus)\n",
    ">>> tokens\n",
    "['\\x02', 'when', 'I', 'eat', 'pizza', ',', 'I', 'smile', ',', 'but', 'when', 'I', 'drink', 'Coke', ',', 'my', 'stomach', 'hurts', '\\x03']\n",
    ">>> pizza_model = NGrams(3, tokens)\n",
    "```\n",
    "\n",
    "Here, `pizza_model.train` must compute $P(\\text{I | \\x02 when})$, $P(\\text{eat | when I})$, $P(\\text{pizza | I eat})$, and so on, until $P(\\text{\\x03 | stomach hurts})$.\n",
    "\n",
    "To compute $P(\\text{eat | when I})$, we must find the number of occurrences of `'when I eat'` in the training corpus, and divide it by the number of occurrences of `'when I'` in the training corpus. `'when I eat'` occurred exactly once in the training corpus, while `'when I'` occurred twice, so,\n",
    "\n",
    "$$P(\\text{eat | when I}) = \\frac{C(\\text{when I eat})}{C(\\text{when I})} = \\frac{1}{2}$$\n",
    "\n",
    "To store the conditional probabilities of all N-Grams, we will use a DataFrame with three columns, like so:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>ngram</th>\n",
    "      <th>n1gram</th>\n",
    "      <th>prob</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>(when, I, drink)</td>\n",
    "      <td>(when, I)</td>\n",
    "      <td>0.5</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>(when, I, eat)</td>\n",
    "      <td>(when, I)</td>\n",
    "      <td>0.5</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>(,, but, when)</td>\n",
    "      <td>(,, but)</td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>(,, I, smile)</td>\n",
    "      <td>(,, I)</td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>(I, smile, ,)</td>\n",
    "      <td>(I, smile)</td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>5</th>\n",
    "      <td>(,, my, stomach)</td>\n",
    "      <td>(,, my)</td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>6</th>\n",
    "      <td>(but, when, I)</td>\n",
    "      <td>(but, when)</td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>7</th>\n",
    "      <td>(\u0002, when, I)</td>\n",
    "      <td>(\u0002, when)</td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>8</th>\n",
    "      <td>(stomach, hurts, \u0003)</td>\n",
    "      <td>(stomach, hurts)</td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>9</th>\n",
    "      <td>(Coke, ,, my)</td>\n",
    "      <td>(Coke, ,)</td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>10</th>\n",
    "      <td>(eat, pizza, ,)</td>\n",
    "      <td>(eat, pizza)</td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>11</th>\n",
    "      <td>(I, drink, Coke)</td>\n",
    "      <td>(I, drink)</td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>12</th>\n",
    "      <td>(my, stomach, hurts)</td>\n",
    "      <td>(my, stomach)</td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>13</th>\n",
    "      <td>(pizza, ,, I)</td>\n",
    "      <td>(pizza, ,)</td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>14</th>\n",
    "      <td>(I, eat, pizza)</td>\n",
    "      <td>(I, eat)</td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>15</th>\n",
    "      <td>(drink, Coke, ,)</td>\n",
    "      <td>(drink, Coke)</td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>16</th>\n",
    "      <td>(smile, ,, but)</td>\n",
    "      <td>(smile, ,)</td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "The row at position **1** in the above table shows that the probability of the trigram `('when', 'I', 'eat')` conditioned on the bigram `('when', 'I')` is 0.5, as we computed above. Note that many of the above conditional probabilities are equal to 1 because many trigrams and their corresponding bigrams each appeared only once, and $\\frac{1}{1} = 1$. Note that `'\\x02'` and `'\\x03'` appear as spaces above, such as in row **7**.\n",
    "\n",
    "\n",
    "After you've understood the above example output, complete the implementation of the `train` method in `NGramLM`. Remember that your model may use any $N$, not just 3 (i.e not just trigrams)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tuple('\\x02 one two three one four \\x03'.split())\n",
    "\n",
    "N = 2\n",
    "\n",
    "out= pd.DataFrame(columns=[\"ngram\", \"n1gram\", \"prob\"])\n",
    "x = NGramLM(2, tokens)\n",
    "n1grams = [tuple(x[:-1]) for x in x.ngrams]\n",
    "out[\"ngram\"] = x.ngrams\n",
    "out[\"n1gram\"] = n1grams\n",
    "out[\"prob\"] = [1 for x in x.ngrams]\n",
    "vcounts = out[\"n1gram\"].value_counts()\n",
    "\n",
    "def helper(row):\n",
    "    return row['prob']/vcounts[row['n1gram']]\n",
    "\n",
    "out[\"prob\"] = out.apply(helper, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Zaki Ahmed\\dsc30_sp22\\dsc80-2022-fa\\projects\\04-language_models\\assignment\\project.ipynb Cell 53\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zaki%20Ahmed/dsc30_sp22/dsc80-2022-fa/projects/04-language_models/assignment/project.ipynb#Y102sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(subgrams)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zaki%20Ahmed/dsc30_sp22/dsc80-2022-fa/projects/04-language_models/assignment/project.ipynb#Y102sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Zaki%20Ahmed/dsc30_sp22/dsc80-2022-fa/projects/04-language_models/assignment/project.ipynb#Y102sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         prob\u001b[39m.\u001b[39;49mappend(subgrams[i]\u001b[39m.\u001b[39mmdl[words[\u001b[39m0\u001b[39m:i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zaki%20Ahmed/dsc30_sp22/dsc80-2022-fa/projects/04-language_models/assignment/project.ipynb#Y102sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zaki%20Ahmed/dsc30_sp22/dsc80-2022-fa/projects/04-language_models/assignment/project.ipynb#Y102sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtuple\u001b[39m(words[\u001b[39m0\u001b[39m:i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(subgrams[i]\u001b[39m.\u001b[39mmdl[\u001b[39m\"\u001b[39m\u001b[39mngram\u001b[39m\u001b[39m\"\u001b[39m]):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "self = x \n",
    "\n",
    "\n",
    "words = (\"one\", \"two\", \"three\", \"one\", \"five\")\n",
    "\n",
    "self.ngrams\n",
    "\n",
    "modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
    "\n",
    "prob = []\n",
    "\n",
    "if not all([ngram in modelngrams for ngram in wordsngrams]):\n",
    "    prob = 0 #\n",
    "    print(0)\n",
    "\n",
    "\n",
    "subgram = self.prev_mdl\n",
    "subgrams = []\n",
    "while hasattr(subgram, 'prev_mdl'):\n",
    "    subgrams.append(subgram)\n",
    "    subgram = subgram.prev_mdl\n",
    "\n",
    "subgrams.append(subgram)\n",
    "subgrams = subgrams[::-1]\n",
    "\n",
    "if not all([word in subgrams[0].mdl.index for word in words]):\n",
    "    prob = 0 #\n",
    "    print(0)\n",
    "    \n",
    "for i in range(len(subgrams)):\n",
    "    if i == 0:\n",
    "        prob.append(subgrams[i].mdl[words[0:i+1][0]])\n",
    "        continue\n",
    "    if tuple(words[0:i+1]) not in list(subgrams[i].mdl[\"ngram\"]):\n",
    "        prob = 0 #\n",
    "        print(0)\n",
    "    prob.append(float(sdf[sdf[\"ngram\"] == tuple(words[0:i+1])][\"prob\"]))\n",
    "    \n",
    "\n",
    "prob\n",
    "\n",
    "model = self.mdl\n",
    "for ngram in wordsngrams:\n",
    "    print(float(model[model[\"ngram\"] == ngram][\"prob\"]))\n",
    "    prob.append(float(model[model[\"ngram\"] == ngram][\"prob\"]))\n",
    "\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>n1gram</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(\u0002, one)</td>\n",
       "      <td>(\u0002,)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(one, two)</td>\n",
       "      <td>(one,)</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(two, three)</td>\n",
       "      <td>(two,)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(three, one)</td>\n",
       "      <td>(three,)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(one, four)</td>\n",
       "      <td>(one,)</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(four, \u0003)</td>\n",
       "      <td>(four,)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ngram    n1gram  prob\n",
       "0      (\u0002, one)      (\u0002,)   1.0\n",
       "1    (one, two)    (one,)   0.5\n",
       "2  (two, three)    (two,)   1.0\n",
       "3  (three, one)  (three,)   1.0\n",
       "4   (one, four)    (one,)   0.5\n",
       "5     (four, \u0003)   (four,)   1.0"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=1\n",
    "sdf = subgrams[i].mdl\n",
    "float(sdf[sdf[\"ngram\"] == tuple(words[0:i+1])][\"prob\"])\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u0002        0.142857\n",
       "one      0.285714\n",
       "two      0.142857\n",
       "three    0.142857\n",
       "four     0.142857\n",
       "\u0003        0.142857\n",
       "dtype: float64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subgrams[0].mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('one', 'two')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(words[0:i+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.3 â€“ Computing Probabilities using the N-Gram Model\n",
    "\n",
    "<a name='question5c'></a>\n",
    "\n",
    "After we've trained our N-Gram model â€“ that is, after we've computed a DataFrame associating each N-Gram with a conditional probability â€“ we need to compute probabilities for new sentences.\n",
    "\n",
    "To illustrate how this may work, let's look at an example input tuple to `probability`. Assume our model is `pizza_model` from Question 5.2's description; we will not repeat the probability table here.\n",
    "\n",
    "Suppose our input tuple is `('when', 'I', 'eat', 'pizza', ',', 'I', 'smile')`, corresponding to the sentence `'when I eat pizza, I smile'` (remember again that the tuples provided to `probability` don't need to include `'\\x02'` or `'\\x03'`). Then,\n",
    "\n",
    "$$\n",
    "\\begin{align*} &P(\\text{when I eat pizza, I smile}) \\\\ &= P(\\text{when}) \\cdot P(\\text{I | when}) \\cdot P(\\text{eat | when I}) \\cdot P(\\text{pizza | I eat}) \\cdot P(\\text{, | eat pizza}) \\cdot P(\\text{I | pizza,})\\cdot P(\\text{smile | , I}) \\\\ &= \\frac{2}{19} \\cdot 1 \\cdot \\frac{1}{2} \\cdot 1 \\cdot 1 \\cdot 1 \\cdot 1 \\\\ &= \\frac{1}{19} \\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "- To find the latter five probabilities â€“ $P(\\text{eat | when I}) , P(\\text{pizza | I eat}) , P(\\text{, | eat pizza}) , P(\\text{I | pizza,}),$ and $P(\\text{smile | , I})$, we can use the `mdl` DataFrame that the `train` method computes.\n",
    "- To find $P(\\text{I | when})$, we can't just look at the `mdl` DataFrame, because `('when', 'I')` is not a trigram, it is a bigram. Instead, we look at our model's `prev_mdl` attribute, which itself is another instance of `NGramLM`, corresponding to a bigram model over the same corpus. There, we can find the probability $P(\\text{I | when})$.\n",
    "- To find $P(\\text{when})$, we can't just look at the `mdl` DataFrame, because `'when'` is not a trigram. It is not a bigram either. Instead, we need to look at `prev_mdl`'s `prev_mdl`, which is a `UnigramLM`, to find $P(\\text{when})$.\n",
    "\n",
    "Note that if the input tuple contains an N-Gram that was never seen in the training corpus, the returned probability is 0. Convince yourself why `pizza_model.probability(('when', 'I', 'drink', 'Coke', ',', 'I', 'smile'))` is 0 before proceeding.\n",
    "\n",
    "After you've understood the above example output, complete the implementation of the `probability` method in `NGramLM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>n1gram</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(\u0002, one)</td>\n",
       "      <td>(\u0002,)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(one, two)</td>\n",
       "      <td>(one,)</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(two, three)</td>\n",
       "      <td>(two,)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(three, one)</td>\n",
       "      <td>(three,)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(one, four)</td>\n",
       "      <td>(one,)</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(four, \u0003)</td>\n",
       "      <td>(four,)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ngram    n1gram  prob\n",
       "0      (\u0002, one)      (\u0002,)   1.0\n",
       "1    (one, two)    (one,)   0.5\n",
       "2  (two, three)    (two,)   1.0\n",
       "3  (three, one)  (three,)   1.0\n",
       "4   (one, four)    (one,)   0.5\n",
       "5     (four, \u0003)   (four,)   1.0"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subgrams[1].mdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.4 â€“ Sampling from the N-Gram Model\n",
    "\n",
    "<a name='question5d'></a>\n",
    "\n",
    "The last method you implemented in the `UniformLM` and `UnigramLM` classes was `sample`, which gave you a way of generating new sentences. \n",
    "\n",
    "Now, you will implement the `sample` method in the `NGramLM` class. It should take in a positive integer `M` and generate a string of M tokens using the trained language model. It should begin with a starting token `'\\x02'`, then generate subsequent tokens from the probabilities in `self.mdl` and continue picking words conditional on the previous choice. \n",
    "\n",
    "Let's illustrate how sampling works using a small concrete example. Suppose our corpus and **trigram** model are defined below:\n",
    "\n",
    "```py\n",
    ">>> short_corpus = 'zebras eat green peas \\n\\n cows eat green grass \\n\\n zebras eat green peppers'\n",
    ">>> short_tokens = tokenize(short_corpus)\n",
    ">>> short_tokens\n",
    "['\\x02', 'zebras', 'eat', 'green', 'peas', '\\x03', '\\x02', 'cows', 'eat', 'green', 'grass', '\\x03', '\\x02', 'zebras', 'eat', 'green', 'peppers', '\\x03']\n",
    ">>> grass_model = NGramLM(3, short_tokens)\n",
    "```\n",
    "\n",
    "Suppose we are told to execute `grass_model.sample(5)`. Here's how we'd proceed:\n",
    "\n",
    "0. The first character in the output is `'\\x02'`, as specified above. **We won't count `'\\x02'` in the length of our output string**, so we still need to find 5 more tokens.\n",
    "1. The next character needs to be either `'zebras'` or `'cows'`, since `('\\x02', 'zebras')` and `('\\x02', 'cows')` are the only **bigrams** in `short_tokens` that start with an `'\\x02'`. $P(\\text{zebras | \\x02})$ is $\\frac{2}{3}$ and $P(\\text{cows | \\x02})$ is $\\frac{1}{3}$, so we select either `'zebras'` or `'cows'` for our next token according to these probabilities. For the sake of example, suppose we select `'cows'`. 4 more tokens to go.\n",
    "2. Now, we must look for **trigrams** that start with the bigram `('\\x02', 'cows')`. There is just one, `('\\x02', 'cows', 'eat')`, so our next token must be `'eat'`. 3 more tokens to go.\n",
    "3. Now, we must look for **trigrams** that start with the bigram `('cows', 'eat')`. Again, there is just one, `('cows', 'eat', 'green')`, so our next token must be `'green'`. 2 more tokens to go.\n",
    "4. Now, we must look for **trigrams** that start with the bigram `('eat', 'green')`. There are three options â€“ `('eat', 'green', 'peas')`, `('eat', 'green', 'grass')`, and `('eat', 'green', 'peppers')`. Since $P(\\text{peas | eat green}) = P(\\text{grass | eat green}) = P(\\text{peppers | eat green}) = \\frac{1}{3}$, we pick either `'peas'`, `'grass'`, or `'peppers'` uniformly at random. For the sake of example, suppose we select `'peppers'`. 1 more token to go.\n",
    "5. We must end the output string now with `'\\x03'`, putting us at `'\\x02'` plus 5 tokens, which is the number of tokens we were told to sample. Note that `'\\x03'` **does** count towards the number of tokens we were asked to sample.\n",
    "\n",
    "Our result is `'\\x02 cows eat green peppers \\x03'`. **Note that in our training corpus we never encountered an instance of cows ðŸ„ eating green peppers ðŸ«‘, but we were able to generate a coherent sentence in which they did â€“ pretty cool!**\n",
    "\n",
    "\n",
    "Some additional guidance:\n",
    "- If you run into a situation where there are no N-Grams that match the most recent (N-1)-Gram, you should add `'\\x03'` (STOP) token as the next token in your output sentence. There is a chance that your sampled sentence ends in many `'\\x03'`s, and that's fine.\n",
    "- Helper functions and recursion will be very helpful.\n",
    "\n",
    "After you've understood the above example, complete the implementation of the `sample` method in `NGramLM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\x02', 'one', 'four', '\\x03', '\\x03', '\\x03']"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = 5\n",
    "\n",
    "string = [\"\\x02\"]\n",
    "\n",
    "subgram = self.prev_mdl\n",
    "subgrams = []\n",
    "while hasattr(subgram, 'prev_mdl'):\n",
    "    subgrams.append(subgram)\n",
    "    subgram = subgram.prev_mdl\n",
    "\n",
    "subgrams.append(subgram)\n",
    "subgrams = subgrams[::-1][1:]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(subgrams)):\n",
    "    tdf = subgrams[0].mdl\n",
    "    tdf = tdf[tdf[\"n1gram\"]==tuple(string[i:i+1])]\n",
    "    if tdf.shape[0] == 1:\n",
    "        string.append(tdf['ngram'][0][-1])\n",
    "    else:\n",
    "        x = tdf\n",
    "\n",
    "\n",
    "\n",
    "self.mdl\n",
    "i = len(subgrams)\n",
    "while i < M-1:\n",
    "    tdf = self.mdl\n",
    "    if tuple(string[i:i+self.N]) not in [tup for tup in tdf[\"n1gram\"]]:\n",
    "        for i in range(M-len(string)):\n",
    "            string.extend([\"\\x03\"]*(M-len(string)))\n",
    "            break\n",
    "    else:\n",
    "        tdf = tdf[tdf[\"n1gram\"]==tuple(string[i:i+self.N])]\n",
    "        if tdf.shape[0] == 1:\n",
    "            string.append(tdf['ngram'].values[0][-1])\n",
    "        else:\n",
    "            string.append(np.random.choice(\n",
    "                        a=[ngram[-1] for ngram in tdf[\"ngram\"]],\n",
    "                        p=[p for p in tdf[\"prob\"]]))\n",
    "    \n",
    "    i+=1\n",
    "\n",
    "\n",
    "\n",
    "string.append(\"\\x03\")\n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = 'Humpty Dumpty'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests\n",
    "# note â€“ these tests are different than the doctests; you should run them both \n",
    "tokens = \"\\x02 Humpty Dumpty sat on a wall , Humpty Dumpty had a great fall . \\x03 \\x02 All the king ' s horses and all the king ' s men couldn ' t put Humpty together again . \\x03\".split()\n",
    "tokens = tuple(tokens)\n",
    "ngram = NGramLM(2, tokens)\n",
    "out_5a1 = ngram.create_ngrams(tokens)\n",
    "out_5b1 = ngram.mdl\n",
    "out_5c1 = ngram\n",
    "out_5d1 = ngram.sample(500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Zaki Ahmed\\dsc30_sp22\\dsc80-2022-fa\\projects\\04-language_models\\assignment\\project.ipynb Cell 64\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Zaki%20Ahmed/dsc30_sp22/dsc80-2022-fa/projects/04-language_models/assignment/project.ipynb#Y151sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m out_5b1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Zaki%20Ahmed/dsc30_sp22/dsc80-2022-fa/projects/04-language_models/assignment/project.ipynb#Y151sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m dupes \u001b[39m=\u001b[39m df[df\u001b[39m.\u001b[39mduplicated()]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Zaki%20Ahmed/dsc30_sp22/dsc80-2022-fa/projects/04-language_models/assignment/project.ipynb#Y151sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m dupes\u001b[39m.\u001b[39miloc[\u001b[39m\"\u001b[39m\u001b[39mprob\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m dupes[\u001b[39m\"\u001b[39m\u001b[39mprob\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Zaki%20Ahmed/dsc30_sp22/dsc80-2022-fa/projects/04-language_models/assignment/project.ipynb#Y151sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdrop_duplicates(keep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:716\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    715\u001b[0m iloc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39miloc\n\u001b[1;32m--> 716\u001b[0m iloc\u001b[39m.\u001b[39;49m_setitem_with_indexer(indexer, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1688\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1685\u001b[0m \u001b[39m# align and set the values\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m \u001b[39mif\u001b[39;00m take_split_path:\n\u001b[0;32m   1687\u001b[0m     \u001b[39m# We have to operate column-wise\u001b[39;00m\n\u001b[1;32m-> 1688\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_with_indexer_split_path(indexer, value, name)\n\u001b[0;32m   1689\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1690\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[1;32mc:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1770\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1767\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_single_column(ilocs[\u001b[39m0\u001b[39m], value, pi)\n\u001b[0;32m   1769\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1770\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1771\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMust have equal len keys and value \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1772\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mwhen setting with an iterable\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1773\u001b[0m         )\n\u001b[0;32m   1775\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1776\u001b[0m \n\u001b[0;32m   1777\u001b[0m     \u001b[39m# scalar value\u001b[39;00m\n\u001b[0;32m   1778\u001b[0m     \u001b[39mfor\u001b[39;00m loc \u001b[39min\u001b[39;00m ilocs:\n",
      "\u001b[1;31mValueError\u001b[0m: Must have equal len keys and value when setting with an iterable"
     ]
    }
   ],
   "source": [
    "df = out_5b1\n",
    "dupes = df[df.duplicated()]\n",
    "dupes.iloc[\"prob\"] = dupes[\"prob\"]*2\n",
    "df = df.drop_duplicates(keep=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>n1gram</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(\u0002, Humpty)</td>\n",
       "      <td>(\u0002,)</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Humpty, Dumpty)</td>\n",
       "      <td>(Humpty,)</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Dumpty, sat)</td>\n",
       "      <td>(Dumpty,)</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(sat, on)</td>\n",
       "      <td>(sat,)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(on, a)</td>\n",
       "      <td>(on,)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(a, wall)</td>\n",
       "      <td>(a,)</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(wall, ,)</td>\n",
       "      <td>(wall,)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(,, Humpty)</td>\n",
       "      <td>(,,)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Humpty, Dumpty)</td>\n",
       "      <td>(Humpty,)</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Dumpty, had)</td>\n",
       "      <td>(Dumpty,)</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(had, a)</td>\n",
       "      <td>(had,)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(a, great)</td>\n",
       "      <td>(a,)</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(great, fall)</td>\n",
       "      <td>(great,)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(fall, .)</td>\n",
       "      <td>(fall,)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(., \u0003)</td>\n",
       "      <td>(.,)</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(\u0003, \u0002)</td>\n",
       "      <td>(\u0003,)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(\u0002, All)</td>\n",
       "      <td>(\u0002,)</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(All, the)</td>\n",
       "      <td>(All,)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(the, king)</td>\n",
       "      <td>(the,)</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(king, ')</td>\n",
       "      <td>(king,)</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(', s)</td>\n",
       "      <td>(',)</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(s, horses)</td>\n",
       "      <td>(s,)</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(horses, and)</td>\n",
       "      <td>(horses,)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(and, all)</td>\n",
       "      <td>(and,)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(all, the)</td>\n",
       "      <td>(all,)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(the, king)</td>\n",
       "      <td>(the,)</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(king, ')</td>\n",
       "      <td>(king,)</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(', s)</td>\n",
       "      <td>(',)</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(s, men)</td>\n",
       "      <td>(s,)</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(men, couldn)</td>\n",
       "      <td>(men,)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(couldn, ')</td>\n",
       "      <td>(couldn,)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(', t)</td>\n",
       "      <td>(',)</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(t, put)</td>\n",
       "      <td>(t,)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(put, Humpty)</td>\n",
       "      <td>(put,)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(Humpty, together)</td>\n",
       "      <td>(Humpty,)</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(together, again)</td>\n",
       "      <td>(together,)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(again, .)</td>\n",
       "      <td>(again,)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>(., \u0003)</td>\n",
       "      <td>(.,)</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ngram       n1gram      prob\n",
       "0          (\u0002, Humpty)         (\u0002,)  0.500000\n",
       "1     (Humpty, Dumpty)    (Humpty,)  0.333333\n",
       "2        (Dumpty, sat)    (Dumpty,)  0.500000\n",
       "3            (sat, on)       (sat,)  1.000000\n",
       "4              (on, a)        (on,)  1.000000\n",
       "5            (a, wall)         (a,)  0.500000\n",
       "6            (wall, ,)      (wall,)  1.000000\n",
       "7          (,, Humpty)         (,,)  1.000000\n",
       "8     (Humpty, Dumpty)    (Humpty,)  0.333333\n",
       "9        (Dumpty, had)    (Dumpty,)  0.500000\n",
       "10            (had, a)       (had,)  1.000000\n",
       "11          (a, great)         (a,)  0.500000\n",
       "12       (great, fall)     (great,)  1.000000\n",
       "13           (fall, .)      (fall,)  1.000000\n",
       "14              (., \u0003)         (.,)  0.500000\n",
       "15              (\u0003, \u0002)         (\u0003,)  1.000000\n",
       "16            (\u0002, All)         (\u0002,)  0.500000\n",
       "17          (All, the)       (All,)  1.000000\n",
       "18         (the, king)       (the,)  0.500000\n",
       "19           (king, ')      (king,)  0.500000\n",
       "20              (', s)         (',)  0.333333\n",
       "21         (s, horses)         (s,)  0.500000\n",
       "22       (horses, and)    (horses,)  1.000000\n",
       "23          (and, all)       (and,)  1.000000\n",
       "24          (all, the)       (all,)  1.000000\n",
       "25         (the, king)       (the,)  0.500000\n",
       "26           (king, ')      (king,)  0.500000\n",
       "27              (', s)         (',)  0.333333\n",
       "28            (s, men)         (s,)  0.500000\n",
       "29       (men, couldn)       (men,)  1.000000\n",
       "30         (couldn, ')    (couldn,)  1.000000\n",
       "31              (', t)         (',)  0.333333\n",
       "32            (t, put)         (t,)  1.000000\n",
       "33       (put, Humpty)       (put,)  1.000000\n",
       "34  (Humpty, together)    (Humpty,)  0.333333\n",
       "35   (together, again)  (together,)  1.000000\n",
       "36          (again, .)     (again,)  1.000000\n",
       "37              (., \u0003)         (.,)  0.500000"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_5b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05128205128205128"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = 'Humpty Dumpty'.split()\n",
    "self = out_5c1\n",
    "\n",
    "modelngrams, wordsngrams = list(self.mdl['ngram']), list(self.create_ngrams(words))\n",
    "\n",
    "prob = []\n",
    "\n",
    "subgram = self.prev_mdl\n",
    "subgrams = []\n",
    "while hasattr(subgram, 'prev_mdl'):\n",
    "    subgrams.append(subgram)\n",
    "    subgram = subgram.prev_mdl\n",
    "\n",
    "subgrams.append(subgram)\n",
    "subgrams = subgrams[::-1]\n",
    "\n",
    "for i in range(len(subgrams)):\n",
    "            if i == 0:\n",
    "                prob.append(subgrams[i].mdl[words[0:i+1][0]])\n",
    "                continue\n",
    "            if tuple(words[0:i+1]) not in list(subgrams[i].mdl[\"ngram\"]):\n",
    "                print(0)\n",
    "            sdf = subgrams[i].mdl\n",
    "            prob.append(float(sdf[sdf[\"ngram\"] == tuple(words[0:i+1])][\"prob\"]))\n",
    "\n",
    "prob\n",
    "\n",
    "model = self.mdl\n",
    "for ngram in wordsngrams:\n",
    "    prob.append(float(model[model[\"ngram\"] == ngram][\"prob\"].sum()))\n",
    "\n",
    "np.prod(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests\n",
    "\n",
    "# 5a Test2\n",
    "tokens = \"\\x02 Humpty Dumpty sat on a wall , Humpty Dumpty had a great fall . \\x03 \\x02 All the king ' s horses and all the king ' s men couldn ' t put Humpty together again . \\x03\".split()\n",
    "tokens = tuple(tokens)\n",
    "ngram = NGramLM(3, tokens)\n",
    "out_5a2 = ngram.create_ngrams(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests\n",
    "\n",
    "# 5a Test3\n",
    "tokens = tuple(open('data/homertokens.txt').read().split(' '))\n",
    "ngram = NGramLM(3, tokens)\n",
    "out_5a3 = ngram.create_ngrams(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests\n",
    "\n",
    "# 5b Test2\n",
    "tokens = \"\\x02 Humpty Dumpty sat on a wall , Humpty Dumpty had a great fall . \\x03 \\x02 All the king ' s horses and all the king ' s men couldn ' t put Humpty together again . \\x03\".split()\n",
    "tokens = tuple(tokens)\n",
    "ngram = NGramLM(3, tokens)\n",
    "out_5b2 = ngram.mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests\n",
    "\n",
    "# 5b Test3\n",
    "tokens = tuple(open('data/homertokens.txt').read().split(' '))\n",
    "out_5b3 = NGramLM(3, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests\n",
    "\n",
    "# 5c Test2\n",
    "tokens = \"\\x02 Humpty Dumpty sat on a wall , Humpty Dumpty had a great fall . \\x03 \\x02 All the king ' s horses and all the king ' s men couldn ' t put Humpty together again . \\x03\".split()\n",
    "tokens = tuple(tokens)\n",
    "out_5c2 = NGramLM(3, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests\n",
    "\n",
    "# 5c Test3\n",
    "tokens = tuple(open('data/homertokens.txt').read().split(' '))\n",
    "out_5c3 = NGramLM(2, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests\n",
    "\n",
    "# 5d Test2\n",
    "tokens = \"\\x02 Humpty Dumpty sat on a wall , Humpty Dumpty had a great fall . \\x03 \\x02 All the king ' s horses and all the king ' s men couldn ' t put Humpty together again . \\x03\".split()\n",
    "tokens = tuple(tokens)\n",
    "ngram = NGramLM(3, tokens)\n",
    "out_5d2 = ngram.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests\n",
    "\n",
    "# 5d Test3\n",
    "tokens = tuple(open('data/homertokens.txt').read().split(' '))\n",
    "ngram = NGramLM(3, tokens)\n",
    "out_5d3 = ngram.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>q5</pre> results:</strong></p><p><strong><pre style='display: inline;'>q5 - 1</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q5 - 2</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q5 - 3</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q5 - 4</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q5 - 5</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q5 - 6</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q5 - 7</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q5 - 8</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q5 - 9</pre> result:</strong></p><pre>    Trying:\n",
       "        p = out_5b1.loc[out_5b1.ngram == ('Humpty', 'Dumpty'), 'prob'].squeeze()\n",
       "    Expecting nothing\n",
       "    ok\n",
       "    Trying:\n",
       "        np.isclose(p, 0.666666, atol=0.001)\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 2, in q5 8\n",
       "    Failed example:\n",
       "        np.isclose(p, 0.666666, atol=0.001)\n",
       "    Expected:\n",
       "        True\n",
       "    Got:\n",
       "        array([False, False])\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 9</pre> message:</strong> Humpty Dumpty in bigrams</p><p><strong><pre style='display: inline;'>q5 - 10</pre> result:</strong></p><pre>    Trying:\n",
       "        words = 'Humpty Dumpty sat on a great fall'.split()\n",
       "    Expecting nothing\n",
       "    ok\n",
       "    Trying:\n",
       "        p = out_5c1.probability(words)\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 2, in q5 9\n",
       "    Failed example:\n",
       "        p = out_5c1.probability(words)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 9[1]>\", line 1, in <module>\n",
       "            p = out_5c1.probability(words)\n",
       "          File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "            modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "        AttributeError: 'list' object has no attribute 'mdl'\n",
       "    Trying:\n",
       "        np.isclose(p, 0.01282051282051282, atol=0.001)\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 3, in q5 9\n",
       "    Failed example:\n",
       "        np.isclose(p, 0.01282051282051282, atol=0.001)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 9[2]>\", line 1, in <module>\n",
       "            np.isclose(p, 0.01282051282051282, atol=0.001)\n",
       "        NameError: name 'p' is not defined\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 10</pre> message:</strong> test probability 2gram</p><p><strong><pre style='display: inline;'>q5 - 11</pre> result:</strong></p><pre>    Trying:\n",
       "        words = 'Humpty Dumpty'.split()\n",
       "    Expecting nothing\n",
       "    ok\n",
       "    Trying:\n",
       "        p = out_5c1.probability(words)\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 2, in q5 10\n",
       "    Failed example:\n",
       "        p = out_5c1.probability(words)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 10[1]>\", line 1, in <module>\n",
       "            p = out_5c1.probability(words)\n",
       "          File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "            modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "        AttributeError: 'list' object has no attribute 'mdl'\n",
       "    Trying:\n",
       "        np.isclose(p, 0.05128205128205128, atol=0.001)\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 3, in q5 10\n",
       "    Failed example:\n",
       "        np.isclose(p, 0.05128205128205128, atol=0.001)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 10[2]>\", line 1, in <module>\n",
       "            np.isclose(p, 0.05128205128205128, atol=0.001)\n",
       "        NameError: name 'p' is not defined\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 11</pre> message:</strong> test probability 2gram</p><p><strong><pre style='display: inline;'>q5 - 12</pre> result:</strong></p><pre>    Trying:\n",
       "        words = 'couldn \\' t put Humpty'.split()\n",
       "    Expecting nothing\n",
       "    ok\n",
       "    Trying:\n",
       "        p = out_5c1.probability(words)\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 2, in q5 11\n",
       "    Failed example:\n",
       "        p = out_5c1.probability(words)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 11[1]>\", line 1, in <module>\n",
       "            p = out_5c1.probability(words)\n",
       "          File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "            modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "        AttributeError: 'list' object has no attribute 'mdl'\n",
       "    Trying:\n",
       "        np.isclose(p, 0.008547008547008546, atol=0.001)\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 3, in q5 11\n",
       "    Failed example:\n",
       "        np.isclose(p, 0.008547008547008546, atol=0.001)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 11[2]>\", line 1, in <module>\n",
       "            np.isclose(p, 0.008547008547008546, atol=0.001)\n",
       "        NameError: name 'p' is not defined\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 12</pre> message:</strong> test probability 2gram</p><p><strong><pre style='display: inline;'>q5 - 13</pre> result:</strong></p><pre>    Trying:\n",
       "        words = 'All the king \\' s men'.split()\n",
       "    Expecting nothing\n",
       "    ok\n",
       "    Trying:\n",
       "        p = out_5c1.probability(words)\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 2, in q5 12\n",
       "    Failed example:\n",
       "        p = out_5c1.probability(words)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 12[1]>\", line 1, in <module>\n",
       "            p = out_5c1.probability(words)\n",
       "          File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "            modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "        AttributeError: 'list' object has no attribute 'mdl'\n",
       "    Trying:\n",
       "        np.isclose(p, 0.008547008547008546, atol=0.001)\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 3, in q5 12\n",
       "    Failed example:\n",
       "        np.isclose(p, 0.008547008547008546, atol=0.001)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 12[2]>\", line 1, in <module>\n",
       "            np.isclose(p, 0.008547008547008546, atol=0.001)\n",
       "        NameError: name 'p' is not defined\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 13</pre> message:</strong> test probability 2gram</p><p><strong><pre style='display: inline;'>q5 - 14</pre> result:</strong></p><pre>    Trying:\n",
       "        words = 'Humpty Dumpty together again'.split()\n",
       "    Expecting nothing\n",
       "    ok\n",
       "    Trying:\n",
       "        p = out_5c1.probability(words)\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 2, in q5 13\n",
       "    Failed example:\n",
       "        p = out_5c1.probability(words)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 13[1]>\", line 1, in <module>\n",
       "            p = out_5c1.probability(words)\n",
       "          File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "            modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "        AttributeError: 'list' object has no attribute 'mdl'\n",
       "    Trying:\n",
       "        np.isclose(p, 0, atol=0.001)\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 3, in q5 13\n",
       "    Failed example:\n",
       "        np.isclose(p, 0, atol=0.001)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 13[2]>\", line 1, in <module>\n",
       "            np.isclose(p, 0, atol=0.001)\n",
       "        NameError: name 'p' is not defined\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 14</pre> message:</strong> test probability 2gram</p><p><strong><pre style='display: inline;'>q5 - 15</pre> result:</strong></p><pre>    Trying:\n",
       "        495 <= len(out_5d1.split()) < 505\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q5 14\n",
       "    Failed example:\n",
       "        495 <= len(out_5d1.split()) < 505\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 14[0]>\", line 1, in <module>\n",
       "            495 <= len(out_5d1.split()) < 505\n",
       "        AttributeError: 'list' object has no attribute 'split'\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 15</pre> message:</strong> approx length of sample</p><p><strong><pre style='display: inline;'>q5 - 16</pre> result:</strong></p><pre>    Trying:\n",
       "        'Humpty Dumpty' in out_5d1\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q5 15\n",
       "    Failed example:\n",
       "        'Humpty Dumpty' in out_5d1\n",
       "    Expected:\n",
       "        True\n",
       "    Got:\n",
       "        False\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 16</pre> message:</strong> Humpty Dumpty in sample</p><p><strong><pre style='display: inline;'>q5 - 17</pre> result:</strong></p><pre>    Trying:\n",
       "        'together again' in out_5d1\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q5 16\n",
       "    Failed example:\n",
       "        'together again' in out_5d1\n",
       "    Expected:\n",
       "        True\n",
       "    Got:\n",
       "        False\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 17</pre> message:</strong> together again in sample</p><p><strong><pre style='display: inline;'>q5 - 18</pre> result:</strong></p><pre>    Trying:\n",
       "        vc = pd.Series(out_5d1.split()).value_counts(normalize=True)\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in q5 17\n",
       "    Failed example:\n",
       "        vc = pd.Series(out_5d1.split()).value_counts(normalize=True)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 17[0]>\", line 1, in <module>\n",
       "            vc = pd.Series(out_5d1.split()).value_counts(normalize=True)\n",
       "        AttributeError: 'list' object has no attribute 'split'\n",
       "    Trying:\n",
       "        {'\\'', 'the', 'Humpty'}.intersection(set(vc.index[:6])) != {}\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 2, in q5 17\n",
       "    Failed example:\n",
       "        {'\\'', 'the', 'Humpty'}.intersection(set(vc.index[:6])) != {}\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 17[1]>\", line 1, in <module>\n",
       "            {'\\'', 'the', 'Humpty'}.intersection(set(vc.index[:6])) != {}\n",
       "        NameError: name 'vc' is not defined\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 18</pre> message:</strong> most common sampled tokens</p><p><strong><pre style='display: inline;'>q5 - 19</pre> result:</strong></p><pre>    Trying:\n",
       "        vc = pd.Series(out_5d1.split()).value_counts(normalize=True)\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in q5 18\n",
       "    Failed example:\n",
       "        vc = pd.Series(out_5d1.split()).value_counts(normalize=True)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 18[0]>\", line 1, in <module>\n",
       "            vc = pd.Series(out_5d1.split()).value_counts(normalize=True)\n",
       "        AttributeError: 'list' object has no attribute 'split'\n",
       "    Trying:\n",
       "        np.isclose(vc.iloc[0], 0.07, atol=0.03)\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 2, in q5 18\n",
       "    Failed example:\n",
       "        np.isclose(vc.iloc[0], 0.07, atol=0.03)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 18[1]>\", line 1, in <module>\n",
       "            np.isclose(vc.iloc[0], 0.07, atol=0.03)\n",
       "        NameError: name 'vc' is not defined\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 19</pre> message:</strong> most common sampled tokens</p><p><strong><pre style='display: inline;'>q5 - 20</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q5 - 21</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q5 - 22</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q5 - 23</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q5 - 24</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q5 - 25</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q5 - 26</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q5 - 27</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q5 - 28</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q5 - 29</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q5 - 30</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q5 - 31</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q5 - 32</pre> result:</strong></p><pre>    Test case passed!</pre><p><strong><pre style='display: inline;'>q5 - 33</pre> result:</strong></p><pre>    Trying:\n",
       "        words = 'Humpty Dumpty sat on a great fall'.split()\n",
       "    Expecting nothing\n",
       "    ok\n",
       "    Trying:\n",
       "        p = out_5c2.probability(words)\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 2, in q5 32\n",
       "    Failed example:\n",
       "        p = out_5c2.probability(words)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 32[1]>\", line 1, in <module>\n",
       "            p = out_5c2.probability(words)\n",
       "          File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "            modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "        AttributeError: 'list' object has no attribute 'mdl'\n",
       "    Trying:\n",
       "        np.isclose(p, 0.0, atol=0.001)\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 3, in q5 32\n",
       "    Failed example:\n",
       "        np.isclose(p, 0.0, atol=0.001)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 32[2]>\", line 1, in <module>\n",
       "            np.isclose(p, 0.0, atol=0.001)\n",
       "        NameError: name 'p' is not defined\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 33</pre> message:</strong> test probability 3gram</p><p><strong><pre style='display: inline;'>q5 - 34</pre> result:</strong></p><pre>    Trying:\n",
       "        words = 'Humpty Dumpty had'.split()\n",
       "    Expecting nothing\n",
       "    ok\n",
       "    Trying:\n",
       "        p = out_5c2.probability(words)\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 2, in q5 33\n",
       "    Failed example:\n",
       "        p = out_5c2.probability(words)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 33[1]>\", line 1, in <module>\n",
       "            p = out_5c2.probability(words)\n",
       "          File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "            modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "        AttributeError: 'list' object has no attribute 'mdl'\n",
       "    Trying:\n",
       "        np.isclose(p, 0.02564102564102564, atol=0.001)\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 3, in q5 33\n",
       "    Failed example:\n",
       "        np.isclose(p, 0.02564102564102564, atol=0.001)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 33[2]>\", line 1, in <module>\n",
       "            np.isclose(p, 0.02564102564102564, atol=0.001)\n",
       "        NameError: name 'p' is not defined\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 34</pre> message:</strong> test probability 3gram</p><p><strong><pre style='display: inline;'>q5 - 35</pre> result:</strong></p><pre>    Trying:\n",
       "        words = 'had a great fall'.split()\n",
       "    Expecting nothing\n",
       "    ok\n",
       "    Trying:\n",
       "        p = out_5c2.probability(words)\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 2, in q5 34\n",
       "    Failed example:\n",
       "        p = out_5c2.probability(words)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 34[1]>\", line 1, in <module>\n",
       "            p = out_5c2.probability(words)\n",
       "          File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "            modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "        AttributeError: 'list' object has no attribute 'mdl'\n",
       "    Trying:\n",
       "        np.isclose(p, 0.02564102564102564, atol=0.001)\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 3, in q5 34\n",
       "    Failed example:\n",
       "        np.isclose(p, 0.02564102564102564, atol=0.001)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 34[2]>\", line 1, in <module>\n",
       "            np.isclose(p, 0.02564102564102564, atol=0.001)\n",
       "        NameError: name 'p' is not defined\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 35</pre> message:</strong> test probability 3gram</p><p><strong><pre style='display: inline;'>q5 - 36</pre> result:</strong></p><pre>    Trying:\n",
       "        words = 'All the king \\' s men'.split()\n",
       "    Expecting nothing\n",
       "    ok\n",
       "    Trying:\n",
       "        p = out_5c2.probability(words)\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 2, in q5 35\n",
       "    Failed example:\n",
       "        p = out_5c2.probability(words)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 35[1]>\", line 1, in <module>\n",
       "            p = out_5c2.probability(words)\n",
       "          File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "            modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "        AttributeError: 'list' object has no attribute 'mdl'\n",
       "    Trying:\n",
       "        np.isclose(p, 0.01282051282051282, atol=0.001)\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 3, in q5 35\n",
       "    Failed example:\n",
       "        np.isclose(p, 0.01282051282051282, atol=0.001)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 35[2]>\", line 1, in <module>\n",
       "            np.isclose(p, 0.01282051282051282, atol=0.001)\n",
       "        NameError: name 'p' is not defined\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 36</pre> message:</strong> test probability 3gram</p><p><strong><pre style='display: inline;'>q5 - 37</pre> result:</strong></p><pre>    Trying:\n",
       "        words = 'Humpty Dumpty together again'.split()\n",
       "    Expecting nothing\n",
       "    ok\n",
       "    Trying:\n",
       "        p = out_5c2.probability(words)\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 2, in q5 36\n",
       "    Failed example:\n",
       "        p = out_5c2.probability(words)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 36[1]>\", line 1, in <module>\n",
       "            p = out_5c2.probability(words)\n",
       "          File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "            modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "        AttributeError: 'list' object has no attribute 'mdl'\n",
       "    Trying:\n",
       "        np.isclose(p, 0, atol=0.001)\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 3, in q5 36\n",
       "    Failed example:\n",
       "        np.isclose(p, 0, atol=0.001)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 36[2]>\", line 1, in <module>\n",
       "            np.isclose(p, 0, atol=0.001)\n",
       "        NameError: name 'p' is not defined\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 37</pre> message:</strong> test probability 3gram</p><p><strong><pre style='display: inline;'>q5 - 38</pre> result:</strong></p><pre>    Trying:\n",
       "        p = out_5c3.probability('In an appendix I base the first things to'.split())\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in q5 37\n",
       "    Failed example:\n",
       "        p = out_5c3.probability('In an appendix I base the first things to'.split())\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 37[0]>\", line 1, in <module>\n",
       "            p = out_5c3.probability('In an appendix I base the first things to'.split())\n",
       "          File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "            modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "        AttributeError: 'list' object has no attribute 'mdl'\n",
       "    Trying:\n",
       "        p > 0\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 2, in q5 37\n",
       "    Failed example:\n",
       "        p > 0\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 37[1]>\", line 1, in <module>\n",
       "            p > 0\n",
       "        NameError: name 'p' is not defined\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 38</pre> message:</strong> nonzero probability from homer</p><p><strong><pre style='display: inline;'>q5 - 39</pre> result:</strong></p><pre>    Trying:\n",
       "        p = out_5c3.probability('and there is'.split())\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in q5 38\n",
       "    Failed example:\n",
       "        p = out_5c3.probability('and there is'.split())\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 38[0]>\", line 1, in <module>\n",
       "            p = out_5c3.probability('and there is'.split())\n",
       "          File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "            modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "        AttributeError: 'list' object has no attribute 'mdl'\n",
       "    Trying:\n",
       "        np.isclose(p, 3.770591063715432e-05, atol=0.0001)\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 2, in q5 38\n",
       "    Failed example:\n",
       "        np.isclose(p, 3.770591063715432e-05, atol=0.0001)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 38[1]>\", line 1, in <module>\n",
       "            np.isclose(p, 3.770591063715432e-05, atol=0.0001)\n",
       "        NameError: name 'p' is not defined\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 39</pre> message:</strong> homer: common phrase</p><p><strong><pre style='display: inline;'>q5 - 40</pre> result:</strong></p><pre>    Trying:\n",
       "        495 <= len(out_5d2.split()) < 505\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q5 39\n",
       "    Failed example:\n",
       "        495 <= len(out_5d2.split()) < 505\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 39[0]>\", line 1, in <module>\n",
       "            495 <= len(out_5d2.split()) < 505\n",
       "        AttributeError: 'list' object has no attribute 'split'\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 40</pre> message:</strong> approx length of sample</p><p><strong><pre style='display: inline;'>q5 - 41</pre> result:</strong></p><pre>    Trying:\n",
       "        ('Humpty Dumpty' in out_5d2) or ('All the' in out_5d2)\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q5 40\n",
       "    Failed example:\n",
       "        ('Humpty Dumpty' in out_5d2) or ('All the' in out_5d2)\n",
       "    Expected:\n",
       "        True\n",
       "    Got:\n",
       "        False\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 41</pre> message:</strong> \"Humpty Dumpty\" or \"All the\" in sample</p><p><strong><pre style='display: inline;'>q5 - 42</pre> result:</strong></p><pre>    Trying:\n",
       "        'together again' in out_5d2\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q5 41\n",
       "    Failed example:\n",
       "        'together again' in out_5d2\n",
       "    Expected:\n",
       "        True\n",
       "    Got:\n",
       "        False\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 42</pre> message:</strong> together again in sample</p><p><strong><pre style='display: inline;'>q5 - 43</pre> result:</strong></p><pre>    Trying:\n",
       "        vc = pd.Series(out_5d2.split()).value_counts(normalize=True)\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in q5 42\n",
       "    Failed example:\n",
       "        vc = pd.Series(out_5d2.split()).value_counts(normalize=True)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 42[0]>\", line 1, in <module>\n",
       "            vc = pd.Series(out_5d2.split()).value_counts(normalize=True)\n",
       "        AttributeError: 'list' object has no attribute 'split'\n",
       "    Trying:\n",
       "        {'\\'', 'the', 'Humpty'}.intersection(set(vc.index[:6])) != {}\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 2, in q5 42\n",
       "    Failed example:\n",
       "        {'\\'', 'the', 'Humpty'}.intersection(set(vc.index[:6])) != {}\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 42[1]>\", line 1, in <module>\n",
       "            {'\\'', 'the', 'Humpty'}.intersection(set(vc.index[:6])) != {}\n",
       "        NameError: name 'vc' is not defined\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 43</pre> message:</strong> most common sampled tokens</p><p><strong><pre style='display: inline;'>q5 - 44</pre> result:</strong></p><pre>    Trying:\n",
       "        vc = pd.Series(out_5d2.split()).value_counts(normalize=True)\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in q5 43\n",
       "    Failed example:\n",
       "        vc = pd.Series(out_5d2.split()).value_counts(normalize=True)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 43[0]>\", line 1, in <module>\n",
       "            vc = pd.Series(out_5d2.split()).value_counts(normalize=True)\n",
       "        AttributeError: 'list' object has no attribute 'split'\n",
       "    Trying:\n",
       "        vc.iloc[0] >= 0.12\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 2, in q5 43\n",
       "    Failed example:\n",
       "        vc.iloc[0] >= 0.12\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 43[1]>\", line 1, in <module>\n",
       "            vc.iloc[0] >= 0.12\n",
       "        NameError: name 'vc' is not defined\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 44</pre> message:</strong> most common sampled tokens</p><p><strong><pre style='display: inline;'>q5 - 45</pre> result:</strong></p><pre>    Trying:\n",
       "        8 <= len(out_5d3.split()) <= 12\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q5 44\n",
       "    Failed example:\n",
       "        8 <= len(out_5d3.split()) <= 12\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q5 44[0]>\", line 1, in <module>\n",
       "            8 <= len(out_5d3.split()) <= 12\n",
       "        AttributeError: 'list' object has no attribute 'split'\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 45</pre> message:</strong> correct sample length</p><p><strong><pre style='display: inline;'>q5 - 46</pre> result:</strong></p><pre>    Trying:\n",
       "        cond = False\n",
       "    Expecting nothing\n",
       "    ok\n",
       "    Trying:\n",
       "        for w in 'Ulysses a the ,'.split():\n",
       "            cond = cond or (w in out_5d3)\n",
       "    Expecting nothing\n",
       "    ok\n",
       "    Trying:\n",
       "        cond\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 4, in q5 45\n",
       "    Failed example:\n",
       "        cond\n",
       "    Expected:\n",
       "        True\n",
       "    Got:\n",
       "        False\n",
       "</pre><p><strong><pre style='display: inline;'>q5 - 46</pre> message:</strong> homer: check for common word</p>"
      ],
      "text/plain": [
       "q5 results:\n",
       "    q5 - 1 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 2 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 3 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 4 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 5 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 6 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 7 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 8 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 9 result:\n",
       "        Trying:\n",
       "            p = out_5b1.loc[out_5b1.ngram == ('Humpty', 'Dumpty'), 'prob'].squeeze()\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            np.isclose(p, 0.666666, atol=0.001)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 8\n",
       "        Failed example:\n",
       "            np.isclose(p, 0.666666, atol=0.001)\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            array([False, False])\n",
       "\n",
       "    q5 - 9 message: Humpty Dumpty in bigrams\n",
       "\n",
       "    q5 - 10 result:\n",
       "        Trying:\n",
       "            words = 'Humpty Dumpty sat on a great fall'.split()\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            p = out_5c1.probability(words)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 9\n",
       "        Failed example:\n",
       "            p = out_5c1.probability(words)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 9[1]>\", line 1, in <module>\n",
       "                p = out_5c1.probability(words)\n",
       "              File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "                modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "            AttributeError: 'list' object has no attribute 'mdl'\n",
       "        Trying:\n",
       "            np.isclose(p, 0.01282051282051282, atol=0.001)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 3, in q5 9\n",
       "        Failed example:\n",
       "            np.isclose(p, 0.01282051282051282, atol=0.001)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 9[2]>\", line 1, in <module>\n",
       "                np.isclose(p, 0.01282051282051282, atol=0.001)\n",
       "            NameError: name 'p' is not defined\n",
       "\n",
       "    q5 - 10 message: test probability 2gram\n",
       "\n",
       "    q5 - 11 result:\n",
       "        Trying:\n",
       "            words = 'Humpty Dumpty'.split()\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            p = out_5c1.probability(words)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 10\n",
       "        Failed example:\n",
       "            p = out_5c1.probability(words)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 10[1]>\", line 1, in <module>\n",
       "                p = out_5c1.probability(words)\n",
       "              File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "                modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "            AttributeError: 'list' object has no attribute 'mdl'\n",
       "        Trying:\n",
       "            np.isclose(p, 0.05128205128205128, atol=0.001)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 3, in q5 10\n",
       "        Failed example:\n",
       "            np.isclose(p, 0.05128205128205128, atol=0.001)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 10[2]>\", line 1, in <module>\n",
       "                np.isclose(p, 0.05128205128205128, atol=0.001)\n",
       "            NameError: name 'p' is not defined\n",
       "\n",
       "    q5 - 11 message: test probability 2gram\n",
       "\n",
       "    q5 - 12 result:\n",
       "        Trying:\n",
       "            words = 'couldn \\' t put Humpty'.split()\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            p = out_5c1.probability(words)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 11\n",
       "        Failed example:\n",
       "            p = out_5c1.probability(words)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 11[1]>\", line 1, in <module>\n",
       "                p = out_5c1.probability(words)\n",
       "              File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "                modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "            AttributeError: 'list' object has no attribute 'mdl'\n",
       "        Trying:\n",
       "            np.isclose(p, 0.008547008547008546, atol=0.001)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 3, in q5 11\n",
       "        Failed example:\n",
       "            np.isclose(p, 0.008547008547008546, atol=0.001)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 11[2]>\", line 1, in <module>\n",
       "                np.isclose(p, 0.008547008547008546, atol=0.001)\n",
       "            NameError: name 'p' is not defined\n",
       "\n",
       "    q5 - 12 message: test probability 2gram\n",
       "\n",
       "    q5 - 13 result:\n",
       "        Trying:\n",
       "            words = 'All the king \\' s men'.split()\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            p = out_5c1.probability(words)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 12\n",
       "        Failed example:\n",
       "            p = out_5c1.probability(words)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 12[1]>\", line 1, in <module>\n",
       "                p = out_5c1.probability(words)\n",
       "              File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "                modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "            AttributeError: 'list' object has no attribute 'mdl'\n",
       "        Trying:\n",
       "            np.isclose(p, 0.008547008547008546, atol=0.001)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 3, in q5 12\n",
       "        Failed example:\n",
       "            np.isclose(p, 0.008547008547008546, atol=0.001)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 12[2]>\", line 1, in <module>\n",
       "                np.isclose(p, 0.008547008547008546, atol=0.001)\n",
       "            NameError: name 'p' is not defined\n",
       "\n",
       "    q5 - 13 message: test probability 2gram\n",
       "\n",
       "    q5 - 14 result:\n",
       "        Trying:\n",
       "            words = 'Humpty Dumpty together again'.split()\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            p = out_5c1.probability(words)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 13\n",
       "        Failed example:\n",
       "            p = out_5c1.probability(words)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 13[1]>\", line 1, in <module>\n",
       "                p = out_5c1.probability(words)\n",
       "              File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "                modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "            AttributeError: 'list' object has no attribute 'mdl'\n",
       "        Trying:\n",
       "            np.isclose(p, 0, atol=0.001)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 3, in q5 13\n",
       "        Failed example:\n",
       "            np.isclose(p, 0, atol=0.001)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 13[2]>\", line 1, in <module>\n",
       "                np.isclose(p, 0, atol=0.001)\n",
       "            NameError: name 'p' is not defined\n",
       "\n",
       "    q5 - 14 message: test probability 2gram\n",
       "\n",
       "    q5 - 15 result:\n",
       "        Trying:\n",
       "            495 <= len(out_5d1.split()) < 505\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 14\n",
       "        Failed example:\n",
       "            495 <= len(out_5d1.split()) < 505\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 14[0]>\", line 1, in <module>\n",
       "                495 <= len(out_5d1.split()) < 505\n",
       "            AttributeError: 'list' object has no attribute 'split'\n",
       "\n",
       "    q5 - 15 message: approx length of sample\n",
       "\n",
       "    q5 - 16 result:\n",
       "        Trying:\n",
       "            'Humpty Dumpty' in out_5d1\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 15\n",
       "        Failed example:\n",
       "            'Humpty Dumpty' in out_5d1\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            False\n",
       "\n",
       "    q5 - 16 message: Humpty Dumpty in sample\n",
       "\n",
       "    q5 - 17 result:\n",
       "        Trying:\n",
       "            'together again' in out_5d1\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 16\n",
       "        Failed example:\n",
       "            'together again' in out_5d1\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            False\n",
       "\n",
       "    q5 - 17 message: together again in sample\n",
       "\n",
       "    q5 - 18 result:\n",
       "        Trying:\n",
       "            vc = pd.Series(out_5d1.split()).value_counts(normalize=True)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 17\n",
       "        Failed example:\n",
       "            vc = pd.Series(out_5d1.split()).value_counts(normalize=True)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 17[0]>\", line 1, in <module>\n",
       "                vc = pd.Series(out_5d1.split()).value_counts(normalize=True)\n",
       "            AttributeError: 'list' object has no attribute 'split'\n",
       "        Trying:\n",
       "            {'\\'', 'the', 'Humpty'}.intersection(set(vc.index[:6])) != {}\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 17\n",
       "        Failed example:\n",
       "            {'\\'', 'the', 'Humpty'}.intersection(set(vc.index[:6])) != {}\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 17[1]>\", line 1, in <module>\n",
       "                {'\\'', 'the', 'Humpty'}.intersection(set(vc.index[:6])) != {}\n",
       "            NameError: name 'vc' is not defined\n",
       "\n",
       "    q5 - 18 message: most common sampled tokens\n",
       "\n",
       "    q5 - 19 result:\n",
       "        Trying:\n",
       "            vc = pd.Series(out_5d1.split()).value_counts(normalize=True)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 18\n",
       "        Failed example:\n",
       "            vc = pd.Series(out_5d1.split()).value_counts(normalize=True)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 18[0]>\", line 1, in <module>\n",
       "                vc = pd.Series(out_5d1.split()).value_counts(normalize=True)\n",
       "            AttributeError: 'list' object has no attribute 'split'\n",
       "        Trying:\n",
       "            np.isclose(vc.iloc[0], 0.07, atol=0.03)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 18\n",
       "        Failed example:\n",
       "            np.isclose(vc.iloc[0], 0.07, atol=0.03)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 18[1]>\", line 1, in <module>\n",
       "                np.isclose(vc.iloc[0], 0.07, atol=0.03)\n",
       "            NameError: name 'vc' is not defined\n",
       "\n",
       "    q5 - 19 message: most common sampled tokens\n",
       "\n",
       "    q5 - 20 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 21 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 22 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 23 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 24 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 25 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 26 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 27 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 28 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 29 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 30 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 31 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 32 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 33 result:\n",
       "        Trying:\n",
       "            words = 'Humpty Dumpty sat on a great fall'.split()\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            p = out_5c2.probability(words)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 32\n",
       "        Failed example:\n",
       "            p = out_5c2.probability(words)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 32[1]>\", line 1, in <module>\n",
       "                p = out_5c2.probability(words)\n",
       "              File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "                modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "            AttributeError: 'list' object has no attribute 'mdl'\n",
       "        Trying:\n",
       "            np.isclose(p, 0.0, atol=0.001)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 3, in q5 32\n",
       "        Failed example:\n",
       "            np.isclose(p, 0.0, atol=0.001)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 32[2]>\", line 1, in <module>\n",
       "                np.isclose(p, 0.0, atol=0.001)\n",
       "            NameError: name 'p' is not defined\n",
       "\n",
       "    q5 - 33 message: test probability 3gram\n",
       "\n",
       "    q5 - 34 result:\n",
       "        Trying:\n",
       "            words = 'Humpty Dumpty had'.split()\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            p = out_5c2.probability(words)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 33\n",
       "        Failed example:\n",
       "            p = out_5c2.probability(words)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 33[1]>\", line 1, in <module>\n",
       "                p = out_5c2.probability(words)\n",
       "              File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "                modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "            AttributeError: 'list' object has no attribute 'mdl'\n",
       "        Trying:\n",
       "            np.isclose(p, 0.02564102564102564, atol=0.001)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 3, in q5 33\n",
       "        Failed example:\n",
       "            np.isclose(p, 0.02564102564102564, atol=0.001)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 33[2]>\", line 1, in <module>\n",
       "                np.isclose(p, 0.02564102564102564, atol=0.001)\n",
       "            NameError: name 'p' is not defined\n",
       "\n",
       "    q5 - 34 message: test probability 3gram\n",
       "\n",
       "    q5 - 35 result:\n",
       "        Trying:\n",
       "            words = 'had a great fall'.split()\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            p = out_5c2.probability(words)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 34\n",
       "        Failed example:\n",
       "            p = out_5c2.probability(words)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 34[1]>\", line 1, in <module>\n",
       "                p = out_5c2.probability(words)\n",
       "              File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "                modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "            AttributeError: 'list' object has no attribute 'mdl'\n",
       "        Trying:\n",
       "            np.isclose(p, 0.02564102564102564, atol=0.001)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 3, in q5 34\n",
       "        Failed example:\n",
       "            np.isclose(p, 0.02564102564102564, atol=0.001)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 34[2]>\", line 1, in <module>\n",
       "                np.isclose(p, 0.02564102564102564, atol=0.001)\n",
       "            NameError: name 'p' is not defined\n",
       "\n",
       "    q5 - 35 message: test probability 3gram\n",
       "\n",
       "    q5 - 36 result:\n",
       "        Trying:\n",
       "            words = 'All the king \\' s men'.split()\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            p = out_5c2.probability(words)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 35\n",
       "        Failed example:\n",
       "            p = out_5c2.probability(words)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 35[1]>\", line 1, in <module>\n",
       "                p = out_5c2.probability(words)\n",
       "              File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "                modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "            AttributeError: 'list' object has no attribute 'mdl'\n",
       "        Trying:\n",
       "            np.isclose(p, 0.01282051282051282, atol=0.001)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 3, in q5 35\n",
       "        Failed example:\n",
       "            np.isclose(p, 0.01282051282051282, atol=0.001)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 35[2]>\", line 1, in <module>\n",
       "                np.isclose(p, 0.01282051282051282, atol=0.001)\n",
       "            NameError: name 'p' is not defined\n",
       "\n",
       "    q5 - 36 message: test probability 3gram\n",
       "\n",
       "    q5 - 37 result:\n",
       "        Trying:\n",
       "            words = 'Humpty Dumpty together again'.split()\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            p = out_5c2.probability(words)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 36\n",
       "        Failed example:\n",
       "            p = out_5c2.probability(words)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 36[1]>\", line 1, in <module>\n",
       "                p = out_5c2.probability(words)\n",
       "              File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "                modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "            AttributeError: 'list' object has no attribute 'mdl'\n",
       "        Trying:\n",
       "            np.isclose(p, 0, atol=0.001)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 3, in q5 36\n",
       "        Failed example:\n",
       "            np.isclose(p, 0, atol=0.001)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 36[2]>\", line 1, in <module>\n",
       "                np.isclose(p, 0, atol=0.001)\n",
       "            NameError: name 'p' is not defined\n",
       "\n",
       "    q5 - 37 message: test probability 3gram\n",
       "\n",
       "    q5 - 38 result:\n",
       "        Trying:\n",
       "            p = out_5c3.probability('In an appendix I base the first things to'.split())\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 37\n",
       "        Failed example:\n",
       "            p = out_5c3.probability('In an appendix I base the first things to'.split())\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 37[0]>\", line 1, in <module>\n",
       "                p = out_5c3.probability('In an appendix I base the first things to'.split())\n",
       "              File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "                modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "            AttributeError: 'list' object has no attribute 'mdl'\n",
       "        Trying:\n",
       "            p > 0\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 37\n",
       "        Failed example:\n",
       "            p > 0\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 37[1]>\", line 1, in <module>\n",
       "                p > 0\n",
       "            NameError: name 'p' is not defined\n",
       "\n",
       "    q5 - 38 message: nonzero probability from homer\n",
       "\n",
       "    q5 - 39 result:\n",
       "        Trying:\n",
       "            p = out_5c3.probability('and there is'.split())\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 38\n",
       "        Failed example:\n",
       "            p = out_5c3.probability('and there is'.split())\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 38[0]>\", line 1, in <module>\n",
       "                p = out_5c3.probability('and there is'.split())\n",
       "              File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "                modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "            AttributeError: 'list' object has no attribute 'mdl'\n",
       "        Trying:\n",
       "            np.isclose(p, 3.770591063715432e-05, atol=0.0001)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 38\n",
       "        Failed example:\n",
       "            np.isclose(p, 3.770591063715432e-05, atol=0.0001)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 38[1]>\", line 1, in <module>\n",
       "                np.isclose(p, 3.770591063715432e-05, atol=0.0001)\n",
       "            NameError: name 'p' is not defined\n",
       "\n",
       "    q5 - 39 message: homer: common phrase\n",
       "\n",
       "    q5 - 40 result:\n",
       "        Trying:\n",
       "            495 <= len(out_5d2.split()) < 505\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 39\n",
       "        Failed example:\n",
       "            495 <= len(out_5d2.split()) < 505\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 39[0]>\", line 1, in <module>\n",
       "                495 <= len(out_5d2.split()) < 505\n",
       "            AttributeError: 'list' object has no attribute 'split'\n",
       "\n",
       "    q5 - 40 message: approx length of sample\n",
       "\n",
       "    q5 - 41 result:\n",
       "        Trying:\n",
       "            ('Humpty Dumpty' in out_5d2) or ('All the' in out_5d2)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 40\n",
       "        Failed example:\n",
       "            ('Humpty Dumpty' in out_5d2) or ('All the' in out_5d2)\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            False\n",
       "\n",
       "    q5 - 41 message: \"Humpty Dumpty\" or \"All the\" in sample\n",
       "\n",
       "    q5 - 42 result:\n",
       "        Trying:\n",
       "            'together again' in out_5d2\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 41\n",
       "        Failed example:\n",
       "            'together again' in out_5d2\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            False\n",
       "\n",
       "    q5 - 42 message: together again in sample\n",
       "\n",
       "    q5 - 43 result:\n",
       "        Trying:\n",
       "            vc = pd.Series(out_5d2.split()).value_counts(normalize=True)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 42\n",
       "        Failed example:\n",
       "            vc = pd.Series(out_5d2.split()).value_counts(normalize=True)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 42[0]>\", line 1, in <module>\n",
       "                vc = pd.Series(out_5d2.split()).value_counts(normalize=True)\n",
       "            AttributeError: 'list' object has no attribute 'split'\n",
       "        Trying:\n",
       "            {'\\'', 'the', 'Humpty'}.intersection(set(vc.index[:6])) != {}\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 42\n",
       "        Failed example:\n",
       "            {'\\'', 'the', 'Humpty'}.intersection(set(vc.index[:6])) != {}\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 42[1]>\", line 1, in <module>\n",
       "                {'\\'', 'the', 'Humpty'}.intersection(set(vc.index[:6])) != {}\n",
       "            NameError: name 'vc' is not defined\n",
       "\n",
       "    q5 - 43 message: most common sampled tokens\n",
       "\n",
       "    q5 - 44 result:\n",
       "        Trying:\n",
       "            vc = pd.Series(out_5d2.split()).value_counts(normalize=True)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 43\n",
       "        Failed example:\n",
       "            vc = pd.Series(out_5d2.split()).value_counts(normalize=True)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 43[0]>\", line 1, in <module>\n",
       "                vc = pd.Series(out_5d2.split()).value_counts(normalize=True)\n",
       "            AttributeError: 'list' object has no attribute 'split'\n",
       "        Trying:\n",
       "            vc.iloc[0] >= 0.12\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 43\n",
       "        Failed example:\n",
       "            vc.iloc[0] >= 0.12\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 43[1]>\", line 1, in <module>\n",
       "                vc.iloc[0] >= 0.12\n",
       "            NameError: name 'vc' is not defined\n",
       "\n",
       "    q5 - 44 message: most common sampled tokens\n",
       "\n",
       "    q5 - 45 result:\n",
       "        Trying:\n",
       "            8 <= len(out_5d3.split()) <= 12\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 44\n",
       "        Failed example:\n",
       "            8 <= len(out_5d3.split()) <= 12\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 44[0]>\", line 1, in <module>\n",
       "                8 <= len(out_5d3.split()) <= 12\n",
       "            AttributeError: 'list' object has no attribute 'split'\n",
       "\n",
       "    q5 - 45 message: correct sample length\n",
       "\n",
       "    q5 - 46 result:\n",
       "        Trying:\n",
       "            cond = False\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            for w in 'Ulysses a the ,'.split():\n",
       "                cond = cond or (w in out_5d3)\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            cond\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 4, in q5 45\n",
       "        Failed example:\n",
       "            cond\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            False\n",
       "\n",
       "    q5 - 46 message: homer: check for common word"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've built an N-Gram language model, let's use it to actually generate sentences!\n",
    "\n",
    "Uncomment and run the cell below to define a bigram model using the `shakes` corpus and to generate a sentence of length 50 using the model. **The cell should run in under 30 seconds.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run\n",
    "# shakes_bigram = NGramLM(2, shakes)\n",
    "# shakes_bigram.sample(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hidden tests in Part 3/Question 5 will test your `NGramLM` implementation on corpuses that are much longer than the doctests/public tests. One of the corpuses we will test your implementation on is in `data/homertokens.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "homer_tokens = tuple(open('data/homertokens.txt').read().split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As such, it's a good idea to make sure that you can instantiate an `NGramLM` object using `homer_tokens` and that all methods (`probability`, `sample`) run in under ~20 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NGramLM(5, homer_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you're satisfied with your `NGramLM` implementation, do a little bit of reflecting. How might you improve the `NGramLM` model? One major deficit is that it assigns a probability of 0 to sentences that contain N-Grams that weren't seen in the corpus; how might you address this? _Hint: You encountered a similar issue when learning NaÃ¯ve Bayes in DSC 40A! ðŸ˜Š_\n",
    "\n",
    "You don't need to actually make any improvements to `NGramLM`, these are just points for you to think about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations, you've finished Project 4! ðŸŽ‰\n",
    "\n",
    "Submit your `project.py` file to Gradescope. Note that you only need to submit the `project.py` file; this notebook should not be uploaded because there are no manually-graded questions in this project.\n",
    "\n",
    "Before submitting, you should ensure that all of your work is in the `project.py` file. You can do this by running the doctests below, which will verify that your work passes the public tests **and** that your work is in the `project.py` file. Run the cell below; you should see no output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "File \"c:\\Users\\Zaki Ahmed\\dsc30_sp22\\dsc80-2022-fa\\projects\\04-language_models\\assignment\\project.py\", line 315, in project.NGramLM.create_ngrams\n",
      "Failed example:\n",
      "    bigrams = NGramLM(2, [])\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "      File \"<doctest project.NGramLM.create_ngrams[1]>\", line 1, in <module>\n",
      "        bigrams = NGramLM(2, [])\n",
      "      File \"c:\\Users\\Zaki Ahmed\\dsc30_sp22\\dsc80-2022-fa\\projects\\04-language_models\\assignment\\project.py\", line 298, in __init__\n",
      "        self.mdl = self.train(ngrams)\n",
      "      File \"c:\\Users\\Zaki Ahmed\\dsc30_sp22\\dsc80-2022-fa\\projects\\04-language_models\\assignment\\project.py\", line 367, in train\n",
      "        out[\"prob\"] = out.apply(helper, axis=1)\n",
      "      File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py\", line 3646, in __setitem__\n",
      "        self._set_item_frame_value(key, value)\n",
      "      File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py\", line 3776, in _set_item_frame_value\n",
      "        raise ValueError(\"Columns must be same length as key\")\n",
      "    ValueError: Columns must be same length as key\n",
      "**********************************************************************\n",
      "File \"c:\\Users\\Zaki Ahmed\\dsc30_sp22\\dsc80-2022-fa\\projects\\04-language_models\\assignment\\project.py\", line 316, in project.NGramLM.create_ngrams\n",
      "Failed example:\n",
      "    out = bigrams.create_ngrams(tokens)\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "      File \"<doctest project.NGramLM.create_ngrams[2]>\", line 1, in <module>\n",
      "        out = bigrams.create_ngrams(tokens)\n",
      "    NameError: name 'bigrams' is not defined\n",
      "**********************************************************************\n",
      "File \"c:\\Users\\Zaki Ahmed\\dsc30_sp22\\dsc80-2022-fa\\projects\\04-language_models\\assignment\\project.py\", line 317, in project.NGramLM.create_ngrams\n",
      "Failed example:\n",
      "    isinstance(out[0], tuple)\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "      File \"<doctest project.NGramLM.create_ngrams[3]>\", line 1, in <module>\n",
      "        isinstance(out[0], tuple)\n",
      "    NameError: name 'out' is not defined\n",
      "**********************************************************************\n",
      "File \"c:\\Users\\Zaki Ahmed\\dsc30_sp22\\dsc80-2022-fa\\projects\\04-language_models\\assignment\\project.py\", line 319, in project.NGramLM.create_ngrams\n",
      "Failed example:\n",
      "    out[0]\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "      File \"<doctest project.NGramLM.create_ngrams[4]>\", line 1, in <module>\n",
      "        out[0]\n",
      "    NameError: name 'out' is not defined\n",
      "**********************************************************************\n",
      "File \"c:\\Users\\Zaki Ahmed\\dsc30_sp22\\dsc80-2022-fa\\projects\\04-language_models\\assignment\\project.py\", line 321, in project.NGramLM.create_ngrams\n",
      "Failed example:\n",
      "    out[2]\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "      File \"<doctest project.NGramLM.create_ngrams[5]>\", line 1, in <module>\n",
      "        out[2]\n",
      "    NameError: name 'out' is not defined\n",
      "**********************************************************************\n",
      "File \"c:\\Users\\Zaki Ahmed\\dsc30_sp22\\dsc80-2022-fa\\projects\\04-language_models\\assignment\\project.py\", line 384, in project.NGramLM.probability\n",
      "Failed example:\n",
      "    np.isclose(p, (1/4) * (1/2) * (1/3))\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "      File \"<doctest project.NGramLM.probability[3]>\", line 1, in <module>\n",
      "        np.isclose(p, (1/4) * (1/2) * (1/3))\n",
      "      File \"<__array_function__ internals>\", line 180, in isclose\n",
      "      File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\numeric.py\", line 2358, in isclose\n",
      "        xfin = isfinite(x)\n",
      "    TypeError: ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\n",
      "**********************************************************************\n",
      "File \"c:\\Users\\Zaki Ahmed\\dsc30_sp22\\dsc80-2022-fa\\projects\\04-language_models\\assignment\\project.py\", line 386, in project.NGramLM.probability\n",
      "Failed example:\n",
      "    bigrams.probability('one two five'.split()) == 0\n",
      "Expected:\n",
      "    True\n",
      "Got:\n",
      "    False\n",
      "**********************************************************************\n",
      "File \"c:\\Users\\Zaki Ahmed\\dsc30_sp22\\dsc80-2022-fa\\projects\\04-language_models\\assignment\\project.py\", line 401, in project.NGramLM.sample\n",
      "Failed example:\n",
      "    len(samp.split()) == 4  # don't count the initial START token.\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "      File \"<doctest project.NGramLM.sample[3]>\", line 1, in <module>\n",
      "        len(samp.split()) == 4  # don't count the initial START token.\n",
      "    AttributeError: 'NoneType' object has no attribute 'split'\n",
      "**********************************************************************\n",
      "File \"c:\\Users\\Zaki Ahmed\\dsc30_sp22\\dsc80-2022-fa\\projects\\04-language_models\\assignment\\project.py\", line 403, in project.NGramLM.sample\n",
      "Failed example:\n",
      "    samp[:2] == '\\x02 '\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "      File \"<doctest project.NGramLM.sample[4]>\", line 1, in <module>\n",
      "        samp[:2] == '\\x02 '\n",
      "    TypeError: 'NoneType' object is not subscriptable\n",
      "**********************************************************************\n",
      "File \"c:\\Users\\Zaki Ahmed\\dsc30_sp22\\dsc80-2022-fa\\projects\\04-language_models\\assignment\\project.py\", line 405, in project.NGramLM.sample\n",
      "Failed example:\n",
      "    set(samp.split()) <= {'\\x02', '\\x03', 'one', 'two', 'three', 'four'}\n",
      "Exception raised:\n",
      "    Traceback (most recent call last):\n",
      "      File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
      "        exec(compile(example.source, filename, \"single\",\n",
      "      File \"<doctest project.NGramLM.sample[5]>\", line 1, in <module>\n",
      "        set(samp.split()) <= {'\\x02', '\\x03', 'one', 'two', 'three', 'four'}\n",
      "    AttributeError: 'NoneType' object has no attribute 'split'\n",
      "**********************************************************************\n",
      "3 items had failures:\n",
      "   5 of   6 in project.NGramLM.create_ngrams\n",
      "   2 of   5 in project.NGramLM.probability\n",
      "   3 of   6 in project.NGramLM.sample\n",
      "***Test Failed*** 10 failures.\n"
     ]
    }
   ],
   "source": [
    "!python -m doctest project.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, `grader.check_all()` will verify that your work passes the public tests. Ultimately, the Gradescope autograder is also going to run `grader.check_all()`, so you should ensure these pass as well (which they should if the doctests above passed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q1 results:\n",
       "    q1 - 1 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q1 - 2 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q1 - 3 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q1 - 4 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q1 - 5 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q1 - 6 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q1 - 7 result:\n",
       "        Trying:\n",
       "            story = 'rendered into English'\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            story in homer\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 2, in q1 6\n",
       "        Failed example:\n",
       "            story in homer\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            False\n",
       "\n",
       "    q1 - 7 message: text from book check\n",
       "\n",
       "    q1 - 8 result:\n",
       "        Trying:\n",
       "            story = 'I was shown a man who was always called'\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            story in homer\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 2, in q1 7\n",
       "        Failed example:\n",
       "            story in homer\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            False\n",
       "\n",
       "    q1 - 8 message: text from book check\n",
       "\n",
       "    q1 - 9 result:\n",
       "        Test case passed!\n",
       "\n",
       "q2 results: All test cases passed!\n",
       "\n",
       "q3 results: All test cases passed!\n",
       "\n",
       "q4 results: All test cases passed!\n",
       "\n",
       "q5 results:\n",
       "    q5 - 1 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 2 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 3 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 4 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 5 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 6 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 7 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 8 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 9 result:\n",
       "        Trying:\n",
       "            p = out_5b1.loc[out_5b1.ngram == ('Humpty', 'Dumpty'), 'prob'].squeeze()\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            np.isclose(p, 0.666666, atol=0.001)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 8\n",
       "        Failed example:\n",
       "            np.isclose(p, 0.666666, atol=0.001)\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            array([False, False])\n",
       "\n",
       "    q5 - 9 message: Humpty Dumpty in bigrams\n",
       "\n",
       "    q5 - 10 result:\n",
       "        Trying:\n",
       "            words = 'Humpty Dumpty sat on a great fall'.split()\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            p = out_5c1.probability(words)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 9\n",
       "        Failed example:\n",
       "            p = out_5c1.probability(words)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 9[1]>\", line 1, in <module>\n",
       "                p = out_5c1.probability(words)\n",
       "              File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "                modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "            AttributeError: 'list' object has no attribute 'mdl'\n",
       "        Trying:\n",
       "            np.isclose(p, 0.01282051282051282, atol=0.001)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 3, in q5 9\n",
       "        Failed example:\n",
       "            np.isclose(p, 0.01282051282051282, atol=0.001)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 9[2]>\", line 1, in <module>\n",
       "                np.isclose(p, 0.01282051282051282, atol=0.001)\n",
       "            NameError: name 'p' is not defined\n",
       "\n",
       "    q5 - 10 message: test probability 2gram\n",
       "\n",
       "    q5 - 11 result:\n",
       "        Trying:\n",
       "            words = 'Humpty Dumpty'.split()\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            p = out_5c1.probability(words)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 10\n",
       "        Failed example:\n",
       "            p = out_5c1.probability(words)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 10[1]>\", line 1, in <module>\n",
       "                p = out_5c1.probability(words)\n",
       "              File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "                modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "            AttributeError: 'list' object has no attribute 'mdl'\n",
       "        Trying:\n",
       "            np.isclose(p, 0.05128205128205128, atol=0.001)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 3, in q5 10\n",
       "        Failed example:\n",
       "            np.isclose(p, 0.05128205128205128, atol=0.001)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 10[2]>\", line 1, in <module>\n",
       "                np.isclose(p, 0.05128205128205128, atol=0.001)\n",
       "            NameError: name 'p' is not defined\n",
       "\n",
       "    q5 - 11 message: test probability 2gram\n",
       "\n",
       "    q5 - 12 result:\n",
       "        Trying:\n",
       "            words = 'couldn \\' t put Humpty'.split()\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            p = out_5c1.probability(words)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 11\n",
       "        Failed example:\n",
       "            p = out_5c1.probability(words)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 11[1]>\", line 1, in <module>\n",
       "                p = out_5c1.probability(words)\n",
       "              File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "                modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "            AttributeError: 'list' object has no attribute 'mdl'\n",
       "        Trying:\n",
       "            np.isclose(p, 0.008547008547008546, atol=0.001)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 3, in q5 11\n",
       "        Failed example:\n",
       "            np.isclose(p, 0.008547008547008546, atol=0.001)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 11[2]>\", line 1, in <module>\n",
       "                np.isclose(p, 0.008547008547008546, atol=0.001)\n",
       "            NameError: name 'p' is not defined\n",
       "\n",
       "    q5 - 12 message: test probability 2gram\n",
       "\n",
       "    q5 - 13 result:\n",
       "        Trying:\n",
       "            words = 'All the king \\' s men'.split()\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            p = out_5c1.probability(words)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 12\n",
       "        Failed example:\n",
       "            p = out_5c1.probability(words)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 12[1]>\", line 1, in <module>\n",
       "                p = out_5c1.probability(words)\n",
       "              File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "                modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "            AttributeError: 'list' object has no attribute 'mdl'\n",
       "        Trying:\n",
       "            np.isclose(p, 0.008547008547008546, atol=0.001)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 3, in q5 12\n",
       "        Failed example:\n",
       "            np.isclose(p, 0.008547008547008546, atol=0.001)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 12[2]>\", line 1, in <module>\n",
       "                np.isclose(p, 0.008547008547008546, atol=0.001)\n",
       "            NameError: name 'p' is not defined\n",
       "\n",
       "    q5 - 13 message: test probability 2gram\n",
       "\n",
       "    q5 - 14 result:\n",
       "        Trying:\n",
       "            words = 'Humpty Dumpty together again'.split()\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            p = out_5c1.probability(words)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 13\n",
       "        Failed example:\n",
       "            p = out_5c1.probability(words)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 13[1]>\", line 1, in <module>\n",
       "                p = out_5c1.probability(words)\n",
       "              File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "                modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "            AttributeError: 'list' object has no attribute 'mdl'\n",
       "        Trying:\n",
       "            np.isclose(p, 0, atol=0.001)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 3, in q5 13\n",
       "        Failed example:\n",
       "            np.isclose(p, 0, atol=0.001)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 13[2]>\", line 1, in <module>\n",
       "                np.isclose(p, 0, atol=0.001)\n",
       "            NameError: name 'p' is not defined\n",
       "\n",
       "    q5 - 14 message: test probability 2gram\n",
       "\n",
       "    q5 - 15 result:\n",
       "        Trying:\n",
       "            495 <= len(out_5d1.split()) < 505\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 14\n",
       "        Failed example:\n",
       "            495 <= len(out_5d1.split()) < 505\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 14[0]>\", line 1, in <module>\n",
       "                495 <= len(out_5d1.split()) < 505\n",
       "            AttributeError: 'list' object has no attribute 'split'\n",
       "\n",
       "    q5 - 15 message: approx length of sample\n",
       "\n",
       "    q5 - 16 result:\n",
       "        Trying:\n",
       "            'Humpty Dumpty' in out_5d1\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 15\n",
       "        Failed example:\n",
       "            'Humpty Dumpty' in out_5d1\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            False\n",
       "\n",
       "    q5 - 16 message: Humpty Dumpty in sample\n",
       "\n",
       "    q5 - 17 result:\n",
       "        Trying:\n",
       "            'together again' in out_5d1\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 16\n",
       "        Failed example:\n",
       "            'together again' in out_5d1\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            False\n",
       "\n",
       "    q5 - 17 message: together again in sample\n",
       "\n",
       "    q5 - 18 result:\n",
       "        Trying:\n",
       "            vc = pd.Series(out_5d1.split()).value_counts(normalize=True)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 17\n",
       "        Failed example:\n",
       "            vc = pd.Series(out_5d1.split()).value_counts(normalize=True)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 17[0]>\", line 1, in <module>\n",
       "                vc = pd.Series(out_5d1.split()).value_counts(normalize=True)\n",
       "            AttributeError: 'list' object has no attribute 'split'\n",
       "        Trying:\n",
       "            {'\\'', 'the', 'Humpty'}.intersection(set(vc.index[:6])) != {}\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 17\n",
       "        Failed example:\n",
       "            {'\\'', 'the', 'Humpty'}.intersection(set(vc.index[:6])) != {}\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 17[1]>\", line 1, in <module>\n",
       "                {'\\'', 'the', 'Humpty'}.intersection(set(vc.index[:6])) != {}\n",
       "            NameError: name 'vc' is not defined\n",
       "\n",
       "    q5 - 18 message: most common sampled tokens\n",
       "\n",
       "    q5 - 19 result:\n",
       "        Trying:\n",
       "            vc = pd.Series(out_5d1.split()).value_counts(normalize=True)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 18\n",
       "        Failed example:\n",
       "            vc = pd.Series(out_5d1.split()).value_counts(normalize=True)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 18[0]>\", line 1, in <module>\n",
       "                vc = pd.Series(out_5d1.split()).value_counts(normalize=True)\n",
       "            AttributeError: 'list' object has no attribute 'split'\n",
       "        Trying:\n",
       "            np.isclose(vc.iloc[0], 0.07, atol=0.03)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 18\n",
       "        Failed example:\n",
       "            np.isclose(vc.iloc[0], 0.07, atol=0.03)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 18[1]>\", line 1, in <module>\n",
       "                np.isclose(vc.iloc[0], 0.07, atol=0.03)\n",
       "            NameError: name 'vc' is not defined\n",
       "\n",
       "    q5 - 19 message: most common sampled tokens\n",
       "\n",
       "    q5 - 20 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 21 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 22 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 23 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 24 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 25 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 26 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 27 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 28 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 29 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 30 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 31 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 32 result:\n",
       "        Test case passed!\n",
       "\n",
       "    q5 - 33 result:\n",
       "        Trying:\n",
       "            words = 'Humpty Dumpty sat on a great fall'.split()\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            p = out_5c2.probability(words)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 32\n",
       "        Failed example:\n",
       "            p = out_5c2.probability(words)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 32[1]>\", line 1, in <module>\n",
       "                p = out_5c2.probability(words)\n",
       "              File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "                modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "            AttributeError: 'list' object has no attribute 'mdl'\n",
       "        Trying:\n",
       "            np.isclose(p, 0.0, atol=0.001)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 3, in q5 32\n",
       "        Failed example:\n",
       "            np.isclose(p, 0.0, atol=0.001)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 32[2]>\", line 1, in <module>\n",
       "                np.isclose(p, 0.0, atol=0.001)\n",
       "            NameError: name 'p' is not defined\n",
       "\n",
       "    q5 - 33 message: test probability 3gram\n",
       "\n",
       "    q5 - 34 result:\n",
       "        Trying:\n",
       "            words = 'Humpty Dumpty had'.split()\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            p = out_5c2.probability(words)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 33\n",
       "        Failed example:\n",
       "            p = out_5c2.probability(words)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 33[1]>\", line 1, in <module>\n",
       "                p = out_5c2.probability(words)\n",
       "              File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "                modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "            AttributeError: 'list' object has no attribute 'mdl'\n",
       "        Trying:\n",
       "            np.isclose(p, 0.02564102564102564, atol=0.001)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 3, in q5 33\n",
       "        Failed example:\n",
       "            np.isclose(p, 0.02564102564102564, atol=0.001)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 33[2]>\", line 1, in <module>\n",
       "                np.isclose(p, 0.02564102564102564, atol=0.001)\n",
       "            NameError: name 'p' is not defined\n",
       "\n",
       "    q5 - 34 message: test probability 3gram\n",
       "\n",
       "    q5 - 35 result:\n",
       "        Trying:\n",
       "            words = 'had a great fall'.split()\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            p = out_5c2.probability(words)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 34\n",
       "        Failed example:\n",
       "            p = out_5c2.probability(words)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 34[1]>\", line 1, in <module>\n",
       "                p = out_5c2.probability(words)\n",
       "              File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "                modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "            AttributeError: 'list' object has no attribute 'mdl'\n",
       "        Trying:\n",
       "            np.isclose(p, 0.02564102564102564, atol=0.001)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 3, in q5 34\n",
       "        Failed example:\n",
       "            np.isclose(p, 0.02564102564102564, atol=0.001)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 34[2]>\", line 1, in <module>\n",
       "                np.isclose(p, 0.02564102564102564, atol=0.001)\n",
       "            NameError: name 'p' is not defined\n",
       "\n",
       "    q5 - 35 message: test probability 3gram\n",
       "\n",
       "    q5 - 36 result:\n",
       "        Trying:\n",
       "            words = 'All the king \\' s men'.split()\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            p = out_5c2.probability(words)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 35\n",
       "        Failed example:\n",
       "            p = out_5c2.probability(words)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 35[1]>\", line 1, in <module>\n",
       "                p = out_5c2.probability(words)\n",
       "              File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "                modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "            AttributeError: 'list' object has no attribute 'mdl'\n",
       "        Trying:\n",
       "            np.isclose(p, 0.01282051282051282, atol=0.001)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 3, in q5 35\n",
       "        Failed example:\n",
       "            np.isclose(p, 0.01282051282051282, atol=0.001)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 35[2]>\", line 1, in <module>\n",
       "                np.isclose(p, 0.01282051282051282, atol=0.001)\n",
       "            NameError: name 'p' is not defined\n",
       "\n",
       "    q5 - 36 message: test probability 3gram\n",
       "\n",
       "    q5 - 37 result:\n",
       "        Trying:\n",
       "            words = 'Humpty Dumpty together again'.split()\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            p = out_5c2.probability(words)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 36\n",
       "        Failed example:\n",
       "            p = out_5c2.probability(words)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 36[1]>\", line 1, in <module>\n",
       "                p = out_5c2.probability(words)\n",
       "              File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "                modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "            AttributeError: 'list' object has no attribute 'mdl'\n",
       "        Trying:\n",
       "            np.isclose(p, 0, atol=0.001)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 3, in q5 36\n",
       "        Failed example:\n",
       "            np.isclose(p, 0, atol=0.001)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 36[2]>\", line 1, in <module>\n",
       "                np.isclose(p, 0, atol=0.001)\n",
       "            NameError: name 'p' is not defined\n",
       "\n",
       "    q5 - 37 message: test probability 3gram\n",
       "\n",
       "    q5 - 38 result:\n",
       "        Trying:\n",
       "            p = out_5c3.probability('In an appendix I base the first things to'.split())\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 37\n",
       "        Failed example:\n",
       "            p = out_5c3.probability('In an appendix I base the first things to'.split())\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 37[0]>\", line 1, in <module>\n",
       "                p = out_5c3.probability('In an appendix I base the first things to'.split())\n",
       "              File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "                modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "            AttributeError: 'list' object has no attribute 'mdl'\n",
       "        Trying:\n",
       "            p > 0\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 37\n",
       "        Failed example:\n",
       "            p > 0\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 37[1]>\", line 1, in <module>\n",
       "                p > 0\n",
       "            NameError: name 'p' is not defined\n",
       "\n",
       "    q5 - 38 message: nonzero probability from homer\n",
       "\n",
       "    q5 - 39 result:\n",
       "        Trying:\n",
       "            p = out_5c3.probability('and there is'.split())\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 38\n",
       "        Failed example:\n",
       "            p = out_5c3.probability('and there is'.split())\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 38[0]>\", line 1, in <module>\n",
       "                p = out_5c3.probability('and there is'.split())\n",
       "              File \"C:\\Users\\Zaki Ahmed\\AppData\\Local\\Temp\\ipykernel_13792\\3570117194.py\", line 113, in probability\n",
       "                modelngrams, wordsngrams = list(x.mdl['ngram']), list(self.create_ngrams(words))\n",
       "            AttributeError: 'list' object has no attribute 'mdl'\n",
       "        Trying:\n",
       "            np.isclose(p, 3.770591063715432e-05, atol=0.0001)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 38\n",
       "        Failed example:\n",
       "            np.isclose(p, 3.770591063715432e-05, atol=0.0001)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 38[1]>\", line 1, in <module>\n",
       "                np.isclose(p, 3.770591063715432e-05, atol=0.0001)\n",
       "            NameError: name 'p' is not defined\n",
       "\n",
       "    q5 - 39 message: homer: common phrase\n",
       "\n",
       "    q5 - 40 result:\n",
       "        Trying:\n",
       "            495 <= len(out_5d2.split()) < 505\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 39\n",
       "        Failed example:\n",
       "            495 <= len(out_5d2.split()) < 505\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 39[0]>\", line 1, in <module>\n",
       "                495 <= len(out_5d2.split()) < 505\n",
       "            AttributeError: 'list' object has no attribute 'split'\n",
       "\n",
       "    q5 - 40 message: approx length of sample\n",
       "\n",
       "    q5 - 41 result:\n",
       "        Trying:\n",
       "            ('Humpty Dumpty' in out_5d2) or ('All the' in out_5d2)\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 40\n",
       "        Failed example:\n",
       "            ('Humpty Dumpty' in out_5d2) or ('All the' in out_5d2)\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            False\n",
       "\n",
       "    q5 - 41 message: \"Humpty Dumpty\" or \"All the\" in sample\n",
       "\n",
       "    q5 - 42 result:\n",
       "        Trying:\n",
       "            'together again' in out_5d2\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 41\n",
       "        Failed example:\n",
       "            'together again' in out_5d2\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            False\n",
       "\n",
       "    q5 - 42 message: together again in sample\n",
       "\n",
       "    q5 - 43 result:\n",
       "        Trying:\n",
       "            vc = pd.Series(out_5d2.split()).value_counts(normalize=True)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 42\n",
       "        Failed example:\n",
       "            vc = pd.Series(out_5d2.split()).value_counts(normalize=True)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 42[0]>\", line 1, in <module>\n",
       "                vc = pd.Series(out_5d2.split()).value_counts(normalize=True)\n",
       "            AttributeError: 'list' object has no attribute 'split'\n",
       "        Trying:\n",
       "            {'\\'', 'the', 'Humpty'}.intersection(set(vc.index[:6])) != {}\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 42\n",
       "        Failed example:\n",
       "            {'\\'', 'the', 'Humpty'}.intersection(set(vc.index[:6])) != {}\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 42[1]>\", line 1, in <module>\n",
       "                {'\\'', 'the', 'Humpty'}.intersection(set(vc.index[:6])) != {}\n",
       "            NameError: name 'vc' is not defined\n",
       "\n",
       "    q5 - 43 message: most common sampled tokens\n",
       "\n",
       "    q5 - 44 result:\n",
       "        Trying:\n",
       "            vc = pd.Series(out_5d2.split()).value_counts(normalize=True)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 43\n",
       "        Failed example:\n",
       "            vc = pd.Series(out_5d2.split()).value_counts(normalize=True)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 43[0]>\", line 1, in <module>\n",
       "                vc = pd.Series(out_5d2.split()).value_counts(normalize=True)\n",
       "            AttributeError: 'list' object has no attribute 'split'\n",
       "        Trying:\n",
       "            vc.iloc[0] >= 0.12\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 2, in q5 43\n",
       "        Failed example:\n",
       "            vc.iloc[0] >= 0.12\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 43[1]>\", line 1, in <module>\n",
       "                vc.iloc[0] >= 0.12\n",
       "            NameError: name 'vc' is not defined\n",
       "\n",
       "    q5 - 44 message: most common sampled tokens\n",
       "\n",
       "    q5 - 45 result:\n",
       "        Trying:\n",
       "            8 <= len(out_5d3.split()) <= 12\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 44\n",
       "        Failed example:\n",
       "            8 <= len(out_5d3.split()) <= 12\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"c:\\Users\\Zaki Ahmed\\AppData\\Local\\Programs\\Python\\Python39\\lib\\doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q5 44[0]>\", line 1, in <module>\n",
       "                8 <= len(out_5d3.split()) <= 12\n",
       "            AttributeError: 'list' object has no attribute 'split'\n",
       "\n",
       "    q5 - 45 message: correct sample length\n",
       "\n",
       "    q5 - 46 result:\n",
       "        Trying:\n",
       "            cond = False\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            for w in 'Ulysses a the ,'.split():\n",
       "                cond = cond or (w in out_5d3)\n",
       "        Expecting nothing\n",
       "        ok\n",
       "        Trying:\n",
       "            cond\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 4, in q5 45\n",
       "        Failed example:\n",
       "            cond\n",
       "        Expected:\n",
       "            True\n",
       "        Got:\n",
       "            False\n",
       "\n",
       "    q5 - 46 message: homer: check for common word"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> beowulf[:20] == '\\n\\n\\n\\n\\nProduced by Dav'\nTrue",
         "failure_message": "make sure front matter not in string",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> license = 're-use it under the terms of the Project Gutenberg License'\n>>> license not in beowulf\nTrue",
         "failure_message": "make sure front matter not in string",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> story = 'king of the Danes, or Scyldings'\n>>> story in beowulf\nTrue",
         "failure_message": "text from book check",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> story = 'Said he was kindest of kings'\n>>> story in beowulf\nTrue",
         "failure_message": "text from book check",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> end = 'This file should be named 16328-8.txt'\n>>> end not in beowulf\nTrue",
         "failure_message": "end matter check",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> license = 're-use it under the terms of the Project Gutenberg License'\n>>> license not in homer\nTrue",
         "failure_message": "make sure front matter not in string",
         "hidden": false,
         "locked": false,
         "points": 1.5
        },
        {
         "code": ">>> story = 'rendered into English'\n>>> story in homer\nTrue",
         "failure_message": "text from book check",
         "hidden": false,
         "locked": false,
         "points": 1.5
        },
        {
         "code": ">>> story = 'I was shown a man who was always called'\n>>> story in homer\nTrue",
         "failure_message": "text from book check",
         "hidden": false,
         "locked": false,
         "points": 1.5
        },
        {
         "code": ">>> end = 'This file should be named'\n>>> end not in homer\nTrue",
         "failure_message": "end matter check",
         "hidden": false,
         "locked": false,
         "points": 1.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 1000000 <= len(shakes) <= 1500000\nTrue",
         "failure_message": "approx correct number of tokens",
         "hidden": false,
         "locked": false,
         "points": 3
        },
        {
         "code": ">>> elapsed <= 10\nTrue",
         "failure_message": "shakespeare fast enough",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> shakes[:3] == ['\\x02', 'The', 'Complete']\nTrue",
         "failure_message": "check beginning",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> shakes[-3:] == ['William', 'Shakespeare', '\\x03']\nTrue",
         "failure_message": "check ending",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> shakes[41] == 'IT'\nTrue",
         "failure_message": "Check specific token",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> 'youth' in shakes[490:510]\nTrue",
         "failure_message": "approx correct number of tokens",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> 149000 <= len(homer) <= 155000\nTrue",
         "failure_message": "approx correct number of tokens",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> 'illustrations' in homer[480:520]\nTrue",
         "failure_message": "token example",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> '. \\x03 \\x02 I shall' in ' '.join(homer[:550])\nTrue",
         "failure_message": "token example",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> (unif.mdl == 0.25).all()\nTrue",
         "failure_message": "only one probability",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> unif.mdl.shape[0] == 4\nTrue",
         "failure_message": "number of tokens in mdl",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> isinstance(unif.mdl, pd.Series)\nTrue",
         "failure_message": "mdl correct type",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> set(unif.mdl.index) == set('one two three four'.split())\nTrue",
         "failure_message": "correct indices for mdl",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> unif.probability(('five',)) == 0\nTrue",
         "failure_message": "five not a token",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> unif.probability(('one', 'two')) == 0.0625\nTrue",
         "failure_message": "probability of given sequence appearing",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> np.isclose(unif.probability(('one', 'two', 'three', 'two', 'one', 'four', 'one', 'two')), 0.25 ** 8, atol=1e-6)\nTrue",
         "failure_message": "probability of given sequence appearing",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(unif.sample(1000), str)\nTrue",
         "failure_message": "sample is string",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> len(unif.sample(1000).split()) == 1000\nTrue",
         "failure_message": "length of sample",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> s = pd.Series(unif.sample(1000).split()).value_counts(normalize=True)\n>>> np.isclose(s, 0.25, atol=0.05).all()\nTrue",
         "failure_message": "prop of words in sample close to 0.25",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> hidden_unif.mdl.nunique() == 1\nTrue",
         "failure_message": "only one probability",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> hidden_unif.mdl.shape[0] == 27\nTrue",
         "failure_message": "number of tokens in mdl",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(hidden_unif.mdl.iloc[0], 0.037037)\nTrue",
         "failure_message": "correct probability",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> p = hidden_unif.mdl['Humpty'] * hidden_unif.mdl['Dumpty']\n>>> hidden_unif.probability(('Humpty', 'Dumpty')) == p\nTrue",
         "failure_message": "probability method test",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> p = hidden_unif.mdl['sat'] * hidden_unif.mdl['Dumpty']\n>>> hidden_unif.probability(('sat', 'Dumpty')) == p\nTrue",
         "failure_message": "probability method test: non-consec",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> hidden_unif.probability(('Humpty', 'blahblah')) == 0\nTrue",
         "failure_message": "probability method test: no exist",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> hidden_unif.probability(('\\x02',)) == hidden_unif.mdl['\\x02']\nTrue",
         "failure_message": "probability method test: START token",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> len(hidden_unif.sample(10).split()) == 10\nTrue",
         "failure_message": "sample length",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> samp = hidden_unif.sample(100)\n>>> pd.Series(samp.split()).value_counts().max() <= 15\nTrue",
         "failure_message": "*uniform* sample check",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> samp = hidden_unif.sample(100)\n>>> isinstance(samp, str)\nTrue",
         "failure_message": "sample is string",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> unigram.mdl.nunique() == 3\nTrue",
         "failure_message": "test mdl",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> isinstance(unigram.mdl, pd.Series)\nTrue",
         "failure_message": "mdl correct type",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> set(unigram.mdl.index) == set('one two three four'.split())\nTrue",
         "failure_message": "correct indices for mdl",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> np.isclose(unigram.mdl.loc['one'], 3/7, atol=0.005)\nTrue",
         "failure_message": "mdl: one",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> unigram.probability(('five',)) == 0\nTrue",
         "failure_message": "five not a token",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> p = unigram.probability(('one', 'two')) \n>>> np.isclose(p, 0.12244897959, atol=0.0001)\nTrue",
         "failure_message": "probability of given sequence appearing",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> p = unigram.probability(('one', 'two', 'one', 'one', 'four'))\n>>> p_out = (unigram.mdl['one'] ** 3) * unigram.mdl['two'] * unigram.mdl['four']\n>>> np.isclose(p, p_out, atol=0.0001)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> len(unigram.sample(1000).split()) == 1000\nTrue",
         "failure_message": "sample length",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> isinstance(unigram.sample(1000), str)\nTrue",
         "failure_message": "sample is string",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> s = pd.Series(unigram.sample(1000).split()).value_counts(normalize=True).loc['one']\n>>> np.isclose(s, 0.41, atol=0.05).all()\nTrue",
         "failure_message": "prop of words in sample close to observed prop, 0.41",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> ugrm.mdl.nunique() == 3\nTrue",
         "failure_message": "test mdl",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> len(ugrm.sample(10).split()) == 10\nTrue",
         "failure_message": "sample length",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> ugrm.mdl.nunique() == 3\nTrue",
         "failure_message": "test mdl",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(ugrm.mdl.loc['Humpty'], 0.076923, atol=0.005)\nTrue",
         "failure_message": "mdl: Humpty",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(ugrm.mdl.loc[','], 0.025641)\nTrue",
         "failure_message": "mdl: comma",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> p = ugrm.mdl['Humpty'] * ugrm.mdl['Dumpty']\n>>> ugrm.probability(('Humpty', 'Dumpty')) == p\nTrue",
         "failure_message": "probability method test",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> p = ugrm.mdl['sat'] * ugrm.mdl['Dumpty']\n>>> ugrm.probability(('sat', 'Dumpty')) == p\nTrue",
         "failure_message": "probability method test: non-consec",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> ugrm.probability(('Humpty', 'blahblah')) == 0\nTrue",
         "failure_message": "probability method test: no exist",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> ugrm.probability(('\\x02',)) == ugrm.mdl['\\x02']\nTrue",
         "failure_message": "probability method test: START token",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> len(ugrm.sample(10).split()) == 10\nTrue",
         "failure_message": "sample length",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> samp = ugrm.sample(1000)\n>>> pd.Series(samp.split()).value_counts(normalize=True).max() >= 0.061\nTrue",
         "failure_message": "*unigram* sample check",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 36 <= len(out_5a1) <= 40\nTrue",
         "failure_message": "test length",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> all([len(x) == 2 for x in out_5a1])\nTrue",
         "failure_message": "ngram lengths",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_5a1[0] == ('\\x02', 'Humpty')\nTrue",
         "failure_message": "padded with START",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> ('Humpty', 'Dumpty') in out_5a1\nTrue",
         "failure_message": "Humpty Dumpty in bigrams",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> ('great', 'fall') in out_5a1\nTrue",
         "failure_message": "specific bigram in bigrams",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(out_5b1.groupby('n1gram').sum(), 1.0).all()\nTrue",
         "failure_message": "marginal probabilities sum to 1.0",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> (out_5b1['n1gram'].apply(len) == 1).all()\nTrue",
         "failure_message": "n1gram lengths = 1",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> (out_5b1['ngram'].apply(len) == 2).all()\nTrue",
         "failure_message": "ngram lengths = 2",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> p = out_5b1.loc[out_5b1.ngram == ('Humpty', 'Dumpty'), 'prob'].squeeze()\n>>> np.isclose(p, 0.666666, atol=0.001)\nTrue",
         "failure_message": "Humpty Dumpty in bigrams",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> words = 'Humpty Dumpty sat on a great fall'.split()\n>>> p = out_5c1.probability(words)\n>>> np.isclose(p, 0.01282051282051282, atol=0.001)\nTrue",
         "failure_message": "test probability 2gram",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> words = 'Humpty Dumpty'.split()\n>>> p = out_5c1.probability(words)\n>>> np.isclose(p, 0.05128205128205128, atol=0.001)\nTrue",
         "failure_message": "test probability 2gram",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> words = 'couldn \\' t put Humpty'.split()\n>>> p = out_5c1.probability(words)\n>>> np.isclose(p, 0.008547008547008546, atol=0.001)\nTrue",
         "failure_message": "test probability 2gram",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> words = 'All the king \\' s men'.split()\n>>> p = out_5c1.probability(words)\n>>> np.isclose(p, 0.008547008547008546, atol=0.001)\nTrue",
         "failure_message": "test probability 2gram",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> words = 'Humpty Dumpty together again'.split()\n>>> p = out_5c1.probability(words)\n>>> np.isclose(p, 0, atol=0.001)\nTrue",
         "failure_message": "test probability 2gram",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> 495 <= len(out_5d1.split()) < 505\nTrue",
         "failure_message": "approx length of sample",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> 'Humpty Dumpty' in out_5d1\nTrue",
         "failure_message": "Humpty Dumpty in sample",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> 'together again' in out_5d1\nTrue",
         "failure_message": "together again in sample",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> vc = pd.Series(out_5d1.split()).value_counts(normalize=True)\n>>> {'\\'', 'the', 'Humpty'}.intersection(set(vc.index[:6])) != {}\nTrue",
         "failure_message": "most common sampled tokens",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> vc = pd.Series(out_5d1.split()).value_counts(normalize=True)\n>>> np.isclose(vc.iloc[0], 0.07, atol=0.03)\nTrue",
         "failure_message": "most common sampled tokens",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> 35 <= len(out_5a2) <= 39\nTrue",
         "failure_message": "test token size",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> all([len(x) == 3 for x in out_5a2])\nTrue",
         "failure_message": "ngram lengths",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> out_5a2[0] == ('\\x02', 'Humpty', 'Dumpty')\nTrue",
         "failure_message": "padded with START",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> ('Humpty', 'Dumpty', 'sat') in out_5a2\nTrue",
         "failure_message": "Humpty Dumpty in bigrams",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> ('great', 'fall', '.') in out_5a2\nTrue",
         "failure_message": "specific bigram in bigrams",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> 140000 <= len(out_5a3) <= 170000\nTrue",
         "failure_message": "number of ngrams",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> all([len(x) == 3 for x in out_5a3])\nTrue",
         "failure_message": "ngram lengths",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(out_5b2.groupby('n1gram').sum(), 1.0).all()\nTrue",
         "failure_message": "marginal probabilities sum to 1.0",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> (out_5b2['n1gram'].apply(len) == 2).all()\nTrue",
         "failure_message": "n1gram lengths = 2",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> (out_5b2['ngram'].apply(len) == 3).all()\nTrue",
         "failure_message": "ngram lengths = 3",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> p = out_5b2.loc[out_5b2.ngram == ('Humpty', 'Dumpty', 'sat'), 'prob'].squeeze()\n>>> np.isclose(p, 0.5, atol=0.001)\nTrue",
         "failure_message": "Humpty Dumpty in bigrams",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> p = out_5b3.mdl.loc[out_5b3.mdl.ngram == ('was', 'the', 'night'), 'prob'].iloc[0]\n>>> np.isclose(p, 0.018182, atol=0.01)\nTrue",
         "failure_message": "specific row of mdl",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> np.isclose(out_5b3.mdl.groupby('n1gram')['prob'].sum(), 1.0).all()\nTrue",
         "failure_message": "each n1gram sums to 1.0",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> words = 'Humpty Dumpty sat on a great fall'.split()\n>>> p = out_5c2.probability(words)\n>>> np.isclose(p, 0.0, atol=0.001)\nTrue",
         "failure_message": "test probability 3gram",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> words = 'Humpty Dumpty had'.split()\n>>> p = out_5c2.probability(words)\n>>> np.isclose(p, 0.02564102564102564, atol=0.001)\nTrue",
         "failure_message": "test probability 3gram",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> words = 'had a great fall'.split()\n>>> p = out_5c2.probability(words)\n>>> np.isclose(p, 0.02564102564102564, atol=0.001)\nTrue",
         "failure_message": "test probability 3gram",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> words = 'All the king \\' s men'.split()\n>>> p = out_5c2.probability(words)\n>>> np.isclose(p, 0.01282051282051282, atol=0.001)\nTrue",
         "failure_message": "test probability 3gram",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> words = 'Humpty Dumpty together again'.split()\n>>> p = out_5c2.probability(words)\n>>> np.isclose(p, 0, atol=0.001)\nTrue",
         "failure_message": "test probability 3gram",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> p = out_5c3.probability('In an appendix I base the first things to'.split())\n>>> p > 0\nTrue",
         "failure_message": "nonzero probability from homer",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> p = out_5c3.probability('and there is'.split())\n>>> np.isclose(p, 3.770591063715432e-05, atol=0.0001)\nTrue",
         "failure_message": "homer: common phrase",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> 495 <= len(out_5d2.split()) < 505\nTrue",
         "failure_message": "approx length of sample",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> ('Humpty Dumpty' in out_5d2) or ('All the' in out_5d2)\nTrue",
         "failure_message": "\"Humpty Dumpty\" or \"All the\" in sample",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> 'together again' in out_5d2\nTrue",
         "failure_message": "together again in sample",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> vc = pd.Series(out_5d2.split()).value_counts(normalize=True)\n>>> {'\\'', 'the', 'Humpty'}.intersection(set(vc.index[:6])) != {}\nTrue",
         "failure_message": "most common sampled tokens",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> vc = pd.Series(out_5d2.split()).value_counts(normalize=True)\n>>> vc.iloc[0] >= 0.12\nTrue",
         "failure_message": "most common sampled tokens",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> 8 <= len(out_5d3.split()) <= 12\nTrue",
         "failure_message": "correct sample length",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> cond = False\n>>> for w in 'Ulysses a the ,'.split():\n...     cond = cond or (w in out_5d3)\n>>> cond\nTrue",
         "failure_message": "homer: check for common word",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "19b17eba0dbd5e4b8827ab8a6192fc0dff7c2985f63f4f278d5b971ef380745d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
